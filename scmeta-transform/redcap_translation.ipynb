{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Edit the file paths and/or options in the first chunk if needed.\n",
    "\n",
    "Note that to use the REDCap functions, you'll need to create a file in this format:\n",
    "\n",
    "{\n",
    "\t\"Cho Lab Single Cell Sample Metadatabase\": {\n",
    "\t\t\"url\": \"https://redcap.mountsinai.org/redcap/api/\",\n",
    "\t\t\"token\": \"<TOKEN HERE (see API tab on RC)>\",\n",
    "\t\t\"content\": \"project\",\n",
    "\t\t\"format\": \"json\",\n",
    "\t\t\"returnFormat\": \"json\"\n",
    "\t}\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "## Imports & Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import (get_google_sheet, get_redcap_metadata, try_float,\n",
    "                       investigate_fields, extract_categories, search_fields)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_colwidth\", 500)\n",
    "\n",
    "# path_file = None\n",
    "path_file = \"sc-metadata-cleanup.csv\"\n",
    "path_config = os.path.join(os.path.expanduser(\"~\"), \".ssh/config_redcap.json\")\n",
    "path_secret = os.path.join(os.path.expanduser(\"~\"),\n",
    "                           \".ssh/client_secret_google_sheets.json\")\n",
    "dd_dict_csv = os.path.join(\n",
    "    os.path.expanduser(\"~\"), str(\"Downloads/ChoLabSingleCellSampleMetadata_\"\n",
    "                                 \"DataDictionary_2023-12-01.csv\"))\n",
    "rc_project = \"Cho Lab Single Cell Sample Metadatabase\"\n",
    "redcap_event_name = \"forms_arm_1\"\n",
    "id_sheet = \"1PV2vPHjBWxj3Hn0od1B78q98Q6yoyEbj6ku9obzYr2I\"\n",
    "unique_id = \"lib_id\"\n",
    "rm_cols_collapsed = [\"project_owner_id\"]  # collapsing into \"POID_1,POID_2\", etc.\n",
    "cols_should_be_unique = [\"standard_sample_id\"]\n",
    "cols_subject = [\"record_id\", \"record_id1\", \"grid\", \"patient_id\"]\n",
    "# cols_subject = [\"record_id\", \"grid\"]\n",
    "# fields_cat = [\"disease\", \"disease_status\", \"organism\", \"animal_line\", \n",
    "#               \"x_chem_version_sc\", \"inflam_status\",\n",
    "#               \"tissue_origin\", \"index_kit\",  \"instrument\"]\n",
    "missing_ok = []  # TODO: add missing_ok columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              record_id         record_id1   organism               project  \\\n",
      "lib_id                                                                        \n",
      "HH0001       HH_Hu_MO13  Sabic_Project_020      Human      CRISPR Screening   \n",
      "J00002        JM_Ze_Lck         Sabic_7719  Zebrafish  Zebrafish Felix_Josh   \n",
      "J00003        JM_Ze_Lck         Sabic_7719  Zebrafish  Zebrafish Felix_Josh   \n",
      "J00004        JM_Ze_Lck         Sabic_7719  Zebrafish  Zebrafish Felix_Josh   \n",
      "J00005        JM_Ze_Lck         Sabic_7719  Zebrafish  Zebrafish Felix_Josh   \n",
      "LC0001        FC_Hu_sCD  Sabic_Project_022      Human                  PBMC   \n",
      "LC0002        FC_Hu_sCD  Sabic_Project_021      Human                  PBMC   \n",
      "LC0003        FC_Hu_sUC  Sabic_Project_022      Human                  PBMC   \n",
      "LC0004        FC_Hu_sUC  Sabic_Project_021      Human                  PBMC   \n",
      "LC0005         FC_Hu_sH  Sabic_Project_022      Human                  PBMC   \n",
      "LC0006         FC_Hu_sH  Sabic_Project_021      Human                  PBMC   \n",
      "RL0001        RL_Hu_AA2  Sabic_Project_011      Human           Perianal CD   \n",
      "RL0001_re     RL_Hu_AA2  Sabic_Project_013      Human           Perianal CD   \n",
      "RL0002        RL_Hu_AA2  Sabic_Project_011      Human           Perianal CD   \n",
      "RL0002_re     RL_Hu_AA2  Sabic_Project_011      Human           Perianal CD   \n",
      "RL0003        RL_Hu_EA1  Sabic_Project_011      Human           Perianal CD   \n",
      "RL0004        RL_Hu_EA1  Sabic_Project_011      Human           Perianal CD   \n",
      "RL0005        RL_Hu_AA3  Sabic_Project_013      Human           Perianal CD   \n",
      "RL0006        RL_Hu_AA3  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0007        RL_Hu_AA3                NaN      Human           Perianal CD   \n",
      "RL0008        RL_Hu_AA3  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0009        RL_Hu_AA3                NaN      Human           Perianal CD   \n",
      "RL0010        RL_Hu_AA3  Sabic_Project_015      Human           Perianal CD   \n",
      "RL0011        RL_Hu_EA2  Sabic_Project_013      Human           Perianal CD   \n",
      "RL0012        RL_Hu_EA2  Sabic_Project_013      Human           Perianal CD   \n",
      "RL0013        RL_Hu_EA2  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0014        RL_Hu_EA2  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0015        RL_Hu_EA2  Sabic_Project_015      Human           Perianal CD   \n",
      "RL0016        RL_Hu_EA2  Sabic_Project_015      Human           Perianal CD   \n",
      "RL0017        RL_Hu_AA4  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0018        RL_Hu_AA4  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0019        RL_Hu_EA3         Sabic_7609      Human           Perianal CD   \n",
      "RL0020        RL_Hu_EA3         Sabic_7609      Human           Perianal CD   \n",
      "RL0021        RL_Hu_AA5         Sabic_7609      Human           Perianal CD   \n",
      "RL0022        RL_Hu_AA5         Sabic_7609      Human           Perianal CD   \n",
      "RL0023        RL_Hu_AA6  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0024        RL_Hu_AA6  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0025        RL_Hu_AA6  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0026        RL_Hu_AA6  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0027        RL_Hu_AA6  Sabic_Project_015      Human           Perianal CD   \n",
      "RL0028        RL_Hu_AA6  Sabic_Project_015      Human           Perianal CD   \n",
      "RL0029        RL_Hu_EA4  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0030        RL_Hu_EA4  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0031        RL_Hu_EA4  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0032        RL_Hu_EA4  Sabic_Project_016      Human           Perianal CD   \n",
      "RL0033        RL_Hu_EA4  Sabic_Project_015      Human           Perianal CD   \n",
      "RL0034        RL_Hu_EA4  Sabic_Project_015      Human           Perianal CD   \n",
      "RL0035        RL_Hu_SA1         Sabic_7609      Human           Perianal CD   \n",
      "RL0036        RL_Hu_SA1         Sabic_7609      Human           Perianal CD   \n",
      "RL0037        RL_Hu_EA5  Sabic_Project_020      Human           Perianal CD   \n",
      "RL0038        RL_Hu_EA5  Sabic_Project_020      Human           Perianal CD   \n",
      "RL0039        RL_Hu_EA5  Sabic_Project_021      Human           Perianal CD   \n",
      "RL0040        RL_Hu_EA5  Sabic_Project_021      Human           Perianal CD   \n",
      "RL0041        RL_Hu_EA5  Sabic_Project_020      Human           Perianal CD   \n",
      "RL0042        RL_Hu_EA5  Sabic_Project_020      Human           Perianal CD   \n",
      "RL0043        RL_Hu_AA7  Sabic_Project_020      Human           Perianal CD   \n",
      "RL0044        RL_Hu_AA7  Sabic_Project_020      Human           Perianal CD   \n",
      "RL0045        RL_Hu_AA7  Sabic_Project_021      Human           Perianal CD   \n",
      "RL0046        RL_Hu_AA7  Sabic_Project_021      Human           Perianal CD   \n",
      "RL0047        RL_Hu_AA7  Sabic_Project_020      Human           Perianal CD   \n",
      "RL0048        RL_Hu_AA7  Sabic_Project_020      Human           Perianal CD   \n",
      "RL0049        RL_Hu_EA6  Sabic_Project_020      Human           Perianal CD   \n",
      "RL0050        RL_Hu_EA6  Sabic_Project_020      Human           Perianal CD   \n",
      "RL0051        RL_Hu_EA7  Sabic_Project_022      Human           Perianal CD   \n",
      "RL0052        RL_Hu_EA7  Sabic_Project_025      Human           Perianal CD   \n",
      "RL0053        RL_Hu_EA7  Sabic_Project_022      Human           Perianal CD   \n",
      "RL0054        RL_Hu_EA7  Sabic_Project_022      Human           Perianal CD   \n",
      "SN0001         SN_Ze_WT  Sabic_Project_013  Zebrafish      Zebrafish Shikha   \n",
      "SN0002         SN_Ze_WT  Sabic_Project_013  Zebrafish      Zebrafish Shikha   \n",
      "SN0003         SN_Ze_WT                NaN  Zebrafish      Zebrafish Shikha   \n",
      "SN0004         SN_Ze_WT                NaN  Zebrafish      Zebrafish Shikha   \n",
      "SN0005       SN_Ze_nod2  Sabic_Project_013  Zebrafish      Zebrafish Shikha   \n",
      "SN0006       SN_Ze_nod2  Sabic_Project_013  Zebrafish      Zebrafish Shikha   \n",
      "SN0007       SN_Ze_nod2  Sabic_Project_013  Zebrafish      Zebrafish Shikha   \n",
      "SN0008       SN_Ze_nod2  Sabic_Project_013  Zebrafish      Zebrafish Shikha   \n",
      "SN0009        SN_Ze_WT2  Sabic_Project_013  Zebrafish      Zebrafish Shikha   \n",
      "SN0010        SN_Ze_WT2  Sabic_Project_013  Zebrafish      Zebrafish Shikha   \n",
      "SN0011        SN_Ze_WT2  Sabic_Project_013  Zebrafish      Zebrafish Shikha   \n",
      "SN0012        SN_Ze_WT2  Sabic_Project_013  Zebrafish      Zebrafish Shikha   \n",
      "SN0013        SN_Hu_P13  Sabic_Project_016      Human        Ileal CD gp130   \n",
      "SN0014        SN_Hu_P13  Sabic_Project_016      Human        Ileal CD gp130   \n",
      "UC0001         ZC_Hu_P1  Sabic_Project_011      Human              UC_ZC_sc   \n",
      "UC0002         ZC_Hu_P1  Sabic_Project_011      Human              UC_ZC_sc   \n",
      "UC0003         ZC_Hu_P2  Sabic_Project_011      Human              UC_ZC_sc   \n",
      "UC0004         ZC_Hu_P2  Sabic_Project_011      Human              UC_ZC_sc   \n",
      "NH0001        NH_Mo_KO2                NaN      Mouse        Mouse Organoid   \n",
      "NH0002        NH_Mo_KO2                NaN      Mouse        Mouse Organoid   \n",
      "NH0003        NH_Mo_KO4                NaN      Mouse        Mouse Organoid   \n",
      "NH0004        NH_Mo_KO4                NaN      Mouse        Mouse Organoid   \n",
      "NH0005        NH_Mo_WT1                NaN      Mouse        Mouse Organoid   \n",
      "NH0006        NH_Mo_WT1                NaN      Mouse        Mouse Organoid   \n",
      "NH0007        NH_Mo_WT3                NaN      Mouse        Mouse Organoid   \n",
      "NH0008        NH_Mo_WT3                NaN      Mouse        Mouse Organoid   \n",
      "NH0009         NH_Hu_P1                NaN      Human                    UC   \n",
      "NH0010         NH_Hu_P1                NaN      Human                    UC   \n",
      "NH0011         NH_Hu_P2                NaN      Human                    UC   \n",
      "NH0012         NH_Hu_P2                NaN      Human                    UC   \n",
      "NH0013         NH_Hu_P3                NaN      Human                    UC   \n",
      "NH0014         NH_Hu_P3                NaN      Human                    UC   \n",
      "NH0015         NH_Hu_P4                NaN      Human                    UC   \n",
      "NH0016         NH_Hu_P4                NaN      Human                    UC   \n",
      "QQ0001        JM_Hu_P10                NaN      Human              Ileal CD   \n",
      "QQ0002        JM_Hu_P10                NaN      Human              Ileal CD   \n",
      "QQ0003        JM_Hu_P10                NaN      Human              Ileal CD   \n",
      "QQ0004        JM_Hu_P11                NaN      Human              Ileal CD   \n",
      "QQ0005        JM_Hu_P11                NaN      Human              Ileal CD   \n",
      "QQ0006        JM_Hu_P11                NaN      Human              Ileal CD   \n",
      "QQ0007        JM_Hu_P12                NaN      Human              Ileal CD   \n",
      "QQ0008        JM_Hu_P12                NaN      Human              Ileal CD   \n",
      "QQ0009        JM_Hu_P12                NaN      Human              Ileal CD   \n",
      "QQ0010        JM_Hu_P13                NaN      Human              Ileal CD   \n",
      "QQ0011        JM_Hu_P13                NaN      Human              Ileal CD   \n",
      "QQ0012        JM_Hu_P14                NaN      Human              Ileal CD   \n",
      "QQ0013        JM_Hu_P14                NaN      Human              Ileal CD   \n",
      "QQ0014        JM_Hu_P14                NaN      Human              Ileal CD   \n",
      "QQ0015        JM_Hu_P15                NaN      Human              Ileal CD   \n",
      "QQ0016        JM_Hu_P15                NaN      Human              Ileal CD   \n",
      "QQ0017        JM_Hu_P16                NaN      Human              Ileal CD   \n",
      "QQ0018        JM_Hu_P16                NaN      Human              Ileal CD   \n",
      "QQ0019         JM_Hu_P5                NaN      Human              Ileal CD   \n",
      "QQ0020         JM_Hu_P5                NaN      Human              Ileal CD   \n",
      "QQ0021         JM_Hu_P5                NaN      Human              Ileal CD   \n",
      "QQ0022         JM_Hu_P6                NaN      Human              Ileal CD   \n",
      "QQ0023         JM_Hu_P6                NaN      Human              Ileal CD   \n",
      "QQ0024         JM_Hu_P6                NaN      Human              Ileal CD   \n",
      "QQ0025         JM_Hu_P7                NaN      Human              Ileal CD   \n",
      "QQ0026         JM_Hu_P7                NaN      Human              Ileal CD   \n",
      "QQ0027         JM_Hu_P7                NaN      Human              Ileal CD   \n",
      "QQ0028         JM_Hu_P8                NaN      Human              Ileal CD   \n",
      "QQ0029         JM_Hu_P8                NaN      Human              Ileal CD   \n",
      "QQ0030         JM_Hu_P8                NaN      Human              Ileal CD   \n",
      "QQ0031        FC_Hu_IL1                NaN      Human       Ileal CD/PTGER4   \n",
      "QQ0032        FC_Hu_IL1                NaN      Human       Ileal CD/PTGER4   \n",
      "QQ0033         FC_Hu_AA                NaN      Human                  PBMC   \n",
      "QQ0034         FC_Hu_EA                NaN      Human                  PBMC   \n",
      "AA1inf        RL_Hu_AA1                NaN      Human           Perianal CD   \n",
      "AA1non        RL_Hu_AA1                NaN      Human           Perianal CD   \n",
      "QQ0035       FC_Ze_WT03                NaN  Zebrafish  Zebrafish Felix_Josh   \n",
      "QQ0036     FC_Ze_WTJM02                NaN  Zebrafish  Zebrafish Felix_Josh   \n",
      "QQ0037     FC_Ze_WTJM04                NaN  Zebrafish  Zebrafish Felix_Josh   \n",
      "QQ0038       FC_Ze_WT04                NaN  Zebrafish  Zebrafish Felix_Josh   \n",
      "QQ0039       FC_Ze_WT02                NaN  Zebrafish  Zebrafish Felix_Josh   \n",
      "QQ0040     FC_Ze_WTJM03                NaN  Zebrafish  Zebrafish Felix_Josh   \n",
      "QQ0041       FC_Ze_WT01                NaN  Zebrafish  Zebrafish Felix_Josh   \n",
      "QQ0042       FC_Ze_WT05                NaN  Zebrafish  Zebrafish Felix_Josh   \n",
      "QQ0043     FC_Ze_WTJM01                NaN  Zebrafish  Zebrafish Felix_Josh   \n",
      "QQ0044        SN_Ze_KO1                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0045        SN_Ze_KO1                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0046        SN_Ze_KO2                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0047        SN_Ze_KO2                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0048        SN_Ze_KO2                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0049        SN_Ze_WT1                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0050        SN_Ze_WT1                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0051        SN_Ze_WT2                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0052        SN_Ze_WT2                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0053        SN_Ze_WT3                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0054        SN_Ze_WT3                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0055        SN_Ze_WT4                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0056        SN_Ze_WT4                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0057        SN_Ze_WT5                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0058        SN_Ze_WT5                NaN  Zebrafish      Zebrafish Shikha   \n",
      "QQ0059        SN_Ze_WT5                NaN  Zebrafish      Zebrafish Shikha   \n",
      "KC0004        KC_Hu_CD1                NaN      Human              Ileal CD   \n",
      "KC0002        KC_Hu_CD1                NaN      Human              Ileal CD   \n",
      "KC0003        KC_Hu_CD1                NaN      Human              Ileal CD   \n",
      "KC0005        KC_Hu_CD1                NaN      Human              Ileal CD   \n",
      "KC0001        KC_Hu_CD1                NaN      Human              Ileal CD   \n",
      "CD0001        FC_Hu_IL2  Sabic_Project_011      Human              Ileal CD   \n",
      "CD0002        FC_Hu_IL2  Sabic_Project_011      Human              Ileal CD   \n",
      "CD0003        FC_Hu_IL3  Sabic_Project_011      Human              Ileal CD   \n",
      "CD0004        FC_Hu_IL3  Sabic_Project_011      Human              Ileal CD   \n",
      "\n",
      "           disease       disease_status       grid  patient_id  \\\n",
      "lib_id                                                           \n",
      "HH0001          CD             Remisson  1010898.0     1010898   \n",
      "J00002         NaN                  NaN        NaN         NaN   \n",
      "J00003         NaN                  NaN        NaN         NaN   \n",
      "J00004         NaN                  NaN        NaN         NaN   \n",
      "J00005         NaN                  NaN        NaN         NaN   \n",
      "LC0001          CD               Active  1010893.0        sCD1   \n",
      "LC0002          CD               Active  1010893.0        sCD1   \n",
      "LC0003          UC               active  1010933.0        sUC1   \n",
      "LC0004          UC               active  1010933.0        sUC1   \n",
      "LC0005     Healthy                  NaN  1010934.0          sH   \n",
      "LC0006     Healthy                  NaN  1010934.0          sH   \n",
      "RL0001          CD            Remission  1010711.0         AA4   \n",
      "RL0001_re       CD            Remission  1010711.0         AA4   \n",
      "RL0002          CD            Remission  1010711.0         AA4   \n",
      "RL0002_re       CD            Remission  1010711.0         AA4   \n",
      "RL0003          CD     Active + Fistula  1010722.0         EA2   \n",
      "RL0004          CD     Active + Fistula  1010722.0         EA2   \n",
      "RL0005          CD     Active + Fistula  1010733.0         AA5   \n",
      "RL0006          CD     Active + Fistula  1010733.0         AA5   \n",
      "RL0007          CD     Active + Fistula  1010733.0         AA5   \n",
      "RL0008          CD     Active + Fistula  1010733.0         AA5   \n",
      "RL0009          CD     Active + Fistula  1010733.0         AA5   \n",
      "RL0010          CD     Active + Fistula  1010733.0         AA5   \n",
      "RL0011          CD  Remission + Fistula  1010758.0         EA3   \n",
      "RL0012          CD  Remission + Fistula  1010758.0         EA3   \n",
      "RL0013          CD  Remission + Fistula  1010758.0         EA3   \n",
      "RL0014          CD  Remission + Fistula  1010758.0         EA3   \n",
      "RL0015          CD  Remission + Fistula  1010758.0         EA3   \n",
      "RL0016          CD  Remission + Fistula  1010758.0         EA3   \n",
      "RL0017          CD               Active  1010779.0         AA6   \n",
      "RL0018          CD               Active  1010779.0         AA6   \n",
      "RL0019          CD               Active  1010789.0         EA4   \n",
      "RL0020          CD               Active  1010789.0         EA4   \n",
      "RL0021          CD            Remission  1002346.0         AA7   \n",
      "RL0022          CD            Remission  1002346.0         AA7   \n",
      "RL0023          CD    Active + Fistula?  1002363.0         AA8   \n",
      "RL0024          CD    Active + Fistula?  1002363.0         AA8   \n",
      "RL0025          CD    Active + Fistula?  1002363.0         AA8   \n",
      "RL0026          CD    Active + Fistula?  1002363.0         AA8   \n",
      "RL0027          CD    Active + Fistula?  1002363.0         AA8   \n",
      "RL0028          CD    Active + Fistula?  1002363.0         AA8   \n",
      "RL0029          CD  Remission + Fistula  1010800.0         EA5   \n",
      "RL0030          CD  Remission + Fistula  1010800.0         EA5   \n",
      "RL0031          CD  Remission + Fistula  1010800.0         EA5   \n",
      "RL0032          CD  Remission + Fistula  1010800.0         EA5   \n",
      "RL0033          CD  Remission + Fistula  1010800.0         EA5   \n",
      "RL0034          CD  Remission + Fistula  1010800.0         EA5   \n",
      "RL0035          CD     Active + Fistula  1010810.0         SA1   \n",
      "RL0036          CD     Active + Fistula  1010810.0         SA1   \n",
      "RL0037          CD  Remission + Fistula  1010890.0         EA6   \n",
      "RL0038          CD  Remission + Fistula  1010890.0         EA6   \n",
      "RL0039          CD  Remission + Fistula  1010890.0         EA6   \n",
      "RL0040          CD  Remission + Fistula  1010890.0         EA6   \n",
      "RL0041          CD  Remission + Fistula  1010890.0         EA6   \n",
      "RL0042          CD  Remission + Fistula  1010890.0         EA6   \n",
      "RL0043          CD    Active + stenosis  1010895.0         AA9   \n",
      "RL0044          CD    Active + stenosis  1010895.0         AA9   \n",
      "RL0045          CD    Active + stenosis  1010895.0         AA9   \n",
      "RL0046          CD    Active + stenosis  1010895.0         AA9   \n",
      "RL0047          CD    Active + stenosis  1010895.0         AA9   \n",
      "RL0048          CD    Active + stenosis  1010895.0         AA9   \n",
      "RL0049          CD     Active + fistula  1010893.0         EA7   \n",
      "RL0050          CD     Active + fistula  1010893.0         EA7   \n",
      "RL0051          CD     Active + fistula  1010558.0         EA8   \n",
      "RL0052          CD     Active + fistula  1010558.0         EA8   \n",
      "RL0053          CD     Active + fistula  1010558.0         EA8   \n",
      "RL0054          CD     Active + fistula  1010558.0         EA8   \n",
      "SN0001         NaN                  NaN        NaN         NaN   \n",
      "SN0002         NaN                  NaN        NaN         NaN   \n",
      "SN0003         NaN                  NaN        NaN         NaN   \n",
      "SN0004         NaN                  NaN        NaN         NaN   \n",
      "SN0005         NaN                  NaN        NaN         NaN   \n",
      "SN0006         NaN                  NaN        NaN         NaN   \n",
      "SN0007         NaN                  NaN        NaN         NaN   \n",
      "SN0008         NaN                  NaN        NaN         NaN   \n",
      "SN0009         NaN                  NaN        NaN         NaN   \n",
      "SN0010         NaN                  NaN        NaN         NaN   \n",
      "SN0011         NaN                  NaN        NaN         NaN   \n",
      "SN0012         NaN                  NaN        NaN         NaN   \n",
      "SN0013          CD            Remission  1002131.0        SN13   \n",
      "SN0014          CD            Remission  1002131.0        SN13   \n",
      "UC0001          UC               Active  1010692.0  UC_ZC_sc_1   \n",
      "UC0002          UC               Active  1010692.0  UC_ZC_sc_1   \n",
      "UC0003          UC               Active  1010693.0  UC_ZC_sc_2   \n",
      "UC0004          UC               Active  1010693.0  UC_ZC_sc_2   \n",
      "NH0001         NaN                  NaN        NaN         NaN   \n",
      "NH0002         NaN                  NaN        NaN         NaN   \n",
      "NH0003         NaN                  NaN        NaN         NaN   \n",
      "NH0004         NaN                  NaN        NaN         NaN   \n",
      "NH0005         NaN                  NaN        NaN         NaN   \n",
      "NH0006         NaN                  NaN        NaN         NaN   \n",
      "NH0007         NaN                  NaN        NaN         NaN   \n",
      "NH0008         NaN                  NaN        NaN         NaN   \n",
      "NH0009          UC               Active  1001712.0           1   \n",
      "NH0010          UC               Active  1001712.0           1   \n",
      "NH0011          UC               Active  1002392.0           2   \n",
      "NH0012          UC               Active  1002392.0           2   \n",
      "NH0013          UC               Active  1010378.0           3   \n",
      "NH0014          UC               Active  1010378.0           3   \n",
      "NH0015          UC               Active  1010504.0           4   \n",
      "NH0016          UC               Active  1010504.0           4   \n",
      "QQ0001          CD               Active  1002097.0          10   \n",
      "QQ0002          CD               Active  1002097.0          10   \n",
      "QQ0003          CD               Active  1002097.0          10   \n",
      "QQ0004          CD               Active  1002100.0          11   \n",
      "QQ0005          CD               Active  1002100.0          11   \n",
      "QQ0006          CD               Active  1002100.0          11   \n",
      "QQ0007          CD               Active  1002102.0          12   \n",
      "QQ0008          CD               Active  1002102.0          12   \n",
      "QQ0009          CD               Active  1002102.0          12   \n",
      "QQ0010          CD               Active  1002131.0          13   \n",
      "QQ0011          CD               Active  1002131.0          13   \n",
      "QQ0012          CD               Active  1002132.0          14   \n",
      "QQ0013          CD               Active  1002132.0          14   \n",
      "QQ0014          CD               Active  1002132.0          14   \n",
      "QQ0015          CD               Active  1002143.0          15   \n",
      "QQ0016          CD               Active  1002143.0          15   \n",
      "QQ0017          CD               Active  1001723.0          16   \n",
      "QQ0018          CD               Active  1001723.0          16   \n",
      "QQ0019          CD               Active  1002083.0           5   \n",
      "QQ0020          CD               Active  1002083.0           5   \n",
      "QQ0021          CD               Active  1002083.0           5   \n",
      "QQ0022          CD               Active  1002091.0           6   \n",
      "QQ0023          CD               Active  1002091.0           6   \n",
      "QQ0024          CD               Active  1002091.0           6   \n",
      "QQ0025          CD               Active  1002092.0           7   \n",
      "QQ0026          CD               Active  1002092.0           7   \n",
      "QQ0027          CD               Active  1002092.0           7   \n",
      "QQ0028          CD               Active  1002094.0           8   \n",
      "QQ0029          CD               Active  1002094.0           8   \n",
      "QQ0030          CD               Active  1002094.0           8   \n",
      "QQ0031          CD               Active  1010997.0         IL1   \n",
      "QQ0032          CD               Active  1010997.0         IL1   \n",
      "QQ0033     Healthy                  NaN  1010997.0          AA   \n",
      "QQ0034     Healthy                  NaN  1010659.0          EA   \n",
      "AA1inf          CD               Active  1010667.0         AA1   \n",
      "AA1non          CD               Active  1010667.0         AA1   \n",
      "QQ0035         NaN                  NaN        NaN         NaN   \n",
      "QQ0036         NaN                  NaN        NaN         NaN   \n",
      "QQ0037         NaN                  NaN        NaN         NaN   \n",
      "QQ0038         NaN                  NaN        NaN         NaN   \n",
      "QQ0039         NaN                  NaN        NaN         NaN   \n",
      "QQ0040         NaN                  NaN        NaN         NaN   \n",
      "QQ0041         NaN                  NaN        NaN         NaN   \n",
      "QQ0042         NaN                  NaN        NaN         NaN   \n",
      "QQ0043         NaN                  NaN        NaN         NaN   \n",
      "QQ0044         NaN                  NaN        NaN         NaN   \n",
      "QQ0045         NaN                  NaN        NaN         NaN   \n",
      "QQ0046         NaN                  NaN        NaN         NaN   \n",
      "QQ0047         NaN                  NaN        NaN         NaN   \n",
      "QQ0048         NaN                  NaN        NaN         NaN   \n",
      "QQ0049         NaN                  NaN        NaN         NaN   \n",
      "QQ0050         NaN                  NaN        NaN         NaN   \n",
      "QQ0051         NaN                  NaN        NaN         NaN   \n",
      "QQ0052         NaN                  NaN        NaN         NaN   \n",
      "QQ0053         NaN                  NaN        NaN         NaN   \n",
      "QQ0054         NaN                  NaN        NaN         NaN   \n",
      "QQ0055         NaN                  NaN        NaN         NaN   \n",
      "QQ0056         NaN                  NaN        NaN         NaN   \n",
      "QQ0057         NaN                  NaN        NaN         NaN   \n",
      "QQ0058         NaN                  NaN        NaN         NaN   \n",
      "QQ0059         NaN                  NaN        NaN         NaN   \n",
      "KC0004          CD               Active  1010997.0         KC1   \n",
      "KC0002          CD               Active  1010997.0         KC1   \n",
      "KC0003          CD               Active  1010997.0         KC1   \n",
      "KC0005          CD               Active  1010997.0         KC1   \n",
      "KC0001          CD               Active  1010997.0         KC1   \n",
      "CD0001          CD               Active  1010694.0         IL2   \n",
      "CD0002          CD               Active  1010694.0         IL2   \n",
      "CD0003          CD               Active  1010695.0         IL3   \n",
      "CD0004          CD               Active  1010695.0         IL3   \n",
      "\n",
      "           project_owner_id      animal_line sc_process_date  \\\n",
      "lib_id                                                         \n",
      "HH0001              HH_Spin              NaN      05-18-2022   \n",
      "J00002               JMFC01  Tg(lck:lck-GFP)      03-01-2022   \n",
      "J00003               JMFC02  Tg(lck:lck-GFP)      03-01-2022   \n",
      "J00004               JMFC03  Tg(lck:lck-GFP)      03-01-2022   \n",
      "J00005               JMFC04  Tg(lck:lck-GFP)      04-01-2022   \n",
      "LC0001       Severe CD PBMC              NaN      04-01-2022   \n",
      "LC0002       Severe CD PBMC              NaN      04-01-2022   \n",
      "LC0003                    1              NaN      07-11-2022   \n",
      "LC0004                    1              NaN      07-11-2022   \n",
      "LC0005                    2              NaN      07-11-2022   \n",
      "LC0006                    2              NaN      07-11-2022   \n",
      "RL0001              AA4_Inf              NaN      05-01-2021   \n",
      "RL0001_re           AA4_Inf              NaN      05-01-2021   \n",
      "RL0002               A4_Non              NaN      05-01-2021   \n",
      "RL0002_re            A4_Non              NaN      05-01-2021   \n",
      "RL0003              EA2_Inf              NaN      06-01-2021   \n",
      "RL0004              EA2_Non              NaN      06-01-2021   \n",
      "RL0005              AA5_Inf              NaN      06-01-2021   \n",
      "RL0006              AA5_Non              NaN      06-01-2021   \n",
      "RL0007              AA5_Inf              NaN      06-01-2021   \n",
      "RL0008              AA5_Non              NaN      06-01-2021   \n",
      "RL0009              AA5_Inf              NaN      06-01-2021   \n",
      "RL0010              AA5_Non              NaN      06-01-2021   \n",
      "RL0011           EA3_Rectum              NaN      07-01-2021   \n",
      "RL0012              EA3_Non              NaN      07-01-2021   \n",
      "RL0013           EA3_Rectum              NaN      07-01-2021   \n",
      "RL0014              EA3_Non              NaN      07-01-2021   \n",
      "RL0015           EA3_Rectum              NaN      07-01-2021   \n",
      "RL0016              EA3_Non              NaN      07-01-2021   \n",
      "RL0017           AA6_Rectum              NaN      08-01-2021   \n",
      "RL0018              AA6_Non              NaN      08-01-2021   \n",
      "RL0019           EA4_Rectum              NaN      09-01-2021   \n",
      "RL0020              EA4_Non              NaN      09-01-2021   \n",
      "RL0021           AA7_Rectum              NaN      09-01-2021   \n",
      "RL0022              AA7_Non              NaN      09-01-2021   \n",
      "RL0023           AA8_Rectum              NaN      09-01-2021   \n",
      "RL0024              AA8_Non              NaN      09-01-2021   \n",
      "RL0025           AA8_Rectum              NaN      09-01-2021   \n",
      "RL0026              AA8_Non              NaN      09-01-2021   \n",
      "RL0027           AA8_Rectum              NaN      09-01-2021   \n",
      "RL0028              AA8_Non              NaN      09-01-2021   \n",
      "RL0029             EA5_Rect              NaN      09-01-2021   \n",
      "RL0030              EA5_Non              NaN      09-01-2021   \n",
      "RL0031             EA5_Rect              NaN      09-01-2021   \n",
      "RL0032              EA5_Non              NaN      09-01-2021   \n",
      "RL0033             EA5_Rect              NaN      09-01-2021   \n",
      "RL0034              EA5_Non              NaN      09-01-2021   \n",
      "RL0035             SA1_Rect              NaN      10-01-2021   \n",
      "RL0036          SA1_Fistula              NaN      10-01-2021   \n",
      "RL0037             EA6_Rect              NaN      04-01-2022   \n",
      "RL0038              EA6_Non              NaN      04-01-2022   \n",
      "RL0039             EA6_Rect              NaN      04-01-2022   \n",
      "RL0040              EA6_Non              NaN      04-01-2022   \n",
      "RL0041             EA6_Rect              NaN      04-01-2022   \n",
      "RL0042              EA6_Non              NaN      04-01-2022   \n",
      "RL0043             AA9_Rect              NaN      04-01-2022   \n",
      "RL0044              AA9_Non              NaN      04-01-2022   \n",
      "RL0045             AA9_Rect              NaN      04-01-2022   \n",
      "RL0046              AA9_Non              NaN      04-01-2022   \n",
      "RL0047             AA9_Rect              NaN      04-01-2022   \n",
      "RL0048              AA9_Non              NaN      04-01-2022   \n",
      "RL0049             EA7_Rect              NaN      06-01-2022   \n",
      "RL0050          EA7_Fistula              NaN      06-01-2022   \n",
      "RL0051             EA8_Rect              NaN      12-01-2022   \n",
      "RL0052             EA8_Rect              NaN      12-01-2022   \n",
      "RL0053          EA8_Fistula              NaN      12-01-2022   \n",
      "RL0054             EA8_Rect              NaN      12-01-2022   \n",
      "SN0001                SNBD1               WT      06-01-2021   \n",
      "SN0002                SNBD2               WT      06-01-2021   \n",
      "SN0003                SNBD3               WT      06-01-2021   \n",
      "SN0004                SNBD4               WT      06-01-2021   \n",
      "SN0005                SNBD5          nod2-/-      06-01-2021   \n",
      "SN0006                SNBD6          nod2-/-      06-01-2021   \n",
      "SN0007                SNBD7          nod2-/-      06-01-2021   \n",
      "SN0008                SNBD8          nod2-/-      06-01-2021   \n",
      "SN0009                SNBD9               WT      07-01-2021   \n",
      "SN0010               SNBD10               WT      07-01-2021   \n",
      "SN0011               SNBD11               WT      07-01-2021   \n",
      "SN0012               SNBD12               WT      07-01-2021   \n",
      "SN0013                 SN13              NaN      09-01-2021   \n",
      "SN0014                 SN14              NaN      09-01-2021   \n",
      "UC0001     UC_ZC_sc_1_uninf              NaN      03-24-2021   \n",
      "UC0002       UC_ZC_sc_1_inf              NaN      03-24-2021   \n",
      "UC0003     UC_ZC_sc_2_uninf              NaN      03-24-2021   \n",
      "UC0004       UC_ZC_sc_2_inf              NaN      03-24-2021   \n",
      "NH0001                KO 2n         Nox1 -/-      02-01-2020   \n",
      "NH0002                KO 2p         Nox1 -/-      02-01-2020   \n",
      "NH0003                KO 4n         Nox1 -/-      02-01-2020   \n",
      "NH0004                KO 4p         Nox1 -/-      02-01-2020   \n",
      "NH0005                WT 1n               WT      02-01-2020   \n",
      "NH0006                WT 1p               WT      02-01-2020   \n",
      "NH0007                WT 3n               WT      02-01-2020   \n",
      "NH0008                WT 3p               WT      02-01-2020   \n",
      "NH0009             91 (INF)              NaN      01-01-2017   \n",
      "NH0010           93 (UnInf)              NaN      01-01-2017   \n",
      "NH0011                Cho1R              NaN      06-01-2018   \n",
      "NH0012                Cho1S              NaN      06-01-2018   \n",
      "NH0013               726INF              NaN      07-01-2018   \n",
      "NH0014                726UN              NaN      07-01-2018   \n",
      "NH0015                Cho4R              NaN      10-01-2018   \n",
      "NH0016                Cho4S              NaN      10-01-2018   \n",
      "QQ0001                  158              NaN      03-01-2017   \n",
      "QQ0002                  159              NaN      03-01-2017   \n",
      "QQ0003                  157              NaN      03-01-2017   \n",
      "QQ0004                  180              NaN      05-01-2017   \n",
      "QQ0005                  181              NaN      05-01-2017   \n",
      "QQ0006                  179              NaN      05-01-2017   \n",
      "QQ0007                  186              NaN      05-01-2017   \n",
      "QQ0008                  187              NaN      05-01-2017   \n",
      "QQ0009                  185              NaN      05-01-2017   \n",
      "QQ0010                  189              NaN      07-01-2017   \n",
      "QQ0011                  190              NaN      07-01-2017   \n",
      "QQ0012                  192              NaN      08-01-2017   \n",
      "QQ0013                  193              NaN      08-01-2017   \n",
      "QQ0014                  191              NaN      08-01-2017   \n",
      "QQ0015                  195              NaN      11-01-2017   \n",
      "QQ0016                  196              NaN      11-01-2017   \n",
      "QQ0017                  208              NaN      12-01-2017   \n",
      "QQ0018                  209              NaN      12-01-2017   \n",
      "QQ0019                   68              NaN      12-01-2016   \n",
      "QQ0020                   69              NaN      12-01-2016   \n",
      "QQ0021                   67              NaN      12-01-2016   \n",
      "QQ0022                  123              NaN      02-01-2017   \n",
      "QQ0023                  126              NaN      02-01-2017   \n",
      "QQ0024                  122              NaN      02-01-2017   \n",
      "QQ0025                  128              NaN      02-01-2017   \n",
      "QQ0026                  129              NaN      02-01-2017   \n",
      "QQ0027                  127              NaN      02-01-2017   \n",
      "QQ0028                  135              NaN      03-01-2017   \n",
      "QQ0029                  138              NaN      03-01-2017   \n",
      "QQ0030                  134              NaN      03-01-2017   \n",
      "QQ0031     JUCH09 (HIMC ID)              NaN      10-01-2020   \n",
      "QQ0032     JUCH09 (HIMC ID)              NaN      10-01-2020   \n",
      "QQ0033                  NaN              NaN      08-01-2020   \n",
      "QQ0034                  NaN              NaN      08-01-2020   \n",
      "AA1inf              AA1_Inf              NaN      09-01-2020   \n",
      "AA1non              AA1_Non              NaN      09-01-2020   \n",
      "QQ0035                 FC03               WT      02-01-2022   \n",
      "QQ0036               FCJM02  Tg(lck:lck-GFP)      03-01-2022   \n",
      "QQ0037               FCJM04  Tg(lck:lck-GFP)      03-01-2022   \n",
      "QQ0038                 FC04               WT      02-01-2022   \n",
      "QQ0039                 FC02               WT      02-01-2022   \n",
      "QQ0040               FCJM03  Tg(lck:lck-GFP)      03-01-2022   \n",
      "QQ0041                 FC01               WT      02-01-2022   \n",
      "QQ0042                 FC05               WT      02-01-2022   \n",
      "QQ0043               FCJM01  Tg(lck:lck-GFP)      03-01-2022   \n",
      "QQ0044               SNJM04          nod2-/-      07-01-2020   \n",
      "QQ0045               SNJM02          nod2-/-      07-01-2020   \n",
      "QQ0046               SNJM10          nod2-/-      07-01-2020   \n",
      "QQ0047               SNJM09          nod2-/-      07-01-2020   \n",
      "QQ0048               SNJM08          nod2-/-      07-01-2020   \n",
      "QQ0049               SNJCZ2               WT      03-01-2018   \n",
      "QQ0050               SNJCZ1               WT      03-01-2018   \n",
      "QQ0051                SNZF2               WT      03-01-2018   \n",
      "QQ0052                SNZF1               WT      03-01-2018   \n",
      "QQ0053               SNJC02               WT      08-01-2017   \n",
      "QQ0054               SNJC01               WT      08-01-2017   \n",
      "QQ0055               SNJM03               WT      07-01-2020   \n",
      "QQ0056               SNJM01               WT      07-01-2020   \n",
      "QQ0057               SNJM07               WT      07-01-2020   \n",
      "QQ0058               SNJM06               WT      07-01-2020   \n",
      "QQ0059               SNJM05               WT      07-01-2020   \n",
      "KC0004         KC4_inf_abbv              NaN      10-01-2022   \n",
      "KC0002              KC2_inf              NaN      10-01-2022   \n",
      "KC0003          KC3_inf_jq1              NaN      10-01-2022   \n",
      "KC0005        KC5_inf_MS402              NaN      10-01-2022   \n",
      "KC0001           KC1_Notinf              NaN      10-01-2022   \n",
      "CD0001                 FC01              NaN      03-01-2021   \n",
      "CD0002                 FC02              NaN      03-01-2021   \n",
      "CD0003                 FC03              NaN      03-01-2021   \n",
      "CD0004                 FC04              NaN      03-01-2021   \n",
      "\n",
      "                   type_of_experiment  x_chem_version_sc   standard_sample_id  \\\n",
      "lib_id                                                                          \n",
      "HH0001                          scRNA                3.1      HH_Hu_MO13_Spin   \n",
      "J00002                          scRNA                3.1        JM_Ze_Lck_Non   \n",
      "J00003                          scRNA                3.1      JM_Ze_Lck_GMCSF   \n",
      "J00004                          scRNA                3.1        JM_Ze_Lck_DSS   \n",
      "J00005                          scRNA                3.1  JM_Ze_Lck_DSS_GMCSF   \n",
      "LC0001     Multiome - Gene Expression                1.0          FC_Hu_sCD_1   \n",
      "LC0002                Multiome - ATAC                1.0          FC_Hu_sCD_1   \n",
      "LC0003     Multiome - Gene Expression                1.0          FC_Hu_sUC_1   \n",
      "LC0004                Multiome - ATAC                1.0          FC_Hu_sUC_1   \n",
      "LC0005     Multiome - Gene Expression                1.0           FC_Hu_sH_1   \n",
      "LC0006                Multiome - ATAC                1.0           FC_Hu_sH_1   \n",
      "RL0001                          scRNA                3.1        RL_Hu_AA2_Inf   \n",
      "RL0001_re                       scRNA                3.1        RL_Hu_AA2_Inf   \n",
      "RL0002                          scRNA                3.1        RL_Hu_AA2_Non   \n",
      "RL0002_re                       scRNA                3.1        RL_Hu_AA2_Non   \n",
      "RL0003                          scRNA                3.1        RL_Hu_EA1_Inf   \n",
      "RL0004                          scRNA                3.1        RL_Hu_EA1_Non   \n",
      "RL0005                          scRNA                3.1        RL_Hu_AA3_Inf   \n",
      "RL0006                          scRNA                3.1        RL_Hu_AA3_Non   \n",
      "RL0007     Multiome - Gene Expression                1.0        RL_Hu_AA3_Inf   \n",
      "RL0008     Multiome - Gene Expression                1.0        RL_Hu_AA3_Non   \n",
      "RL0009                Multiome - ATAC                1.0        RL_Hu_AA3_Inf   \n",
      "RL0010                Multiome - ATAC                1.0        RL_Hu_AA3_Non   \n",
      "RL0011                          scRNA                3.1       RL_Hu_EA2_Rect   \n",
      "RL0012                          scRNA                3.1        RL_Hu_EA2_Non   \n",
      "RL0013     Multiome - Gene Expression                1.0       RL_Hu_EA2_Rect   \n",
      "RL0014     Multiome - Gene Expression                1.0        RL_Hu_EA2_Non   \n",
      "RL0015                Multiome - ATAC                1.0       RL_Hu_EA2_Rect   \n",
      "RL0016                Multiome - ATAC                1.0        RL_Hu_EA2_Non   \n",
      "RL0017                          scRNA                3.1        RL_Hu_AA4_Inf   \n",
      "RL0018                          scRNA                3.1        RL_Hu_AA4_Non   \n",
      "RL0019                          scRNA                3.1       RL_Hu_EA3_Rect   \n",
      "RL0020                          scRNA                3.1        RL_Hu_EA3_Non   \n",
      "RL0021                          scRNA                3.1       RL_Hu_AA5_Rect   \n",
      "RL0022                          scRNA                3.1        RL_Hu_AA5_Non   \n",
      "RL0023                          scRNA                3.1       RL_Hu_AA6_Rect   \n",
      "RL0024                          scRNA                3.1        RL_Hu_AA6_Non   \n",
      "RL0025     Multiome - Gene Expression                1.0       RL_Hu_AA6_Rect   \n",
      "RL0026     Multiome - Gene Expression                1.0        RL_Hu_AA6_Non   \n",
      "RL0027                Multiome - ATAC                1.0       RL_Hu_AA6_Rect   \n",
      "RL0028                Multiome - ATAC                1.0        RL_Hu_AA6_Non   \n",
      "RL0029                          scRNA                3.1       RL_Hu_EA4_Rect   \n",
      "RL0030                          scRNA                3.1        RL_Hu_EA4_Non   \n",
      "RL0031     Multiome - Gene Expression                1.0       RL_Hu_EA4_Rect   \n",
      "RL0032     Multiome - Gene Expression                1.0        RL_Hu_EA4_Non   \n",
      "RL0033                Multiome - ATAC                1.0       RL_Hu_EA4_Rect   \n",
      "RL0034                Multiome - ATAC                1.0        RL_Hu_EA4_Non   \n",
      "RL0035                          scRNA                3.1       RL_Hu_SA1_Rect   \n",
      "RL0036                          scRNA                3.1          RL_Hu_SA1_F   \n",
      "RL0037     Multiome - Gene Expression                1.0       RL_Hu_EA5_Rect   \n",
      "RL0038     Multiome - Gene Expression                1.0        RL_Hu_EA5_Non   \n",
      "RL0039                Multiome - ATAC                1.0       RL_Hu_EA5_Rect   \n",
      "RL0040                Multiome - ATAC                1.0        RL_Hu_EA5_Non   \n",
      "RL0041                          scRNA                3.1       RL_Hu_EA5_Rect   \n",
      "RL0042                          scRNA                3.1        RL_Hu_EA5_Non   \n",
      "RL0043     Multiome - Gene Expression                1.0       RL_Hu_AA7_Rect   \n",
      "RL0044     Multiome - Gene Expression                1.0        RL_Hu_AA7_Non   \n",
      "RL0045                Multiome - ATAC                1.0       RL_Hu_AA7_Rect   \n",
      "RL0046                Multiome - ATAC                1.0        RL_Hu_AA7_Non   \n",
      "RL0047                          scRNA                3.1       RL_Hu_AA7_Rect   \n",
      "RL0048                          scRNA                3.1        RL_Hu_AA7_Non   \n",
      "RL0049                          scRNA                3.1       RL_Hu_EA6_Rect   \n",
      "RL0050                          scRNA                3.1          RL_Hu_EA6_F   \n",
      "RL0051     Multiome - Gene Expression                1.0          RL_Hu_EA7_R   \n",
      "RL0052                Multiome - ATAC                1.0          RL_Hu_EA7_R   \n",
      "RL0053                          scRNA                3.1          RL_Hu_EA7_F   \n",
      "RL0054                          scRNA                3.1          RL_Hu_EA7_R   \n",
      "SN0001                          scRNA                3.1         SN_Ze_WT_Non   \n",
      "SN0002                          scRNA                3.1         SN_Ze_WT_DSS   \n",
      "SN0003                          scRNA                3.1          SN_Ze_WT_Co   \n",
      "SN0004                          scRNA                3.1         SN_Ze_WT_BZA   \n",
      "SN0005                          scRNA                3.1       SN_Ze_nod2_Non   \n",
      "SN0006                          scRNA                3.1       SN_Ze_nod2_DSS   \n",
      "SN0007                          scRNA                3.1        SN_Ze_nod2_Co   \n",
      "SN0008                          scRNA                3.1       SN_Ze_nod2_BZA   \n",
      "SN0009                          scRNA                3.1        SN_Ze_WT2_Non   \n",
      "SN0010                          scRNA                3.1        SN_Ze_WT2_DSS   \n",
      "SN0011                          scRNA                3.1         SN_Ze_WT2_Co   \n",
      "SN0012                          scRNA                3.1        SN_Ze_WT2_BZA   \n",
      "SN0013                          scRNA                3.1        SN_Hu_P13_Non   \n",
      "SN0014                          scRNA                3.1       SN_Hu_P13_PBMC   \n",
      "UC0001                          scRNA                3.1         ZC_Hu_P1_Non   \n",
      "UC0002                          scRNA                3.1         ZC_Hu_P1_Inf   \n",
      "UC0003                          scRNA                3.1         ZC_Hu_P2_Non   \n",
      "UC0004                          scRNA                3.1         ZC_Hu_P2_Inf   \n",
      "NH0001                          scRNA                3.0        NH_Mo_KO2_Non   \n",
      "NH0002                          scRNA                3.0        NH_Mo_KO2_TNF   \n",
      "NH0003                          scRNA                3.0        NH_Mo_KO4_Non   \n",
      "NH0004                          scRNA                3.0        NH_Mo_KO4_TNF   \n",
      "NH0005                          scRNA                3.0        NH_Mo_WT1_Non   \n",
      "NH0006                          scRNA                3.0        NH_Mo_WT1_TNF   \n",
      "NH0007                          scRNA                3.0        NH_Mo_WT3_Non   \n",
      "NH0008                          scRNA                3.0        NH_Mo_WT3_TNF   \n",
      "NH0009                          scRNA                2.0         NH_Hu_P1_Inf   \n",
      "NH0010                          scRNA                2.0         NH_Hu_P1_Non   \n",
      "NH0011                          scRNA                2.0         NH_Hu_P2_Inf   \n",
      "NH0012                          scRNA                2.0         NH_Hu_P2_Non   \n",
      "NH0013                          scRNA                2.0         NH_Hu_P3_Inf   \n",
      "NH0014                          scRNA                2.0         NH_Hu_P3_Non   \n",
      "NH0015                          scRNA                2.0         NH_Hu_P4_Inf   \n",
      "NH0016                          scRNA                2.0         NH_Hu_P4_Non   \n",
      "QQ0001                          scRNA                2.0        JM_Hu_P10_Inf   \n",
      "QQ0002                          scRNA                2.0        JM_Hu_P10_Non   \n",
      "QQ0003                          scRNA                2.0       JM_Hu_P10_PBMC   \n",
      "QQ0004                          scRNA                2.0        JM_Hu_P11_Inf   \n",
      "QQ0005                          scRNA                2.0        JM_Hu_P11_Non   \n",
      "QQ0006                          scRNA                2.0       JM_Hu_P11_PBMC   \n",
      "QQ0007                          scRNA                2.0        JM_Hu_P12_Inf   \n",
      "QQ0008                          scRNA                2.0        JM_Hu_P12_Non   \n",
      "QQ0009                          scRNA                2.0       JM_Hu_P12_PBMC   \n",
      "QQ0010                          scRNA                2.0        JM_Hu_P13_Inf   \n",
      "QQ0011                          scRNA                2.0        JM_Hu_P13_Non   \n",
      "QQ0012                          scRNA                2.0        JM_Hu_P14_Inf   \n",
      "QQ0013                          scRNA                2.0        JM_Hu_P14_Non   \n",
      "QQ0014                          scRNA                2.0       JM_Hu_P14_PBMC   \n",
      "QQ0015                          scRNA                2.0        JM_Hu_P15_Inf   \n",
      "QQ0016                          scRNA                2.0        JM_Hu_P15_Non   \n",
      "QQ0017                          scRNA                2.0        JM_Hu_P16_Inf   \n",
      "QQ0018                          scRNA                2.0        JM_Hu_P16_Non   \n",
      "QQ0019                          scRNA                1.0         JM_Hu_P5_Inf   \n",
      "QQ0020                          scRNA                1.0         JM_Hu_P5_Non   \n",
      "QQ0021                          scRNA                1.0        JM_Hu_P5_PBMC   \n",
      "QQ0022                          scRNA                2.0         JM_Hu_P6_Inf   \n",
      "QQ0023                          scRNA                2.0         JM_Hu_P6_Non   \n",
      "QQ0024                          scRNA                2.0        JM_Hu_P6_PBMC   \n",
      "QQ0025                          scRNA                2.0         JM_Hu_P7_Inf   \n",
      "QQ0026                          scRNA                2.0         JM_Hu_P7_Non   \n",
      "QQ0027                          scRNA                2.0        JM_Hu_P7_PBMC   \n",
      "QQ0028                          scRNA                2.0         JM_Hu_P8_Inf   \n",
      "QQ0029                          scRNA                2.0         JM_Hu_P8_Non   \n",
      "QQ0030                          scRNA                2.0        JM_Hu_P8_PBMC   \n",
      "QQ0031                       CITE-seq                3.1        FC_Hu_IL1_Inf   \n",
      "QQ0032                       CITE-seq                3.1        FC_Hu_IL1_Non   \n",
      "QQ0033                       CITE-seq                3.1        FC_Hu_AA_PBMC   \n",
      "QQ0034                       CITE-seq                3.1        FC_Hu_EA_PBMC   \n",
      "AA1inf                       CITE-seq                3.1        RL_Hu_AA1_Inf   \n",
      "AA1non                       CITE-seq                3.1        RL_Hu_AA1_Non   \n",
      "QQ0035                          scRNA                3.1         FC_Ze_WT_DSS   \n",
      "QQ0036                          scRNA                3.1         FC_Ze_WT_DSS   \n",
      "QQ0037                          scRNA                3.1  FC_Ze_WT_DSS_hGMCSF   \n",
      "QQ0038                          scRNA                3.1  FC_Ze_WT_DSS-hGMCSF   \n",
      "QQ0039                          scRNA                3.1      FC_Ze_WT_hGMCSF   \n",
      "QQ0040                          scRNA                3.1      FC_Ze_WT_hGMCSF   \n",
      "QQ0041                          scRNA                3.1         FC_Ze_WT_Non   \n",
      "QQ0042                          scRNA                3.1         FC_Ze_WT_Non   \n",
      "QQ0043                          scRNA                3.1         FC_Ze_WT_Non   \n",
      "QQ0044                          scRNA                3.0        SN_Ze_KO1_DSS   \n",
      "QQ0045                          scRNA                3.0        SN_Ze_KO1_Non   \n",
      "QQ0046                          scRNA                3.0        SN_Ze_KO2_BZA   \n",
      "QQ0047                          scRNA                3.0        SN_Ze_KO2_DSS   \n",
      "QQ0048                          scRNA                3.0        SN_Ze_KO2_Non   \n",
      "QQ0049                          scRNA                2.0        SN_Ze_WT1_DSS   \n",
      "QQ0050                          scRNA                2.0        SN_Ze_WT1_Non   \n",
      "QQ0051                          scRNA                2.0        SN_Ze_WT2_DSS   \n",
      "QQ0052                          scRNA                2.0        SN_Ze_WT2_Non   \n",
      "QQ0053                          scRNA                2.0        SN_Ze_WT3_DSS   \n",
      "QQ0054                          scRNA                2.0        SN_Ze_WT3_Non   \n",
      "QQ0055                          scRNA                3.0        SN_Ze_WT4_DSS   \n",
      "QQ0056                          scRNA                3.0        SN_Ze_WT4_Non   \n",
      "QQ0057                          scRNA                3.0        SN_Ze_WT5_BZA   \n",
      "QQ0058                          scRNA                3.0        SN_Ze_WT5_DSS   \n",
      "QQ0059                          scRNA                3.0        SN_Ze_WT5_Non   \n",
      "KC0004                          scRNA                3.1       KC_Hu_CD1_ABBV   \n",
      "KC0002                          scRNA                3.1        KC_Hu_CD1_INF   \n",
      "KC0003                          scRNA                3.1        KC_Hu_CD1_JQ1   \n",
      "KC0005                          scRNA                3.1      KC_Hu_CD1_MS402   \n",
      "KC0001                          scRNA                3.1        KC_Hu_CD1_Not   \n",
      "CD0001                       CITE-seq                3.1        FC_Hu_IL2_Inf   \n",
      "CD0002                       CITE-seq                3.1        FC_Hu_IL2_Non   \n",
      "CD0003                       CITE-seq                3.1        FC_Hu_IL3_Inf   \n",
      "CD0004                       CITE-seq                3.1        FC_Hu_IL3_Non   \n",
      "\n",
      "                       inflam_status inflam_treatment inflam_treatment_type  \\\n",
      "lib_id                                                                        \n",
      "HH0001                  Non-inflamed              NaN                   NaN   \n",
      "J00002                  Non-inflamed              NaN                   NaN   \n",
      "J00003                  Non-inflamed              NaN                   NaN   \n",
      "J00004                Inflamed_acute            acute                   DSS   \n",
      "J00005                Inflamed_acute            acute         DSS + hGM-CSF   \n",
      "LC0001                          PBMC              NaN                   NaN   \n",
      "LC0002                          PBMC              NaN                   NaN   \n",
      "LC0003                          PBMC              NaN                   NaN   \n",
      "LC0004                          PBMC              NaN                   NaN   \n",
      "LC0005                          PBMC              NaN                   NaN   \n",
      "LC0006                          PBMC              NaN                   NaN   \n",
      "RL0001     ~Non-infl. active fistula              NaN                   NaN   \n",
      "RL0001_re  ~Non-infl. active fistula              NaN                   NaN   \n",
      "RL0002                  non-inflamed              NaN                   NaN   \n",
      "RL0002_re               non-inflamed              NaN                   NaN   \n",
      "RL0003                      Inflamed              NaN                   NaN   \n",
      "RL0004                  Non-inflamed              NaN                   NaN   \n",
      "RL0005                      Inflamed              NaN                   NaN   \n",
      "RL0006                  Non-inflamed              NaN                   NaN   \n",
      "RL0007                      Inflamed              NaN                   NaN   \n",
      "RL0008                  Non-inflamed              NaN                   NaN   \n",
      "RL0009                      Inflamed              NaN                   NaN   \n",
      "RL0010                  Non-inflamed              NaN                   NaN   \n",
      "RL0011                  Non-inflamed              NaN                   NaN   \n",
      "RL0012                  Non-inflamed              NaN                   NaN   \n",
      "RL0013                  Non-inflamed              NaN                   NaN   \n",
      "RL0014                  Non-inflamed              NaN                   NaN   \n",
      "RL0015                  Non-inflamed              NaN                   NaN   \n",
      "RL0016                  Non-inflamed              NaN                   NaN   \n",
      "RL0017                      Inflamed              NaN                   NaN   \n",
      "RL0018                  Non-inflamed              NaN                   NaN   \n",
      "RL0019                      Inflamed              NaN                   NaN   \n",
      "RL0020                  Non-inflamed              NaN                   NaN   \n",
      "RL0021                  Non-inflamed              NaN                   NaN   \n",
      "RL0022                  Non-inflamed              NaN                   NaN   \n",
      "RL0023                      Inflamed              NaN                   NaN   \n",
      "RL0024                      Inflamed              NaN                   NaN   \n",
      "RL0025                      Inflamed              NaN                   NaN   \n",
      "RL0026                      Inflamed              NaN                   NaN   \n",
      "RL0027                      Inflamed              NaN                   NaN   \n",
      "RL0028                      Inflamed              NaN                   NaN   \n",
      "RL0029                  Non-inflamed              NaN                   NaN   \n",
      "RL0030                  Non-inflamed              NaN                   NaN   \n",
      "RL0031                  Non-inflamed              NaN                   NaN   \n",
      "RL0032                  Non-inflamed              NaN                   NaN   \n",
      "RL0033                  Non-inflamed              NaN                   NaN   \n",
      "RL0034                  Non-inflamed              NaN                   NaN   \n",
      "RL0035                      Inflamed              NaN                   NaN   \n",
      "RL0036                     Inflamed*              NaN                   NaN   \n",
      "RL0037                  Non-inflamed              NaN                   NaN   \n",
      "RL0038                  Non-inflamed              NaN                   NaN   \n",
      "RL0039                  Non-inflamed              NaN                   NaN   \n",
      "RL0040                  Non-inflamed              NaN                   NaN   \n",
      "RL0041                  Non-inflamed              NaN                   NaN   \n",
      "RL0042                  Non-inflamed              NaN                   NaN   \n",
      "RL0043                      Inflamed              NaN                   NaN   \n",
      "RL0044                      Inflamed              NaN                   NaN   \n",
      "RL0045                      Inflamed              NaN                   NaN   \n",
      "RL0046                      Inflamed              NaN                   NaN   \n",
      "RL0047                      Inflamed              NaN                   NaN   \n",
      "RL0048                      Inflamed              NaN                   NaN   \n",
      "RL0049                      Inflamed              NaN                   NaN   \n",
      "RL0050                      Inflamed              NaN                   NaN   \n",
      "RL0051                      Inflamed              NaN                   NaN   \n",
      "RL0052                      Inflamed              NaN                   NaN   \n",
      "RL0053                      Inflamed              NaN                   NaN   \n",
      "RL0054                      Inflamed              NaN                   NaN   \n",
      "SN0001                  Non-inflamed              NaN                   NaN   \n",
      "SN0002              inflamed_Chronic              NaN                   NaN   \n",
      "SN0003              inflamed_Chronic              NaN                   NaN   \n",
      "SN0004              inflamed_Chronic              NaN                   NaN   \n",
      "SN0005                  Non-inflamed              NaN                   NaN   \n",
      "SN0006              inflamed_Chronic              NaN                   NaN   \n",
      "SN0007              inflamed_Chronic              NaN                   NaN   \n",
      "SN0008              inflamed_Chronic              NaN                   NaN   \n",
      "SN0009                  Non-inflamed              NaN                   NaN   \n",
      "SN0010              inflamed_Chronic              NaN                   NaN   \n",
      "SN0011              inflamed_Chronic              NaN                   NaN   \n",
      "SN0012              inflamed_Chronic              NaN                   NaN   \n",
      "SN0013                  Non-inflamed              NaN                   NaN   \n",
      "SN0014                  Non-inflamed              NaN                   NaN   \n",
      "UC0001                  non-inflamed              NaN                   NaN   \n",
      "UC0002                      inflamed              NaN                   NaN   \n",
      "UC0003                  non-inflamed              NaN                   NaN   \n",
      "UC0004                      inflamed              NaN                   NaN   \n",
      "NH0001                  Non-inflamed              NaN                   NaN   \n",
      "NH0002              Induced inflamed          treated                   TNF   \n",
      "NH0003                  Non-inflamed        untreated                   NaN   \n",
      "NH0004              Induced inflamed          treated                   TNF   \n",
      "NH0005                  Non-inflamed        untreated                   NaN   \n",
      "NH0006              Induced inflamed          treated                   TNF   \n",
      "NH0007                  Non-inflamed        untreated                   NaN   \n",
      "NH0008              Induced inflamed          treated                   TNF   \n",
      "NH0009                      Inflamed              NaN                   NaN   \n",
      "NH0010                  Non-Inflamed              NaN                   NaN   \n",
      "NH0011                      Inflamed              NaN                   NaN   \n",
      "NH0012                  Non-Inflamed              NaN                   NaN   \n",
      "NH0013                      Inflamed              NaN                   NaN   \n",
      "NH0014                  Non-Inflamed              NaN                   NaN   \n",
      "NH0015                      Inflamed              NaN                   NaN   \n",
      "NH0016                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0001                      Inflamed              NaN                   NaN   \n",
      "QQ0002                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0003                      Inflamed              NaN                   NaN   \n",
      "QQ0004                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0005                      Inflamed              NaN                   NaN   \n",
      "QQ0006                      Inflamed              NaN                   NaN   \n",
      "QQ0007                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0008                      Inflamed              NaN                   NaN   \n",
      "QQ0009                      Inflamed              NaN                   NaN   \n",
      "QQ0010                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0011                      Inflamed              NaN                   NaN   \n",
      "QQ0012                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0013                      Inflamed              NaN                   NaN   \n",
      "QQ0014                      Inflamed              NaN                   NaN   \n",
      "QQ0015                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0016                      Inflamed              NaN                   NaN   \n",
      "QQ0017                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0018                      Inflamed              NaN                   NaN   \n",
      "QQ0019                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0020                      Inflamed              NaN                   NaN   \n",
      "QQ0021                      Inflamed              NaN                   NaN   \n",
      "QQ0022                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0023                      Inflamed              NaN                   NaN   \n",
      "QQ0024                      Inflamed              NaN                   NaN   \n",
      "QQ0025                      Inflamed              NaN                   NaN   \n",
      "QQ0026                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0027                      Inflamed              NaN                   NaN   \n",
      "QQ0028                  Non-Inflamed              NaN                   NaN   \n",
      "QQ0029                      Inflamed              NaN                   NaN   \n",
      "QQ0030                      Inflamed              NaN                   NaN   \n",
      "QQ0031                      Inflamed              NaN                   NaN   \n",
      "QQ0032                  Non-inflamed              NaN                   NaN   \n",
      "QQ0033               Healthy Control              NaN                   NaN   \n",
      "QQ0034               Healthy Control              NaN                   NaN   \n",
      "AA1inf                      Inflamed              NaN                   NaN   \n",
      "AA1non                  Non-inflamed              NaN                   NaN   \n",
      "QQ0035                inflamed_acute            acute                   DSS   \n",
      "QQ0036                inflamed_acute            acute                   DSS   \n",
      "QQ0037                inflamed_acute            acute         DSS + hGM-CSF   \n",
      "QQ0038                inflamed_acute            acute         DSS + hGM-CSF   \n",
      "QQ0039                  Non-inflamed        untreated               hGM-CSF   \n",
      "QQ0040                  Non-inflamed        untreated               hGM-CSF   \n",
      "QQ0041                  Non-inflamed        untreated                   NaN   \n",
      "QQ0042                  Non-inflamed        untreated                   NaN   \n",
      "QQ0043                  Non-inflamed        untreated                   NaN   \n",
      "QQ0044                inflamed_acute            acute                   DSS   \n",
      "QQ0045                  Non-inflamed        untreated                   NaN   \n",
      "QQ0046              inflamed_chronic          chronic                   BZA   \n",
      "QQ0047              inflamed_chronic          chronic                   DSS   \n",
      "QQ0048                  Non-inflamed        untreated                   NaN   \n",
      "QQ0049                inflamed_acute            acute                   DSS   \n",
      "QQ0050                  Non-inflamed        untreated                   NaN   \n",
      "QQ0051                inflamed_acute            acute                   DSS   \n",
      "QQ0052                  Non-inflamed        untreated                   NaN   \n",
      "QQ0053                inflamed_acute            acute                   DSS   \n",
      "QQ0054                  Non-inflamed        untreated                   NaN   \n",
      "QQ0055                inflamed_acute            acute                   DSS   \n",
      "QQ0056                  Non-inflamed        untreated                   NaN   \n",
      "QQ0057              inflamed_chronic          chronic                   BZA   \n",
      "QQ0058              inflamed_chronic          chronic                   DSS   \n",
      "QQ0059                  Non-inflamed        untreated                   NaN   \n",
      "KC0004                      Inflamed              NaN                   NaN   \n",
      "KC0002                      Inflamed              NaN                   NaN   \n",
      "KC0003                      Inflamed              NaN                   NaN   \n",
      "KC0005                      Inflamed              NaN                   NaN   \n",
      "KC0001                  Non-Inflamed              NaN                   NaN   \n",
      "CD0001                      Inflamed              NaN                   NaN   \n",
      "CD0002                  Non-inflamed              NaN                   NaN   \n",
      "CD0003                      Inflamed              NaN                   NaN   \n",
      "CD0004                  Non-inflamed              NaN                   NaN   \n",
      "\n",
      "          inflam_treatment_concentration_DSS inflam_treatment_quantity_DSS  \\\n",
      "lib_id                                                                       \n",
      "HH0001                                   NaN                           NaN   \n",
      "J00002                                   NaN                           NaN   \n",
      "J00003                                   NaN                           NaN   \n",
      "J00004                                   NaN                           NaN   \n",
      "J00005                                   NaN                           NaN   \n",
      "LC0001                                   NaN                           NaN   \n",
      "LC0002                                   NaN                           NaN   \n",
      "LC0003                                   NaN                           NaN   \n",
      "LC0004                                   NaN                           NaN   \n",
      "LC0005                                   NaN                           NaN   \n",
      "LC0006                                   NaN                           NaN   \n",
      "RL0001                                   NaN                           NaN   \n",
      "RL0001_re                                NaN                           NaN   \n",
      "RL0002                                   NaN                           NaN   \n",
      "RL0002_re                                NaN                           NaN   \n",
      "RL0003                                   NaN                           NaN   \n",
      "RL0004                                   NaN                           NaN   \n",
      "RL0005                                   NaN                           NaN   \n",
      "RL0006                                   NaN                           NaN   \n",
      "RL0007                                   NaN                           NaN   \n",
      "RL0008                                   NaN                           NaN   \n",
      "RL0009                                   NaN                           NaN   \n",
      "RL0010                                   NaN                           NaN   \n",
      "RL0011                                   NaN                           NaN   \n",
      "RL0012                                   NaN                           NaN   \n",
      "RL0013                                   NaN                           NaN   \n",
      "RL0014                                   NaN                           NaN   \n",
      "RL0015                                   NaN                           NaN   \n",
      "RL0016                                   NaN                           NaN   \n",
      "RL0017                                   NaN                           NaN   \n",
      "RL0018                                   NaN                           NaN   \n",
      "RL0019                                   NaN                           NaN   \n",
      "RL0020                                   NaN                           NaN   \n",
      "RL0021                                   NaN                           NaN   \n",
      "RL0022                                   NaN                           NaN   \n",
      "RL0023                                   NaN                           NaN   \n",
      "RL0024                                   NaN                           NaN   \n",
      "RL0025                                   NaN                           NaN   \n",
      "RL0026                                   NaN                           NaN   \n",
      "RL0027                                   NaN                           NaN   \n",
      "RL0028                                   NaN                           NaN   \n",
      "RL0029                                   NaN                           NaN   \n",
      "RL0030                                   NaN                           NaN   \n",
      "RL0031                                   NaN                           NaN   \n",
      "RL0032                                   NaN                           NaN   \n",
      "RL0033                                   NaN                           NaN   \n",
      "RL0034                                   NaN                           NaN   \n",
      "RL0035                                   NaN                           NaN   \n",
      "RL0036                                   NaN                           NaN   \n",
      "RL0037                                   NaN                           NaN   \n",
      "RL0038                                   NaN                           NaN   \n",
      "RL0039                                   NaN                           NaN   \n",
      "RL0040                                   NaN                           NaN   \n",
      "RL0041                                   NaN                           NaN   \n",
      "RL0042                                   NaN                           NaN   \n",
      "RL0043                                   NaN                           NaN   \n",
      "RL0044                                   NaN                           NaN   \n",
      "RL0045                                   NaN                           NaN   \n",
      "RL0046                                   NaN                           NaN   \n",
      "RL0047                                   NaN                           NaN   \n",
      "RL0048                                   NaN                           NaN   \n",
      "RL0049                                   NaN                           NaN   \n",
      "RL0050                                   NaN                           NaN   \n",
      "RL0051                                   NaN                           NaN   \n",
      "RL0052                                   NaN                           NaN   \n",
      "RL0053                                   NaN                           NaN   \n",
      "RL0054                                   NaN                           NaN   \n",
      "SN0001                                   NaN                           NaN   \n",
      "SN0002                                   NaN                           NaN   \n",
      "SN0003                                   NaN                           NaN   \n",
      "SN0004                                   NaN                           NaN   \n",
      "SN0005                                   NaN                           NaN   \n",
      "SN0006                                   NaN                           NaN   \n",
      "SN0007                                   NaN                           NaN   \n",
      "SN0008                                   NaN                           NaN   \n",
      "SN0009                                   NaN                           NaN   \n",
      "SN0010                                   NaN                           NaN   \n",
      "SN0011                                   NaN                           NaN   \n",
      "SN0012                                   NaN                           NaN   \n",
      "SN0013                                   NaN                           NaN   \n",
      "SN0014                                   NaN                           NaN   \n",
      "UC0001                                   NaN                           NaN   \n",
      "UC0002                                   NaN                           NaN   \n",
      "UC0003                                   NaN                           NaN   \n",
      "UC0004                                   NaN                           NaN   \n",
      "NH0001                                   NaN                           NaN   \n",
      "NH0002                                   NaN                           NaN   \n",
      "NH0003                                   NaN                           NaN   \n",
      "NH0004                                   NaN                           NaN   \n",
      "NH0005                                   NaN                           NaN   \n",
      "NH0006                                   NaN                           NaN   \n",
      "NH0007                                   NaN                           NaN   \n",
      "NH0008                                   NaN                           NaN   \n",
      "NH0009                                   NaN                           NaN   \n",
      "NH0010                                   NaN                           NaN   \n",
      "NH0011                                   NaN                           NaN   \n",
      "NH0012                                   NaN                           NaN   \n",
      "NH0013                                   NaN                           NaN   \n",
      "NH0014                                   NaN                           NaN   \n",
      "NH0015                                   NaN                           NaN   \n",
      "NH0016                                   NaN                           NaN   \n",
      "QQ0001                                   NaN                           NaN   \n",
      "QQ0002                                   NaN                           NaN   \n",
      "QQ0003                                   NaN                           NaN   \n",
      "QQ0004                                   NaN                           NaN   \n",
      "QQ0005                                   NaN                           NaN   \n",
      "QQ0006                                   NaN                           NaN   \n",
      "QQ0007                                   NaN                           NaN   \n",
      "QQ0008                                   NaN                           NaN   \n",
      "QQ0009                                   NaN                           NaN   \n",
      "QQ0010                                   NaN                           NaN   \n",
      "QQ0011                                   NaN                           NaN   \n",
      "QQ0012                                   NaN                           NaN   \n",
      "QQ0013                                   NaN                           NaN   \n",
      "QQ0014                                   NaN                           NaN   \n",
      "QQ0015                                   NaN                           NaN   \n",
      "QQ0016                                   NaN                           NaN   \n",
      "QQ0017                                   NaN                           NaN   \n",
      "QQ0018                                   NaN                           NaN   \n",
      "QQ0019                                   NaN                           NaN   \n",
      "QQ0020                                   NaN                           NaN   \n",
      "QQ0021                                   NaN                           NaN   \n",
      "QQ0022                                   NaN                           NaN   \n",
      "QQ0023                                   NaN                           NaN   \n",
      "QQ0024                                   NaN                           NaN   \n",
      "QQ0025                                   NaN                           NaN   \n",
      "QQ0026                                   NaN                           NaN   \n",
      "QQ0027                                   NaN                           NaN   \n",
      "QQ0028                                   NaN                           NaN   \n",
      "QQ0029                                   NaN                           NaN   \n",
      "QQ0030                                   NaN                           NaN   \n",
      "QQ0031                                   NaN                           NaN   \n",
      "QQ0032                                   NaN                           NaN   \n",
      "QQ0033                                   NaN                           NaN   \n",
      "QQ0034                                   NaN                           NaN   \n",
      "AA1inf                                   NaN                           NaN   \n",
      "AA1non                                   NaN                           NaN   \n",
      "QQ0035                                 0.25%                            1X   \n",
      "QQ0036                                 0.25%                            1X   \n",
      "QQ0037                                 0.25%                            1X   \n",
      "QQ0038                                 0.25%                            1X   \n",
      "QQ0039                                   NaN                           NaN   \n",
      "QQ0040                                   NaN                           NaN   \n",
      "QQ0041                                   NaN                           NaN   \n",
      "QQ0042                                   NaN                           NaN   \n",
      "QQ0043                                   NaN                           NaN   \n",
      "QQ0044                                 0.08%                            1X   \n",
      "QQ0045                                   NaN                           NaN   \n",
      "QQ0046                                   NaN                            2X   \n",
      "QQ0047                                 0.08%                            2X   \n",
      "QQ0048                                   NaN                           NaN   \n",
      "QQ0049                           DSS treated                            ?X   \n",
      "QQ0050                                   NaN                           NaN   \n",
      "QQ0051                           DSS treated                            ?X   \n",
      "QQ0052                                   NaN                           NaN   \n",
      "QQ0053                           DSS treated                            ?X   \n",
      "QQ0054                                   NaN                           NaN   \n",
      "QQ0055                                 0.08%                            1X   \n",
      "QQ0056                                   NaN                           NaN   \n",
      "QQ0057                                 0.08%                            2X   \n",
      "QQ0058                                 0.08%                            2X   \n",
      "QQ0059                                   NaN                           NaN   \n",
      "KC0004                                   NaN                           NaN   \n",
      "KC0002                                   NaN                           NaN   \n",
      "KC0003                                   NaN                           NaN   \n",
      "KC0005                                   NaN                           NaN   \n",
      "KC0001                                   NaN                           NaN   \n",
      "CD0001                                   NaN                           NaN   \n",
      "CD0002                                   NaN                           NaN   \n",
      "CD0003                                   NaN                           NaN   \n",
      "CD0004                                   NaN                           NaN   \n",
      "\n",
      "          inflam_treatment_quantity_hGMCSF inflam_treatment_quantity_BZA  \\\n",
      "lib_id                                                                     \n",
      "HH0001                                 NaN                           NaN   \n",
      "J00002                                 NaN                           NaN   \n",
      "J00003                                 NaN                           NaN   \n",
      "J00004                                 NaN                           NaN   \n",
      "J00005                                 NaN                           NaN   \n",
      "LC0001                                 NaN                           NaN   \n",
      "LC0002                                 NaN                           NaN   \n",
      "LC0003                                 NaN                           NaN   \n",
      "LC0004                                 NaN                           NaN   \n",
      "LC0005                                 NaN                           NaN   \n",
      "LC0006                                 NaN                           NaN   \n",
      "RL0001                                 NaN                           NaN   \n",
      "RL0001_re                              NaN                           NaN   \n",
      "RL0002                                 NaN                           NaN   \n",
      "RL0002_re                              NaN                           NaN   \n",
      "RL0003                                 NaN                           NaN   \n",
      "RL0004                                 NaN                           NaN   \n",
      "RL0005                                 NaN                           NaN   \n",
      "RL0006                                 NaN                           NaN   \n",
      "RL0007                                 NaN                           NaN   \n",
      "RL0008                                 NaN                           NaN   \n",
      "RL0009                                 NaN                           NaN   \n",
      "RL0010                                 NaN                           NaN   \n",
      "RL0011                                 NaN                           NaN   \n",
      "RL0012                                 NaN                           NaN   \n",
      "RL0013                                 NaN                           NaN   \n",
      "RL0014                                 NaN                           NaN   \n",
      "RL0015                                 NaN                           NaN   \n",
      "RL0016                                 NaN                           NaN   \n",
      "RL0017                                 NaN                           NaN   \n",
      "RL0018                                 NaN                           NaN   \n",
      "RL0019                                 NaN                           NaN   \n",
      "RL0020                                 NaN                           NaN   \n",
      "RL0021                                 NaN                           NaN   \n",
      "RL0022                                 NaN                           NaN   \n",
      "RL0023                                 NaN                           NaN   \n",
      "RL0024                                 NaN                           NaN   \n",
      "RL0025                                 NaN                           NaN   \n",
      "RL0026                                 NaN                           NaN   \n",
      "RL0027                                 NaN                           NaN   \n",
      "RL0028                                 NaN                           NaN   \n",
      "RL0029                                 NaN                           NaN   \n",
      "RL0030                                 NaN                           NaN   \n",
      "RL0031                                 NaN                           NaN   \n",
      "RL0032                                 NaN                           NaN   \n",
      "RL0033                                 NaN                           NaN   \n",
      "RL0034                                 NaN                           NaN   \n",
      "RL0035                                 NaN                           NaN   \n",
      "RL0036                                 NaN                           NaN   \n",
      "RL0037                                 NaN                           NaN   \n",
      "RL0038                                 NaN                           NaN   \n",
      "RL0039                                 NaN                           NaN   \n",
      "RL0040                                 NaN                           NaN   \n",
      "RL0041                                 NaN                           NaN   \n",
      "RL0042                                 NaN                           NaN   \n",
      "RL0043                                 NaN                           NaN   \n",
      "RL0044                                 NaN                           NaN   \n",
      "RL0045                                 NaN                           NaN   \n",
      "RL0046                                 NaN                           NaN   \n",
      "RL0047                                 NaN                           NaN   \n",
      "RL0048                                 NaN                           NaN   \n",
      "RL0049                                 NaN                           NaN   \n",
      "RL0050                                 NaN                           NaN   \n",
      "RL0051                                 NaN                           NaN   \n",
      "RL0052                                 NaN                           NaN   \n",
      "RL0053                                 NaN                           NaN   \n",
      "RL0054                                 NaN                           NaN   \n",
      "SN0001                                 NaN                           NaN   \n",
      "SN0002                                 NaN                           NaN   \n",
      "SN0003                                 NaN                           NaN   \n",
      "SN0004                                 NaN                           NaN   \n",
      "SN0005                                 NaN                           NaN   \n",
      "SN0006                                 NaN                           NaN   \n",
      "SN0007                                 NaN                           NaN   \n",
      "SN0008                                 NaN                           NaN   \n",
      "SN0009                                 NaN                           NaN   \n",
      "SN0010                                 NaN                           NaN   \n",
      "SN0011                                 NaN                           NaN   \n",
      "SN0012                                 NaN                           NaN   \n",
      "SN0013                                 NaN                           NaN   \n",
      "SN0014                                 NaN                           NaN   \n",
      "UC0001                                 NaN                           NaN   \n",
      "UC0002                                 NaN                           NaN   \n",
      "UC0003                                 NaN                           NaN   \n",
      "UC0004                                 NaN                           NaN   \n",
      "NH0001                                 NaN                           NaN   \n",
      "NH0002                                 NaN                           NaN   \n",
      "NH0003                                 NaN                           NaN   \n",
      "NH0004                                 NaN                           NaN   \n",
      "NH0005                                 NaN                           NaN   \n",
      "NH0006                                 NaN                           NaN   \n",
      "NH0007                                 NaN                           NaN   \n",
      "NH0008                                 NaN                           NaN   \n",
      "NH0009                                 NaN                           NaN   \n",
      "NH0010                                 NaN                           NaN   \n",
      "NH0011                                 NaN                           NaN   \n",
      "NH0012                                 NaN                           NaN   \n",
      "NH0013                                 NaN                           NaN   \n",
      "NH0014                                 NaN                           NaN   \n",
      "NH0015                                 NaN                           NaN   \n",
      "NH0016                                 NaN                           NaN   \n",
      "QQ0001                                 NaN                           NaN   \n",
      "QQ0002                                 NaN                           NaN   \n",
      "QQ0003                                 NaN                           NaN   \n",
      "QQ0004                                 NaN                           NaN   \n",
      "QQ0005                                 NaN                           NaN   \n",
      "QQ0006                                 NaN                           NaN   \n",
      "QQ0007                                 NaN                           NaN   \n",
      "QQ0008                                 NaN                           NaN   \n",
      "QQ0009                                 NaN                           NaN   \n",
      "QQ0010                                 NaN                           NaN   \n",
      "QQ0011                                 NaN                           NaN   \n",
      "QQ0012                                 NaN                           NaN   \n",
      "QQ0013                                 NaN                           NaN   \n",
      "QQ0014                                 NaN                           NaN   \n",
      "QQ0015                                 NaN                           NaN   \n",
      "QQ0016                                 NaN                           NaN   \n",
      "QQ0017                                 NaN                           NaN   \n",
      "QQ0018                                 NaN                           NaN   \n",
      "QQ0019                                 NaN                           NaN   \n",
      "QQ0020                                 NaN                           NaN   \n",
      "QQ0021                                 NaN                           NaN   \n",
      "QQ0022                                 NaN                           NaN   \n",
      "QQ0023                                 NaN                           NaN   \n",
      "QQ0024                                 NaN                           NaN   \n",
      "QQ0025                                 NaN                           NaN   \n",
      "QQ0026                                 NaN                           NaN   \n",
      "QQ0027                                 NaN                           NaN   \n",
      "QQ0028                                 NaN                           NaN   \n",
      "QQ0029                                 NaN                           NaN   \n",
      "QQ0030                                 NaN                           NaN   \n",
      "QQ0031                                 NaN                           NaN   \n",
      "QQ0032                                 NaN                           NaN   \n",
      "QQ0033                                 NaN                           NaN   \n",
      "QQ0034                                 NaN                           NaN   \n",
      "AA1inf                                 NaN                           NaN   \n",
      "AA1non                                 NaN                           NaN   \n",
      "QQ0035                                 NaN                           NaN   \n",
      "QQ0036                                 NaN                           NaN   \n",
      "QQ0037                               350nM                           NaN   \n",
      "QQ0038                               350nM                           NaN   \n",
      "QQ0039                               350nM                           NaN   \n",
      "QQ0040                               350nM                           NaN   \n",
      "QQ0041                                 NaN                           NaN   \n",
      "QQ0042                                 NaN                           NaN   \n",
      "QQ0043                                 NaN                           NaN   \n",
      "QQ0044                                 NaN                           NaN   \n",
      "QQ0045                                 NaN                           NaN   \n",
      "QQ0046                                 NaN                          10uM   \n",
      "QQ0047                                 NaN                           NaN   \n",
      "QQ0048                                 NaN                           NaN   \n",
      "QQ0049                                 NaN                           NaN   \n",
      "QQ0050                                 NaN                           NaN   \n",
      "QQ0051                                 NaN                           NaN   \n",
      "QQ0052                                 NaN                           NaN   \n",
      "QQ0053                                 NaN                           NaN   \n",
      "QQ0054                                 NaN                           NaN   \n",
      "QQ0055                                 NaN                           NaN   \n",
      "QQ0056                                 NaN                           NaN   \n",
      "QQ0057                                 NaN                          10uM   \n",
      "QQ0058                                 NaN                           NaN   \n",
      "QQ0059                                 NaN                           NaN   \n",
      "KC0004                                 NaN                           NaN   \n",
      "KC0002                                 NaN                           NaN   \n",
      "KC0003                                 NaN                           NaN   \n",
      "KC0005                                 NaN                           NaN   \n",
      "KC0001                                 NaN                           NaN   \n",
      "CD0001                                 NaN                           NaN   \n",
      "CD0002                                 NaN                           NaN   \n",
      "CD0003                                 NaN                           NaN   \n",
      "CD0004                                 NaN                           NaN   \n",
      "\n",
      "                                                             tissue_origin  \\\n",
      "lib_id                                                                       \n",
      "HH0001                                                                PBMC   \n",
      "J00002     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "J00003     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "J00004     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "J00005     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "LC0001                                                                PBMC   \n",
      "LC0002                                                                PBMC   \n",
      "LC0003                                                                PBMC   \n",
      "LC0004                                                                PBMC   \n",
      "LC0005                                                                PBMC   \n",
      "LC0006                                                                PBMC   \n",
      "RL0001                                                              Rectum   \n",
      "RL0001_re                                                           Rectum   \n",
      "RL0002                                                             Sigmoid   \n",
      "RL0002_re                                                          Sigmoid   \n",
      "RL0003                                       Rectum, proctectomy, biopsies   \n",
      "RL0004                                      Sigmoid, proctectomy, biopsies   \n",
      "RL0005                                       Rectum, colonoscopy, biopsies   \n",
      "RL0006                               Terminal ileum, colonoscopy, biopsies   \n",
      "RL0007                                       Rectum, colonoscopy, biopsies   \n",
      "RL0008                               Terminal ileum, colonoscopy, biopsies   \n",
      "RL0009                                       Rectum, colonoscopy, biopsies   \n",
      "RL0010                               Terminal ileum, colonoscopy, biopsies   \n",
      "RL0011                                       Rectum, colonoscopy, biopsies   \n",
      "RL0012                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0013                                       Rectum, colonoscopy, biopsies   \n",
      "RL0014                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0015                                       Rectum, colonoscopy, biopsies   \n",
      "RL0016                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0017                                       Rectum, colonoscopy, biopsies   \n",
      "RL0018                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0019                                       Rectum, colonoscopy, biopsies   \n",
      "RL0020                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0021                                       Rectum, colonoscopy, biopsies   \n",
      "RL0022                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0023                                       Rectum, colonoscopy, biopsies   \n",
      "RL0024                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0025                                       Rectum, colonoscopy, biopsies   \n",
      "RL0026                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0027                                       Rectum, colonoscopy, biopsies   \n",
      "RL0028                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0029                                       Rectum, colonoscopy, biopsies   \n",
      "RL0030                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0031                                       Rectum, colonoscopy, biopsies   \n",
      "RL0032                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0033                                       Rectum, colonoscopy, biopsies   \n",
      "RL0034                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0035                                      Rectum, proectectomy, biopsies   \n",
      "RL0036                         Fistula tract lining, proctectomy, biopsies   \n",
      "RL0037                                       Rectum, colonoscopy, biopsies   \n",
      "RL0038                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0039                                       Rectum, colonoscopy, biopsies   \n",
      "RL0040                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0041                                       Rectum, colonoscopy, biopsies   \n",
      "RL0042                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0043                                       Rectum, colonoscopy, biopsies   \n",
      "RL0044                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0045                                       Rectum, colonoscopy, biopsies   \n",
      "RL0046                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0047                                       Rectum, colonoscopy, biopsies   \n",
      "RL0048                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0049                                    Rectum, proctectomy --> biopsies   \n",
      "RL0050                                   Fistula, proctectomy --> biopsies   \n",
      "RL0051                                    Rectum, proctectomy --> biopsies   \n",
      "RL0052                                    Rectum, proctectomy --> biopsies   \n",
      "RL0053                                   Fistula, proctectomy --> biopsies   \n",
      "RL0054                                    Rectum, proctectomy --> biopsies   \n",
      "SN0001                                        Larval intestinal dissection   \n",
      "SN0002                                        Larval intestinal dissection   \n",
      "SN0003                                        Larval intestinal dissection   \n",
      "SN0004                                        Larval intestinal dissection   \n",
      "SN0005                                        Larval intestinal dissection   \n",
      "SN0006                                        Larval intestinal dissection   \n",
      "SN0007                                        Larval intestinal dissection   \n",
      "SN0008                                        Larval intestinal dissection   \n",
      "SN0009                                        Larval intestinal dissection   \n",
      "SN0010                                        Larval intestinal dissection   \n",
      "SN0011                                        Larval intestinal dissection   \n",
      "SN0012                                        Larval intestinal dissection   \n",
      "SN0013                                                      Terminal ileum   \n",
      "SN0014                                                               PBMCs   \n",
      "UC0001                                                     sigmoid, biopsy   \n",
      "UC0002                                                      rectum, biopsy   \n",
      "UC0003                                            Transverse Colon, biopsy   \n",
      "UC0004                                                      rectum, biopsy   \n",
      "NH0001                                        Colon organoid (excl. cecum)   \n",
      "NH0002                                        Colon organoid (excl. cecum)   \n",
      "NH0003                                        Colon organoid (excl. cecum)   \n",
      "NH0004                                        Colon organoid (excl. cecum)   \n",
      "NH0005                                        Colon organoid (excl. cecum)   \n",
      "NH0006                                        Colon organoid (excl. cecum)   \n",
      "NH0007                                        Colon organoid (excl. cecum)   \n",
      "NH0008                                        Colon organoid (excl. cecum)   \n",
      "NH0009                                       Rectum (10cm)-Inflamed Biopsy   \n",
      "NH0010                                   Sigmoid (35cm)- Uninflamed Biopsy   \n",
      "NH0011                                       Rectum (10cm)-Inflamed Biopsy   \n",
      "NH0012                                   Sigmoid (35cm)- Uninflamed Biopsy   \n",
      "NH0013                                     Rectum (10cm)-  Inflamed Biopsy   \n",
      "NH0014                                   Sigmoid (25cm)- Uninflamed Biopsy   \n",
      "NH0015                                     Rectum (10cm)-  Inflamed Biopsy   \n",
      "NH0016                                   Sigmoid (35cm)- Uninflamed Biopsy   \n",
      "QQ0001                                                     Ileum resection   \n",
      "QQ0002                                                     Ileum resection   \n",
      "QQ0003                                                                PBMC   \n",
      "QQ0004                                                     Ileum resection   \n",
      "QQ0005                                                     Ileum resection   \n",
      "QQ0006                                                                PBMC   \n",
      "QQ0007                                                     Ileum resection   \n",
      "QQ0008                                                     Ileum resection   \n",
      "QQ0009                                                                PBMC   \n",
      "QQ0010                                                     Ileum resection   \n",
      "QQ0011                                                     Ileum resection   \n",
      "QQ0012                                                     Ileum resection   \n",
      "QQ0013                                                     Ileum resection   \n",
      "QQ0014                                                                PBMC   \n",
      "QQ0015                                                     Ileum resection   \n",
      "QQ0016                                                     Ileum resection   \n",
      "QQ0017                                                     Ileum resection   \n",
      "QQ0018                                                     Ileum resection   \n",
      "QQ0019                                                     Ileum resection   \n",
      "QQ0020                                                     Ileum resection   \n",
      "QQ0021                                                                PBMC   \n",
      "QQ0022                                                     Ileum resection   \n",
      "QQ0023                                                                PBMC   \n",
      "QQ0024                                                     Ileum resection   \n",
      "QQ0025                                                     Ileum resection   \n",
      "QQ0026                                                     Ileum resection   \n",
      "QQ0027                                                                PBMC   \n",
      "QQ0028                                                     Ileum resection   \n",
      "QQ0029                                                     Ileum resection   \n",
      "QQ0030                                                                PBMC   \n",
      "QQ0031                                 Terminal Ileum Resection, Biopsies    \n",
      "QQ0032                                 Terminal Ileum Resection, Biopsies    \n",
      "QQ0033                                                         Whole blood   \n",
      "QQ0034                                                         Whole blood   \n",
      "AA1inf                              Colectomy, Biopsies from sigmoid colon   \n",
      "AA1non                           Colectomy, Biopsies from transverse colon   \n",
      "QQ0035                                        Larval intestinal dissection   \n",
      "QQ0036     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "QQ0037     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "QQ0038                                        Larval intestinal dissection   \n",
      "QQ0039                                        Larval intestinal dissection   \n",
      "QQ0040     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "QQ0041                                        Larval intestinal dissection   \n",
      "QQ0042                                        Larval intestinal dissection   \n",
      "QQ0043     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "QQ0044                                        Larval intestinal dissection   \n",
      "QQ0045                                        Larval intestinal dissection   \n",
      "QQ0046                                        Larval intestinal dissection   \n",
      "QQ0047                                        Larval intestinal dissection   \n",
      "QQ0048                                        Larval intestinal dissection   \n",
      "QQ0049                                        Larval intestinal dissection   \n",
      "QQ0050                                        Larval intestinal dissection   \n",
      "QQ0051                                        Larval intestinal dissection   \n",
      "QQ0052                                        Larval intestinal dissection   \n",
      "QQ0053                                        Larval intestinal dissection   \n",
      "QQ0054                                        Larval intestinal dissection   \n",
      "QQ0055                                        Larval intestinal dissection   \n",
      "QQ0056                                        Larval intestinal dissection   \n",
      "QQ0057                                        Larval intestinal dissection   \n",
      "QQ0058                                        Larval intestinal dissection   \n",
      "QQ0059                                        Larval intestinal dissection   \n",
      "KC0004                                                     Ileal resection   \n",
      "KC0002                                                     Ileal resection   \n",
      "KC0003                                                     Ileal resection   \n",
      "KC0005                                                     Ileal resection   \n",
      "KC0001                                                     Ileal resection   \n",
      "CD0001                                 Terminal Ileal Resection, Biopsies    \n",
      "CD0002                                 Terminal Ileal Resection, Biopsies    \n",
      "CD0003                                 Terminal Ileal Resection, Biopsies    \n",
      "CD0004                                 Terminal Ileal Resection, Biopsies    \n",
      "\n",
      "           no_live_cells  cell_viability_percentage targ_cell no_live_nuclei  \\\n",
      "lib_id                                                                         \n",
      "HH0001           94000.0                       76.6      6000            NaN   \n",
      "J00002            3000.0                       95.0      3000            NaN   \n",
      "J00003            3000.0                       92.0      3000            NaN   \n",
      "J00004            3000.0                       88.0      3000            NaN   \n",
      "J00005            3000.0                       78.0      3000            NaN   \n",
      "LC0001          447000.0                       95.0     10000            NaN   \n",
      "LC0002          447000.0                       95.0     10000         447000   \n",
      "LC0003         1400000.0                       94.0     10000            NaN   \n",
      "LC0004         1400000.0                       94.0     10000          99900   \n",
      "LC0005         1070000.0                       93.7     10000            NaN   \n",
      "LC0006         1070000.0                       93.7     10000          64000   \n",
      "RL0001          634000.0                       77.8      6000            NaN   \n",
      "RL0001_re       634000.0                       77.8      6000            NaN   \n",
      "RL0002         1240000.0                       76.7      6000            NaN   \n",
      "RL0002_re      1240000.0                       76.7      6000            NaN   \n",
      "RL0003         1030000.0                       64.9      6000            NaN   \n",
      "RL0004         2120000.0                       53.2      6000            NaN   \n",
      "RL0005          223000.0                       83.3      6000            NaN   \n",
      "RL0006          671000.0                       89.4      6000            NaN   \n",
      "RL0007          223000.0                        NaN     10000            NaN   \n",
      "RL0008          671000.0                        NaN     10000            NaN   \n",
      "RL0009          223000.0                        NaN     10000            NaN   \n",
      "RL0010          671000.0                        NaN     10000            NaN   \n",
      "RL0011           80400.0                       82.4      6000            NaN   \n",
      "RL0012          611000.0                       79.3      6000            NaN   \n",
      "RL0013           80400.0                        NaN     10000            NaN   \n",
      "RL0014          611000.0                        NaN     10000            NaN   \n",
      "RL0015           80400.0                        NaN     10000            NaN   \n",
      "RL0016          611000.0                        NaN     10000            NaN   \n",
      "RL0017          376000.0                       90.0      6000            NaN   \n",
      "RL0018          425000.0                       89.8      6000            NaN   \n",
      "RL0019           72600.0                       77.8      6000            NaN   \n",
      "RL0020          184000.0                       85.9      6000            NaN   \n",
      "RL0021          105000.0                       87.6      6000            NaN   \n",
      "RL0022           23700.0                       84.1      6000            NaN   \n",
      "RL0023          644000.0                       54.0      6000            NaN   \n",
      "RL0024          496000.0                       67.9      6000            NaN   \n",
      "RL0025          644000.0                        NaN     10000            NaN   \n",
      "RL0026          496000.0                        NaN     10000            NaN   \n",
      "RL0027          644000.0                        NaN     10000            NaN   \n",
      "RL0028          496000.0                        NaN     10000            NaN   \n",
      "RL0029         1600000.0                       69.2      6000            NaN   \n",
      "RL0030          697000.0                       74.1      6000            NaN   \n",
      "RL0031         1600000.0                        NaN     10000            NaN   \n",
      "RL0032          697000.0                        NaN     10000            NaN   \n",
      "RL0033         1600000.0                        NaN     10000            NaN   \n",
      "RL0034          697000.0                        NaN     10000            NaN   \n",
      "RL0035         5200000.0                       58.2      6000            NaN   \n",
      "RL0036        15800000.0                       73.9      6000            NaN   \n",
      "RL0037          995000.0                        NaN     10000    Est: 497.5K   \n",
      "RL0038          625000.0                        NaN     10000    Est: 213.5K   \n",
      "RL0039          995000.0                        NaN     10000    Est: 497.5K   \n",
      "RL0040          625000.0                        NaN     10000    Est: 213.5K   \n",
      "RL0041          995000.0                       57.2      6000            NaN   \n",
      "RL0042          625000.0                       68.1      6000            NaN   \n",
      "RL0043         3380000.0                        0.7     10000        2940000   \n",
      "RL0044         1750000.0                        0.2     10000        1510000   \n",
      "RL0045         3380000.0                        0.7     10000        2940000   \n",
      "RL0046         1750000.0                        0.2     10000        1510000   \n",
      "RL0047         3380000.0                       61.7      6000            NaN   \n",
      "RL0048         1750000.0                       69.8      6000            NaN   \n",
      "RL0049          602000.0                       84.5      6000            NaN   \n",
      "RL0050          366000.0                       87.6      6000            NaN   \n",
      "RL0051          408000.0                       89.5      6000        1030000   \n",
      "RL0052          408000.0                       89.5      6000        1030000   \n",
      "RL0053          675000.0                       88.2      6000            NaN   \n",
      "RL0054          408000.0                       89.5      6000            NaN   \n",
      "SN0001          115000.0                       43.7      5000            NaN   \n",
      "SN0002         1160000.0                       40.3      5000            NaN   \n",
      "SN0003          286000.0                       58.9   No load            NaN   \n",
      "SN0004          187000.0                       49.8   No load            NaN   \n",
      "SN0005          149000.0                       41.6      5000            NaN   \n",
      "SN0006          257000.0                       46.5      5000            NaN   \n",
      "SN0007          336000.0                       43.1      5000            NaN   \n",
      "SN0008          211000.0                       53.2      5000            NaN   \n",
      "SN0009         1070000.0                       52.3      5000            NaN   \n",
      "SN0010          650000.0                       41.8      5000            NaN   \n",
      "SN0011          411000.0                       36.4      5000            NaN   \n",
      "SN0012          629000.0                       36.7      5000            NaN   \n",
      "SN0013         1830000.0                       85.3      6000            NaN   \n",
      "SN0014         1170000.0                       96.0      6000            NaN   \n",
      "UC0001          534000.0                        NaN      5000            NaN   \n",
      "UC0002          585000.0                        NaN      5000            NaN   \n",
      "UC0003          570000.0                        NaN      5000            NaN   \n",
      "UC0004          996000.0                        NaN      5000            NaN   \n",
      "NH0001          548000.0                       80.3      6000            NaN   \n",
      "NH0002          747000.0                       79.9      9000            NaN   \n",
      "NH0003          787000.0                       76.6      8000            NaN   \n",
      "NH0004          951000.0                       81.3      8000            NaN   \n",
      "NH0005          514000.0                       77.0      5000            NaN   \n",
      "NH0006          649000.0                       64.5      4000            NaN   \n",
      "NH0007          884000.0                       72.0      8000            NaN   \n",
      "NH0008          865000.0                       63.4      8000            NaN   \n",
      "NH0009               NaN                       70.0      6000            NaN   \n",
      "NH0010               NaN                       70.0      6000            NaN   \n",
      "NH0011               NaN                       70.0      6000            NaN   \n",
      "NH0012               NaN                       70.0      6000            NaN   \n",
      "NH0013               NaN                       70.0      6000            NaN   \n",
      "NH0014               NaN                       70.0      6000            NaN   \n",
      "NH0015               NaN                       70.0      6000            NaN   \n",
      "NH0016               NaN                       70.0      6000            NaN   \n",
      "QQ0001               NaN                        NaN       NaN            NaN   \n",
      "QQ0002               NaN                        NaN       NaN            NaN   \n",
      "QQ0003               NaN                        NaN       NaN            NaN   \n",
      "QQ0004               NaN                        NaN       NaN            NaN   \n",
      "QQ0005               NaN                        NaN       NaN            NaN   \n",
      "QQ0006               NaN                        NaN       NaN            NaN   \n",
      "QQ0007               NaN                        NaN       NaN            NaN   \n",
      "QQ0008               NaN                        NaN       NaN            NaN   \n",
      "QQ0009               NaN                        NaN       NaN            NaN   \n",
      "QQ0010               NaN                        NaN       NaN            NaN   \n",
      "QQ0011               NaN                        NaN       NaN            NaN   \n",
      "QQ0012               NaN                        NaN       NaN            NaN   \n",
      "QQ0013               NaN                        NaN       NaN            NaN   \n",
      "QQ0014               NaN                        NaN       NaN            NaN   \n",
      "QQ0015               NaN                        NaN       NaN            NaN   \n",
      "QQ0016               NaN                        NaN       NaN            NaN   \n",
      "QQ0017               NaN                        NaN       NaN            NaN   \n",
      "QQ0018               NaN                        NaN       NaN            NaN   \n",
      "QQ0019               NaN                        NaN       NaN            NaN   \n",
      "QQ0020               NaN                        NaN       NaN            NaN   \n",
      "QQ0021               NaN                        NaN       NaN            NaN   \n",
      "QQ0022               NaN                        NaN       NaN            NaN   \n",
      "QQ0023               NaN                        NaN       NaN            NaN   \n",
      "QQ0024               NaN                        NaN       NaN            NaN   \n",
      "QQ0025               NaN                        NaN       NaN            NaN   \n",
      "QQ0026               NaN                        NaN       NaN            NaN   \n",
      "QQ0027               NaN                        NaN       NaN            NaN   \n",
      "QQ0028               NaN                        NaN       NaN            NaN   \n",
      "QQ0029               NaN                        NaN       NaN            NaN   \n",
      "QQ0030               NaN                        NaN       NaN            NaN   \n",
      "QQ0031               NaN                        NaN       NaN            NaN   \n",
      "QQ0032               NaN                        NaN       NaN            NaN   \n",
      "QQ0033               NaN                        NaN       NaN            NaN   \n",
      "QQ0034               NaN                        NaN       NaN            NaN   \n",
      "AA1inf         6480000.0                       50.8      6000            NaN   \n",
      "AA1non         7120000.0                       69.2      6000            NaN   \n",
      "QQ0035               NaN                        NaN      1000            NaN   \n",
      "QQ0036               NaN                        NaN      1000            NaN   \n",
      "QQ0037               NaN                        NaN      1000            NaN   \n",
      "QQ0038               NaN                        NaN      1000            NaN   \n",
      "QQ0039               NaN                        NaN      1000            NaN   \n",
      "QQ0040               NaN                        NaN      1000            NaN   \n",
      "QQ0041               NaN                        NaN      1000            NaN   \n",
      "QQ0042               NaN                        NaN      1000            NaN   \n",
      "QQ0043               NaN                        NaN      1000            NaN   \n",
      "QQ0044          433000.0                        NaN      6000            NaN   \n",
      "QQ0045          266000.0                        NaN      6000            NaN   \n",
      "QQ0046          144000.0                        NaN      6000            NaN   \n",
      "QQ0047          362000.0                        NaN      6000            NaN   \n",
      "QQ0048          404000.0                        NaN      6000            NaN   \n",
      "QQ0049               NaN                        NaN      6000            NaN   \n",
      "QQ0050               NaN                        NaN      6000            NaN   \n",
      "QQ0051               NaN                        NaN      6000            NaN   \n",
      "QQ0052               NaN                        NaN      6000            NaN   \n",
      "QQ0053               NaN                        NaN      6000            NaN   \n",
      "QQ0054               NaN                        NaN      6000            NaN   \n",
      "QQ0055          585000.0                        NaN      6000            NaN   \n",
      "QQ0056          202000.0                        NaN      6000            NaN   \n",
      "QQ0057          248000.0                        NaN      6000            NaN   \n",
      "QQ0058          260000.0                        NaN      6000            NaN   \n",
      "QQ0059          194000.0                        NaN      6000            NaN   \n",
      "KC0004         1000000.0                       63.3      6000            NaN   \n",
      "KC0002         1340000.0                       74.2      6000            NaN   \n",
      "KC0003         1160000.0                       67.2      6000            NaN   \n",
      "KC0005          900000.0                       71.3      6000            NaN   \n",
      "KC0001          800000.0                       60.5      6000            NaN   \n",
      "CD0001          417000.0                       65.2      5000            NaN   \n",
      "CD0002          100000.0                       63.7      5000            NaN   \n",
      "CD0003           61700.0                       69.2      5000            NaN   \n",
      "CD0004          296000.0                       72.5      5000            NaN   \n",
      "\n",
      "           no_nuclei  index_kit   age  sex              race pre_amp_date  \\\n",
      "lib_id                                                                      \n",
      "HH0001           NaN   SI-TT-E2   NaN  NaN               NaN   05-23-2022   \n",
      "J00002           NaN   SI-TT-D1   NaN  NaN               NaN   03-08-2022   \n",
      "J00003           NaN   SI-TT-D2   NaN  NaN               NaN   03-11-2022   \n",
      "J00004           NaN   SI-TT-D3   NaN  NaN               NaN   03-17-2022   \n",
      "J00005           NaN   SI-TT-D4   NaN  NaN               NaN   03-31-2022   \n",
      "LC0001           NaN   SI-TT-D7   NaN  NaN               NaN   04-27-2022   \n",
      "LC0002       10000.0   SI-NA-C2   NaN  NaN               NaN   04-27-2022   \n",
      "LC0003           NaN   SI-TT-E5   NaN  NaN               NaN   07-12-2022   \n",
      "LC0004       10000.0   SI-NA-F2   NaN  NaN               NaN   07-12-2022   \n",
      "LC0005           NaN   SI-TT-E6   NaN  NaN               NaN   07-12-2022   \n",
      "LC0006       10000.0   SI-NA-G2   NaN  NaN               NaN   07-12-2022   \n",
      "RL0001           NaN   SI-TT-E1  37.0    F             Black   06-01-2021   \n",
      "RL0001_re        NaN  SI-TT-A11  37.0    F             Black   06-01-2021   \n",
      "RL0002           NaN   SI-TT-E2  37.0    F             Black   06-01-2021   \n",
      "RL0002_re        NaN  SI-TT-A12  37.0    F             Black   06-01-2021   \n",
      "RL0003           NaN   SI-TT-E5  62.0    F      White/Latina   06-17-2021   \n",
      "RL0004           NaN   SI-TT-E6  62.0    F      White/Latina   06-17-2021   \n",
      "RL0005           NaN   SI-TT-G7  28.0    F             Black   06-28-2021   \n",
      "RL0006           NaN   SI-TT-G8  28.0    F             Black   06-28-2021   \n",
      "RL0007           NaN   SI-TT-A1  28.0    F             Black   07-08-2021   \n",
      "RL0008       10000.0   SI-TT-A2  28.0    F             Black   07-08-2021   \n",
      "RL0009       10000.0   SI-NA-A1  28.0    F             Black   07-08-2021   \n",
      "RL0010       10000.0   SI-NA-B1  28.0    F             Black   07-08-2021   \n",
      "RL0011           NaN   SI-TT-A9  23.0    M             White   07-26-2021   \n",
      "RL0012           NaN  SI-TT-A10  23.0    M             White   07-26-2021   \n",
      "RL0013       10000.0   SI-TT-A7  23.0    M             White   07-27-2021   \n",
      "RL0014       10000.0   SI-TT-A8  23.0    M             White   07-27-2021   \n",
      "RL0015       10000.0   SI-NA-C1  23.0    M             White   07-27-2021   \n",
      "RL0016       10000.0   SI-NA-D1  23.0    M             White   07-27-2021   \n",
      "RL0017           NaN   SI-TT-B1  27.0    M             Black   09-01-2021   \n",
      "RL0018           NaN   SI-TT-B2  27.0    M             Black   09-01-2021   \n",
      "RL0019           NaN   SI-TT-B9  57.0    M             White   09-16-2021   \n",
      "RL0020           NaN  SI-TT-B10  57.0    M             White   09-16-2021   \n",
      "RL0021           NaN   SI-TT-B4  45.0    M             Black   09-28-2021   \n",
      "RL0022           NaN   SI-TT-B5  45.0    M             Black   09-28-2021   \n",
      "RL0023           NaN   SI-TT-B8  52.0    F             Black   09-28-2021   \n",
      "RL0024           NaN  SI-TT-B11  52.0    F             Black   09-28-2021   \n",
      "RL0025       10000.0   SI-TT-C3  52.0    F             Black   10-12-2021   \n",
      "RL0026       10000.0   SI-TT-C4  52.0    F             Black   10-12-2021   \n",
      "RL0027       10000.0   SI-NA-E1  52.0    F             Black   10-12-2021   \n",
      "RL0028       10000.0   SI-NA-F1  52.0    F             Black   10-12-2021   \n",
      "RL0029           NaN   SI-TT-C1  49.0    M      White/Latino   10-04-2021   \n",
      "RL0030           NaN   SI-TT-C2  49.0    M      White/Latino   10-04-2021   \n",
      "RL0031       10000.0   SI-TT-C5  49.0    M      White/Latino   10-12-2021   \n",
      "RL0032       10000.0   SI-TT-C6  49.0    M      White/Latino   10-12-2021   \n",
      "RL0033       10000.0   SI-NA-G1  49.0    M      White/Latino   10-12-2021   \n",
      "RL0034       10000.0   SI-NA-H1  49.0    M      White/Latino   10-12-2021   \n",
      "RL0035           NaN   SI-TT-C9  32.0    M       South Asian   10-18-2021   \n",
      "RL0036           NaN  SI-TT-C10  32.0    M       South Asian   10-18-2021   \n",
      "RL0037       10000.0   SI-TT-D5  31.0    M             White   04-22-2022   \n",
      "RL0038       10000.0   SI-TT-D6  31.0    M             White   04-22-2022   \n",
      "RL0039       10000.0   SI-NA-A2  31.0    M             White   04-27-2022   \n",
      "RL0040       10000.0   SI-NA-B2  31.0    M             White   04-27-2022   \n",
      "RL0041           NaN  SI-TT-D10  31.0    M             White   04-22-2022   \n",
      "RL0042           NaN  SI-TT-D11  31.0    M             White   04-22-2022   \n",
      "RL0043       10000.0   SI-TT-D8  39.0    M             Black   04-27-2022   \n",
      "RL0044       10000.0   SI-TT-D9  39.0    M             Black   04-27-2022   \n",
      "RL0045       10000.0   SI-NA-D2  39.0    M             Black   04-27-2022   \n",
      "RL0046       10000.0   SI-NA-E2  39.0    M             Black   04-27-2022   \n",
      "RL0047           NaN  SI-TT-D12  39.0    M             Black   04-29-2022   \n",
      "RL0048           NaN   SI-TT-E1  39.0    M             Black   04-29-2022   \n",
      "RL0049           NaN   SI-TT-E3  47.0    F      White/Latina   06-15-2022   \n",
      "RL0050           NaN   SI-TT-E4  47.0    F      White/Latina   06-15-2022   \n",
      "RL0051       10000.0   SI-TT-F5  33.0    M             White   12-21-2022   \n",
      "RL0052       10000.0    SI-N-D3  33.0    M             White   12-21-2022   \n",
      "RL0053           NaN   SI-TT-F3  33.0    M             White   12-19-2022   \n",
      "RL0054           NaN   SI-TT-F4  33.0    M             White   12-19-2022   \n",
      "SN0001           NaN  SI-TT-G10   NaN  NaN               NaN   06-09-2021   \n",
      "SN0002           NaN  SI-TT-G11   NaN  NaN               NaN   06-09-2021   \n",
      "SN0003           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "SN0004           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "SN0005           NaN   SI-TT-H1   NaN  NaN               NaN   06-09-2021   \n",
      "SN0006           NaN   SI-TT-H2   NaN  NaN               NaN   06-09-2021   \n",
      "SN0007           NaN   SI-TT-H3   NaN  NaN               NaN   06-09-2021   \n",
      "SN0008           NaN   SI-TT-H4   NaN  NaN               NaN   06-09-2021   \n",
      "SN0009           NaN   SI-TT-A3   NaN  NaN               NaN   07-20-2021   \n",
      "SN0010           NaN   SI-TT-A4   NaN  NaN               NaN   07-20-2021   \n",
      "SN0011           NaN   SI-TT-A5   NaN  NaN               NaN   07-20-2021   \n",
      "SN0012           NaN   SI-TT-A6   NaN  NaN               NaN   07-20-2021   \n",
      "SN0013           NaN   SI-TT-B6   NaN    F             White   09-28-2021   \n",
      "SN0014           NaN   SI-TT-B7   NaN    F             White   09-28-2021   \n",
      "UC0001           NaN   SI-TT-H9   NaN  NaN               NaN   04-01-2021   \n",
      "UC0002           NaN  SI-TT-H10   NaN  NaN               NaN   04-01-2021   \n",
      "UC0003           NaN  SI-TT-H11   NaN  NaN               NaN   04-01-2021   \n",
      "UC0004           NaN  SI-TT-H12   NaN  NaN               NaN   06-01-2021   \n",
      "NH0001           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "NH0002           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "NH0003           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "NH0004           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "NH0005           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "NH0006           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "NH0007           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "NH0008           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "NH0009           NaN        NaN  28.0    F             White          NaN   \n",
      "NH0010           NaN        NaN  28.0    F             White          NaN   \n",
      "NH0011           NaN        NaN  30.0    M             White          NaN   \n",
      "NH0012           NaN        NaN  30.0    M             White          NaN   \n",
      "NH0013           NaN        NaN  26.0    M             White          NaN   \n",
      "NH0014           NaN        NaN  26.0    M             White          NaN   \n",
      "NH0015           NaN        NaN  39.0    F             White          NaN   \n",
      "NH0016           NaN        NaN  39.0    F             White          NaN   \n",
      "QQ0001           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0002           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0003           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0004           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0005           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0006           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0007           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0008           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0009           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0010           NaN        NaN   NaN    F             White          NaN   \n",
      "QQ0011           NaN        NaN   NaN    F             White          NaN   \n",
      "QQ0012           NaN        NaN   NaN    F             White          NaN   \n",
      "QQ0013           NaN        NaN   NaN    F             White          NaN   \n",
      "QQ0014           NaN        NaN   NaN    F             White          NaN   \n",
      "QQ0015           NaN        NaN   NaN    F             White          NaN   \n",
      "QQ0016           NaN        NaN   NaN    F             White          NaN   \n",
      "QQ0017           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0018           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0019           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0020           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0021           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0022           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0023           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0024           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0025           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0026           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0027           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0028           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0029           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0030           NaN        NaN   NaN    M             White          NaN   \n",
      "QQ0031           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0032           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0033           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0034           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "AA1inf           NaN        NaN  33.0    M  African American          NaN   \n",
      "AA1non           NaN        NaN  33.0    M  African American          NaN   \n",
      "QQ0035           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0036           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0037           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0038           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0039           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0040           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0041           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0042           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0043           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0044           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0045           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0046           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0047           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0048           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0049           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0050           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0051           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0052           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0053           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0054           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0055           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0056           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0057           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0058           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "QQ0059           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "KC0004           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "KC0002           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "KC0003           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "KC0005           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "KC0001           NaN        NaN   NaN  NaN               NaN          NaN   \n",
      "CD0001           NaN   SI-TT-H5  60.0    F             White   04-01-2021   \n",
      "CD0002           NaN   SI-TT-H6  60.0    F             White   04-01-2021   \n",
      "CD0003           NaN   SI-TT-H7  32.0    M             White   04-01-2021   \n",
      "CD0004           NaN   SI-TT-H8  32.0    M             White   04-01-2021   \n",
      "\n",
      "            date_sent     instrument repeat_data_release repeat_seq_platform  \\\n",
      "lib_id                                                                         \n",
      "HH0001     07-11-2022     NovaSeq S4                 NaN                 NaN   \n",
      "J00002     03-08-2022     NovaSeq SP                 NaN                 NaN   \n",
      "J00003     03-21-2022     NovaSeq SP                 NaN                 NaN   \n",
      "J00004     03-21-2022     NovaSeq SP                 NaN                 NaN   \n",
      "J00005     04-05-2022     NovaSeq SP                 NaN                 NaN   \n",
      "LC0001     04-28-2022     NovaSeq S4                 NaN                 NaN   \n",
      "LC0002     04-27-2022     NovaSeq S1                 NaN                 NaN   \n",
      "LC0003     07-12-2022     NovaSeq S4                 NaN                 NaN   \n",
      "LC0004     07-12-2022     NovaSeq S1                 NaN                 NaN   \n",
      "LC0005     07-12-2022     NovaSeq S4                 NaN                 NaN   \n",
      "LC0006     07-12-2022     NovaSeq S1                 NaN                 NaN   \n",
      "RL0001     06-08-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0001_re  06-09-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0002     06-08-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0002_re  06-09-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0003     06-22-2021     NovaSeq S4   Sabic_Project_013          NovaSeq S4   \n",
      "RL0004     06-22-2021     NovaSeq S4   Sabic_Project_013          NovaSeq S4   \n",
      "RL0005     07-13-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0006     07-13-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0007     07-15-2021  Not Sequenced                 NaN                 NaN   \n",
      "RL0008     07-15-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0009     07-14-2021  Not Sequenced                 NaN                 NaN   \n",
      "RL0010     07-14-2021     NovaSeq S1                 NaN                 NaN   \n",
      "RL0011     07-29-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0012     07-29-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0013     07-28-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0014     07-28-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0015     07-30-2021     NovaSeq S1   Sabic_Project_021          NovaSeq S4   \n",
      "RL0016     07-30-2021     NovaSeq S1   Sabic_Project_021          NovaSeq S4   \n",
      "RL0017     10-05-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0018     10-05-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0019     10-07-2021     NovaSeq S2                 NaN                 NaN   \n",
      "RL0020     10-07-2021     NovaSeq S2                 NaN                 NaN   \n",
      "RL0021     10-05-2021     NovaSeq S2                 NaN                 NaN   \n",
      "RL0022     10-05-2021     NovaSeq S2                 NaN                 NaN   \n",
      "RL0023     10-05-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0024     10-07-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0025     10-14-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0026     10-14-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0027     10-14-2021     NovaSeq S1   Sabic_Project_021          NovaSeq S4   \n",
      "RL0028     10-14-2021     NovaSeq S1   Sabic_Project_021          NovaSeq S4   \n",
      "RL0029     10-07-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0030     10-07-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0031     10-14-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0032     10-14-2021     NovaSeq S4                 NaN                 NaN   \n",
      "RL0033     10-14-2021     NovaSeq S1   Sabic_Project_021          NovaSeq S4   \n",
      "RL0034     10-14-2021     NovaSeq S1   Sabic_Project_021          NovaSeq S4   \n",
      "RL0035     10-18-2021     NovaSeq S2                 NaN                 NaN   \n",
      "RL0036     10-18-2021     NovaSeq S2                 NaN                 NaN   \n",
      "RL0037     04-28-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0038     04-28-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0039     04-27-2022     NovaSeq S1                 NaN                 NaN   \n",
      "RL0040     04-27-2022     NovaSeq S1                 NaN                 NaN   \n",
      "RL0041     05-18-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0042     05-18-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0043     04-28-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0044     04-28-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0045     04-27-2022     NovaSeq S1                 NaN                 NaN   \n",
      "RL0046     04-27-2022     NovaSeq S1                 NaN                 NaN   \n",
      "RL0047     05-18-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0048     05-18-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0049     07-11-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0050     07-11-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0051     12-27-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0052     06-13-2023     NovaSeq S4                 NaN                 NaN   \n",
      "RL0053     12-21-2022     NovaSeq S4                 NaN                 NaN   \n",
      "RL0054     12-21-2022     NovaSeq S4                 NaN                 NaN   \n",
      "SN0001     06-14-2021     NovaSeq S4                 NaN                 NaN   \n",
      "SN0002     06-14-2021     NovaSeq S4                 NaN                 NaN   \n",
      "SN0003            NaN            NaN                 NaN                 NaN   \n",
      "SN0004            NaN            NaN                 NaN                 NaN   \n",
      "SN0005     06-14-2021     NovaSeq S4                 NaN                 NaN   \n",
      "SN0006     06-14-2021     NovaSeq S4                 NaN                 NaN   \n",
      "SN0007     06-14-2021     NovaSeq S4                 NaN                 NaN   \n",
      "SN0008     06-14-2021     NovaSeq S4                 NaN                 NaN   \n",
      "SN0009     07-22-2021     NovaSeq S4                 NaN                 NaN   \n",
      "SN0010     07-22-2021     NovaSeq S4                 NaN                 NaN   \n",
      "SN0011     07-22-2021     NovaSeq S4                 NaN                 NaN   \n",
      "SN0012     07-22-2021     NovaSeq S4                 NaN                 NaN   \n",
      "SN0013     10-05-2021     NovaSeq S4                 NaN                 NaN   \n",
      "SN0014     10-05-2021     NovaSeq S4                 NaN                 NaN   \n",
      "UC0001     04-08-2021     NovaSeq S4   Sabic_Project_016          NovaSeq S4   \n",
      "UC0002     04-08-2021     NovaSeq S4   Sabic_Project_016          NovaSeq S4   \n",
      "UC0003     04-08-2021     NovaSeq S4   Sabic_Project_016          NovaSeq S4   \n",
      "UC0004     04-08-2021     NovaSeq S4   Sabic_Project_016          NovaSeq S4   \n",
      "NH0001            NaN            NaN                 NaN                 NaN   \n",
      "NH0002            NaN            NaN                 NaN                 NaN   \n",
      "NH0003            NaN            NaN                 NaN                 NaN   \n",
      "NH0004            NaN            NaN                 NaN                 NaN   \n",
      "NH0005            NaN            NaN                 NaN                 NaN   \n",
      "NH0006            NaN            NaN                 NaN                 NaN   \n",
      "NH0007            NaN            NaN                 NaN                 NaN   \n",
      "NH0008            NaN            NaN                 NaN                 NaN   \n",
      "NH0009            NaN            NaN                 NaN                 NaN   \n",
      "NH0010            NaN            NaN                 NaN                 NaN   \n",
      "NH0011            NaN            NaN                 NaN                 NaN   \n",
      "NH0012            NaN            NaN                 NaN                 NaN   \n",
      "NH0013            NaN            NaN                 NaN                 NaN   \n",
      "NH0014            NaN            NaN                 NaN                 NaN   \n",
      "NH0015            NaN            NaN                 NaN                 NaN   \n",
      "NH0016            NaN            NaN                 NaN                 NaN   \n",
      "QQ0001            NaN            NaN                 NaN                 NaN   \n",
      "QQ0002            NaN            NaN                 NaN                 NaN   \n",
      "QQ0003            NaN            NaN                 NaN                 NaN   \n",
      "QQ0004            NaN            NaN                 NaN                 NaN   \n",
      "QQ0005            NaN            NaN                 NaN                 NaN   \n",
      "QQ0006            NaN            NaN                 NaN                 NaN   \n",
      "QQ0007            NaN            NaN                 NaN                 NaN   \n",
      "QQ0008            NaN            NaN                 NaN                 NaN   \n",
      "QQ0009            NaN            NaN                 NaN                 NaN   \n",
      "QQ0010            NaN            NaN                 NaN                 NaN   \n",
      "QQ0011            NaN            NaN                 NaN                 NaN   \n",
      "QQ0012            NaN            NaN                 NaN                 NaN   \n",
      "QQ0013            NaN            NaN                 NaN                 NaN   \n",
      "QQ0014            NaN            NaN                 NaN                 NaN   \n",
      "QQ0015            NaN            NaN                 NaN                 NaN   \n",
      "QQ0016            NaN            NaN                 NaN                 NaN   \n",
      "QQ0017            NaN            NaN                 NaN                 NaN   \n",
      "QQ0018            NaN            NaN                 NaN                 NaN   \n",
      "QQ0019            NaN            NaN                 NaN                 NaN   \n",
      "QQ0020            NaN            NaN                 NaN                 NaN   \n",
      "QQ0021            NaN            NaN                 NaN                 NaN   \n",
      "QQ0022            NaN            NaN                 NaN                 NaN   \n",
      "QQ0023            NaN            NaN                 NaN                 NaN   \n",
      "QQ0024            NaN            NaN                 NaN                 NaN   \n",
      "QQ0025            NaN            NaN                 NaN                 NaN   \n",
      "QQ0026            NaN            NaN                 NaN                 NaN   \n",
      "QQ0027            NaN            NaN                 NaN                 NaN   \n",
      "QQ0028            NaN            NaN                 NaN                 NaN   \n",
      "QQ0029            NaN            NaN                 NaN                 NaN   \n",
      "QQ0030            NaN            NaN                 NaN                 NaN   \n",
      "QQ0031            NaN            NaN                 NaN                 NaN   \n",
      "QQ0032            NaN            NaN                 NaN                 NaN   \n",
      "QQ0033            NaN            NaN                 NaN                 NaN   \n",
      "QQ0034            NaN            NaN                 NaN                 NaN   \n",
      "AA1inf            NaN            NaN                 NaN                 NaN   \n",
      "AA1non            NaN            NaN                 NaN                 NaN   \n",
      "QQ0035            NaN            NaN                 NaN                 NaN   \n",
      "QQ0036            NaN            NaN                 NaN                 NaN   \n",
      "QQ0037            NaN            NaN                 NaN                 NaN   \n",
      "QQ0038            NaN            NaN                 NaN                 NaN   \n",
      "QQ0039            NaN            NaN                 NaN                 NaN   \n",
      "QQ0040            NaN            NaN                 NaN                 NaN   \n",
      "QQ0041            NaN            NaN                 NaN                 NaN   \n",
      "QQ0042            NaN            NaN                 NaN                 NaN   \n",
      "QQ0043            NaN            NaN                 NaN                 NaN   \n",
      "QQ0044            NaN            NaN                 NaN                 NaN   \n",
      "QQ0045            NaN            NaN                 NaN                 NaN   \n",
      "QQ0046            NaN            NaN                 NaN                 NaN   \n",
      "QQ0047            NaN            NaN                 NaN                 NaN   \n",
      "QQ0048            NaN            NaN                 NaN                 NaN   \n",
      "QQ0049            NaN            NaN                 NaN                 NaN   \n",
      "QQ0050            NaN            NaN                 NaN                 NaN   \n",
      "QQ0051            NaN            NaN                 NaN                 NaN   \n",
      "QQ0052            NaN            NaN                 NaN                 NaN   \n",
      "QQ0053            NaN            NaN                 NaN                 NaN   \n",
      "QQ0054            NaN            NaN                 NaN                 NaN   \n",
      "QQ0055            NaN            NaN                 NaN                 NaN   \n",
      "QQ0056            NaN            NaN                 NaN                 NaN   \n",
      "QQ0057            NaN            NaN                 NaN                 NaN   \n",
      "QQ0058            NaN            NaN                 NaN                 NaN   \n",
      "QQ0059            NaN            NaN                 NaN                 NaN   \n",
      "KC0004            NaN            NaN                 NaN                 NaN   \n",
      "KC0002            NaN            NaN                 NaN                 NaN   \n",
      "KC0003            NaN            NaN                 NaN                 NaN   \n",
      "KC0005            NaN            NaN                 NaN                 NaN   \n",
      "KC0001            NaN            NaN                 NaN                 NaN   \n",
      "CD0001     04-08-2021     NovaSeq S4                 NaN                 NaN   \n",
      "CD0002     04-08-2021     NovaSeq S4                 NaN                 NaN   \n",
      "CD0003     04-08-2021     NovaSeq S4                 NaN                 NaN   \n",
      "CD0004     04-08-2021     NovaSeq S4                 NaN                 NaN   \n",
      "\n",
      "              ref_genome  \\\n",
      "lib_id                     \n",
      "HH0001               NaN   \n",
      "J00002               NaN   \n",
      "J00003               NaN   \n",
      "J00004               NaN   \n",
      "J00005               NaN   \n",
      "LC0001               NaN   \n",
      "LC0002     GRCh38-2020-A   \n",
      "LC0003     GRCh38-2020-A   \n",
      "LC0004     GRCh38-2020-A   \n",
      "LC0005     GRCh38-2020-A   \n",
      "LC0006     GRCh38-2020-A   \n",
      "RL0001     GRCh38-2020-A   \n",
      "RL0001_re  GRCh38-2020-A   \n",
      "RL0002     GRCh38-2020-A   \n",
      "RL0002_re  GRCh38-2020-A   \n",
      "RL0003     GRCh38-2020-A   \n",
      "RL0004     GRCh38-2020-A   \n",
      "RL0005     GRCh38-2020-A   \n",
      "RL0006               NaN   \n",
      "RL0007               NaN   \n",
      "RL0008               NaN   \n",
      "RL0009               NaN   \n",
      "RL0010               NaN   \n",
      "RL0011     GRCh38-2020-A   \n",
      "RL0012     GRCh38-2020-A   \n",
      "RL0013               NaN   \n",
      "RL0014               NaN   \n",
      "RL0015               NaN   \n",
      "RL0016               NaN   \n",
      "RL0017               NaN   \n",
      "RL0018               NaN   \n",
      "RL0019               NaN   \n",
      "RL0020               NaN   \n",
      "RL0021               NaN   \n",
      "RL0022               NaN   \n",
      "RL0023               NaN   \n",
      "RL0024               NaN   \n",
      "RL0025               NaN   \n",
      "RL0026               NaN   \n",
      "RL0027               NaN   \n",
      "RL0028               NaN   \n",
      "RL0029               NaN   \n",
      "RL0030               NaN   \n",
      "RL0031               NaN   \n",
      "RL0032               NaN   \n",
      "RL0033               NaN   \n",
      "RL0034               NaN   \n",
      "RL0035               NaN   \n",
      "RL0036               NaN   \n",
      "RL0037               NaN   \n",
      "RL0038               NaN   \n",
      "RL0039               NaN   \n",
      "RL0040               NaN   \n",
      "RL0041               NaN   \n",
      "RL0042               NaN   \n",
      "RL0043               NaN   \n",
      "RL0044               NaN   \n",
      "RL0045               NaN   \n",
      "RL0046               NaN   \n",
      "RL0047               NaN   \n",
      "RL0048               NaN   \n",
      "RL0049               NaN   \n",
      "RL0050               NaN   \n",
      "RL0051               NaN   \n",
      "RL0052               NaN   \n",
      "RL0053               NaN   \n",
      "RL0054               NaN   \n",
      "SN0001            GRCz11   \n",
      "SN0002            GRCz11   \n",
      "SN0003            GRCz11   \n",
      "SN0004            GRCz11   \n",
      "SN0005            GRCz11   \n",
      "SN0006            GRCz11   \n",
      "SN0007            GRCz11   \n",
      "SN0008            GRCz11   \n",
      "SN0009            GRCz11   \n",
      "SN0010            GRCz11   \n",
      "SN0011            GRCz11   \n",
      "SN0012            GRCz11   \n",
      "SN0013               NaN   \n",
      "SN0014               NaN   \n",
      "UC0001     GRCh38-2020-A   \n",
      "UC0002     GRCh38-2020-A   \n",
      "UC0003     GRCh38-2020-A   \n",
      "UC0004     GRCh38-2020-A   \n",
      "NH0001              mm10   \n",
      "NH0002              mm10   \n",
      "NH0003              mm10   \n",
      "NH0004              mm10   \n",
      "NH0005              mm10   \n",
      "NH0006              mm10   \n",
      "NH0007              mm10   \n",
      "NH0008              mm10   \n",
      "NH0009        GRCh38.p13   \n",
      "NH0010        GRCh38.p13   \n",
      "NH0011        GRCh38.p13   \n",
      "NH0012        GRCh38.p13   \n",
      "NH0013        GRCh38.p13   \n",
      "NH0014        GRCh38.p13   \n",
      "NH0015        GRCh38.p13   \n",
      "NH0016        GRCh38.p13   \n",
      "QQ0001        GRCh38.p13   \n",
      "QQ0002        GRCh38.p13   \n",
      "QQ0003        GRCh38.p13   \n",
      "QQ0004        GRCh38.p13   \n",
      "QQ0005        GRCh38.p13   \n",
      "QQ0006        GRCh38.p13   \n",
      "QQ0007        GRCh38.p13   \n",
      "QQ0008        GRCh38.p13   \n",
      "QQ0009        GRCh38.p13   \n",
      "QQ0010        GRCh38.p13   \n",
      "QQ0011        GRCh38.p13   \n",
      "QQ0012        GRCh38.p13   \n",
      "QQ0013        GRCh38.p13   \n",
      "QQ0014        GRCh38.p13   \n",
      "QQ0015        GRCh38.p13   \n",
      "QQ0016        GRCh38.p13   \n",
      "QQ0017        GRCh38.p13   \n",
      "QQ0018        GRCh38.p13   \n",
      "QQ0019        GRCh38.p13   \n",
      "QQ0020        GRCh38.p13   \n",
      "QQ0021        GRCh38.p13   \n",
      "QQ0022        GRCh38.p13   \n",
      "QQ0023        GRCh38.p13   \n",
      "QQ0024        GRCh38.p13   \n",
      "QQ0025        GRCh38.p13   \n",
      "QQ0026        GRCh38.p13   \n",
      "QQ0027        GRCh38.p13   \n",
      "QQ0028        GRCh38.p13   \n",
      "QQ0029        GRCh38.p13   \n",
      "QQ0030        GRCh38.p13   \n",
      "QQ0031               NaN   \n",
      "QQ0032               NaN   \n",
      "QQ0033               NaN   \n",
      "QQ0034               NaN   \n",
      "AA1inf               NaN   \n",
      "AA1non               NaN   \n",
      "QQ0035               NaN   \n",
      "QQ0036               NaN   \n",
      "QQ0037               NaN   \n",
      "QQ0038               NaN   \n",
      "QQ0039               NaN   \n",
      "QQ0040               NaN   \n",
      "QQ0041               NaN   \n",
      "QQ0042               NaN   \n",
      "QQ0043               NaN   \n",
      "QQ0044            GRCz11   \n",
      "QQ0045            GRCz11   \n",
      "QQ0046            GRCz11   \n",
      "QQ0047            GRCz11   \n",
      "QQ0048            GRCz11   \n",
      "QQ0049            GRCz11   \n",
      "QQ0050            GRCz11   \n",
      "QQ0051            GRCz11   \n",
      "QQ0052            GRCz11   \n",
      "QQ0053            GRCz11   \n",
      "QQ0054            GRCz11   \n",
      "QQ0055            GRCz11   \n",
      "QQ0056            GRCz11   \n",
      "QQ0057            GRCz11   \n",
      "QQ0058            GRCz11   \n",
      "QQ0059            GRCz11   \n",
      "KC0004               NaN   \n",
      "KC0002               NaN   \n",
      "KC0003               NaN   \n",
      "KC0005               NaN   \n",
      "KC0001               NaN   \n",
      "CD0001               NaN   \n",
      "CD0002               NaN   \n",
      "CD0003               NaN   \n",
      "CD0004               NaN   \n",
      "\n",
      "                                                                                                                                            data_link  \n",
      "lib_id                                                                                                                                                 \n",
      "HH0001                                                                                                                                            NaN  \n",
      "J00002                                                                                                                                            NaN  \n",
      "J00003                                                                                                                                            NaN  \n",
      "J00004                                                                                                                                            NaN  \n",
      "J00005                                                                                                                                            NaN  \n",
      "LC0001                                                                                                                                            NaN  \n",
      "LC0002                                                                                                                                            NaN  \n",
      "LC0003                                                                                                                                            NaN  \n",
      "LC0004                                                                                                                                            NaN  \n",
      "LC0005                                                                                                                                            NaN  \n",
      "LC0006                                                                                                                                            NaN  \n",
      "RL0001     https://mtsinai-my.sharepoint.com/:f:/g/personal/rachel_levantovsky_icahn_mssm_edu/EqqTyRf99XxAlZD29IQEjBABjvaxmEFu0upUxJAMEz6D-A?e=uDqYID  \n",
      "RL0001_re                                                                                                                                         NaN  \n",
      "RL0002     https://mtsinai-my.sharepoint.com/:f:/g/personal/rachel_levantovsky_icahn_mssm_edu/EqqTyRf99XxAlZD29IQEjBABjvaxmEFu0upUxJAMEz6D-A?e=uDqYID  \n",
      "RL0002_re                                                                                                                                         NaN  \n",
      "RL0003     https://mtsinai-my.sharepoint.com/:f:/g/personal/rachel_levantovsky_icahn_mssm_edu/EqqTyRf99XxAlZD29IQEjBABjvaxmEFu0upUxJAMEz6D-A?e=uDqYID  \n",
      "RL0004     https://mtsinai-my.sharepoint.com/:f:/g/personal/rachel_levantovsky_icahn_mssm_edu/EqqTyRf99XxAlZD29IQEjBABjvaxmEFu0upUxJAMEz6D-A?e=uDqYID  \n",
      "RL0005                                                                                                                                            NaN  \n",
      "RL0006                                                                                                                                            NaN  \n",
      "RL0007                                                                                                                                            NaN  \n",
      "RL0008                                                                                                                                            NaN  \n",
      "RL0009                                                                                                                                            NaN  \n",
      "RL0010                                                                                                                                            NaN  \n",
      "RL0011                                                                                                                                            NaN  \n",
      "RL0012                                                                                                                                            NaN  \n",
      "RL0013                                                                                                                                            NaN  \n",
      "RL0014                                                                                                                                            NaN  \n",
      "RL0015                                                                                                                                            NaN  \n",
      "RL0016                                                                                                                                            NaN  \n",
      "RL0017                                                                                                                                            NaN  \n",
      "RL0018                                                                                                                                            NaN  \n",
      "RL0019                                                                                                                                            NaN  \n",
      "RL0020                                                                                                                                            NaN  \n",
      "RL0021                                                                                                                                            NaN  \n",
      "RL0022                                                                                                                                            NaN  \n",
      "RL0023                                                                                                                                            NaN  \n",
      "RL0024                                                                                                                                            NaN  \n",
      "RL0025                                                                                                                                            NaN  \n",
      "RL0026                                                                                                                                            NaN  \n",
      "RL0027                                                                                                                                            NaN  \n",
      "RL0028                                                                                                                                            NaN  \n",
      "RL0029                                                                                                                                            NaN  \n",
      "RL0030                                                                                                                                            NaN  \n",
      "RL0031                                                                                                                                            NaN  \n",
      "RL0032                                                                                                                                            NaN  \n",
      "RL0033                                                                                                                                            NaN  \n",
      "RL0034                                                                                                                                            NaN  \n",
      "RL0035                                                                                                                                            NaN  \n",
      "RL0036                                                                                                                                            NaN  \n",
      "RL0037                                                                                                                                            NaN  \n",
      "RL0038                                                                                                                                            NaN  \n",
      "RL0039                                                                                                                                            NaN  \n",
      "RL0040                                                                                                                                            NaN  \n",
      "RL0041                                                                                                                                            NaN  \n",
      "RL0042                                                                                                                                            NaN  \n",
      "RL0043                                                                                                                                            NaN  \n",
      "RL0044                                                                                                                                            NaN  \n",
      "RL0045                                                                                                                                            NaN  \n",
      "RL0046                                                                                                                                            NaN  \n",
      "RL0047                                                                                                                                            NaN  \n",
      "RL0048                                                                                                                                            NaN  \n",
      "RL0049                                                                                                                                            NaN  \n",
      "RL0050                                                                                                                                            NaN  \n",
      "RL0051                                                                                                                                            NaN  \n",
      "RL0052                                                                                                                                            NaN  \n",
      "RL0053                                                                                                                                            NaN  \n",
      "RL0054                                                                                                                                            NaN  \n",
      "SN0001                                                                                                                                            NaN  \n",
      "SN0002                                                                                                                                            NaN  \n",
      "SN0003                                                                                                                                            NaN  \n",
      "SN0004                                                                                                                                            NaN  \n",
      "SN0005                                                                                                                                            NaN  \n",
      "SN0006                                                                                                                                            NaN  \n",
      "SN0007                                                                                                                                            NaN  \n",
      "SN0008                                                                                                                                            NaN  \n",
      "SN0009                                                                                                                                            NaN  \n",
      "SN0010                                                                                                                                            NaN  \n",
      "SN0011                                                                                                                                            NaN  \n",
      "SN0012                                                                                                                                            NaN  \n",
      "SN0013                                                                                                                                            NaN  \n",
      "SN0014                                                                                                                                            NaN  \n",
      "UC0001                                                                                                                                            NaN  \n",
      "UC0002                                                                                                                                            NaN  \n",
      "UC0003                                                                                                                                            NaN  \n",
      "UC0004                                                                                                                                            NaN  \n",
      "NH0001                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0002                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0003                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0004                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0005                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0006                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0007                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0008                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0009                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0010                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0011                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0012                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0013                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0014                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0015                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "NH0016                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0001                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0002                                                                                                                                            NaN  \n",
      "QQ0003                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0004                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0005                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0006                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0007                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0008                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0009                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0010                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0011                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0012                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0013                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0014                         https://www.dropbox.com/scl/fi/kfs0932cthnikkiypop6q/scRNA_ileal_metadata_CD.xlsx?dl=0&rlkey=ttjjckpx3bziklzo5hq544kcj  \n",
      "QQ0015                                                                                                                                            NaN  \n",
      "QQ0016                                                                                                                                            NaN  \n",
      "QQ0017                                                                                                                                            NaN  \n",
      "QQ0018                                                                                                                                            NaN  \n",
      "QQ0019                                                                                                                                            NaN  \n",
      "QQ0020                                                                                                                                            NaN  \n",
      "QQ0021                                                                                                                                            NaN  \n",
      "QQ0022                                                                                                                                            NaN  \n",
      "QQ0023                                                                                                                                            NaN  \n",
      "QQ0024                                                                                                                                            NaN  \n",
      "QQ0025                                                                                                                                            NaN  \n",
      "QQ0026                                                                                                                                            NaN  \n",
      "QQ0027                                                                                                                                            NaN  \n",
      "QQ0028                                                                                                                                            NaN  \n",
      "QQ0029                                                                                                                                            NaN  \n",
      "QQ0030                                                                                                                                            NaN  \n",
      "QQ0031                                                                                                                                            NaN  \n",
      "QQ0032                                                                                                                                            NaN  \n",
      "QQ0033                                                                                                                                            NaN  \n",
      "QQ0034                                                                                                                                            NaN  \n",
      "AA1inf                                                                                                                                            NaN  \n",
      "AA1non                                                                                                                                            NaN  \n",
      "QQ0035                                                                                                                                            NaN  \n",
      "QQ0036                                                                                                                                            NaN  \n",
      "QQ0037                                                                                                                                            NaN  \n",
      "QQ0038                                                                                                                                            NaN  \n",
      "QQ0039                                                                                                                                            NaN  \n",
      "QQ0040                                                                                                                                            NaN  \n",
      "QQ0041                                                                                                                                            NaN  \n",
      "QQ0042                                                                                                                                            NaN  \n",
      "QQ0043                                                                                                                                            NaN  \n",
      "QQ0044                                                                                                                                            NaN  \n",
      "QQ0045                                                                                                                                            NaN  \n",
      "QQ0046                                                                                                                                            NaN  \n",
      "QQ0047                                                                                                                                            NaN  \n",
      "QQ0048                                                                                                                                            NaN  \n",
      "QQ0049                                                                                                                                            NaN  \n",
      "QQ0050                                                                                                                                            NaN  \n",
      "QQ0051                                                                                                                                            NaN  \n",
      "QQ0052                                                                                                                                            NaN  \n",
      "QQ0053                                                                                                                                            NaN  \n",
      "QQ0054                                                                                                                                            NaN  \n",
      "QQ0055                                                                                                                                            NaN  \n",
      "QQ0056                                                                                                                                            NaN  \n",
      "QQ0057                                                                                                                                            NaN  \n",
      "QQ0058                                                                                                                                            NaN  \n",
      "QQ0059                                                                                                                                            NaN  \n",
      "KC0004                                                                                                                                            NaN  \n",
      "KC0002                                                                                                                                            NaN  \n",
      "KC0003                                                                                                                                            NaN  \n",
      "KC0005                                                                                                                                            NaN  \n",
      "KC0001                                                                                                                                            NaN  \n",
      "CD0001                                                                                                                                            NaN  \n",
      "CD0002                                                                                                                                            NaN  \n",
      "CD0003                                                                                                                                            NaN  \n",
      "CD0004                                                                                                                                            NaN  \n"
     ]
    }
   ],
   "source": [
    "# Load Google Sheets Database\n",
    "key_cols = list(pd.unique(cols_should_be_unique + cols_subject))\n",
    "if path_file is None:\n",
    "    dff = get_google_sheet(id_sheet, path_secret)\n",
    "    if any(dff.duplicated(unique_id)):\n",
    "        raise ValueError(f\"{unique_id} is repeated and can\"\"t be used as the true unique id column.\")\n",
    "    else:\n",
    "        if unique_id in cols_should_be_unique:\n",
    "            cols_should_be_unique.remove(unique_id)\n",
    "else:\n",
    "    dff = pd.read_csv(path_file)\n",
    "dff = dff.set_index(unique_id)\n",
    "print(dff)\n",
    "\n",
    "# Load REDCap Configuration File\n",
    "with open(path_config, \"r\") as json_file:\n",
    "    config = json.load(json_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REDCap Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Status: 200\n",
      "HTTP Status: 200\n",
      "dict_keys(['field_names', 'record_ids', 'data_dictionary'])\n",
      "          field_name                          form_name section_header  \\\n",
      "record_id  record_id  sample_information_3_gex_multiome                  \n",
      "lib_id_1    lib_id_1  sample_information_3_gex_multiome                  \n",
      "lib_id_2    lib_id_2  sample_information_3_gex_multiome                  \n",
      "lib_id_3    lib_id_3  sample_information_3_gex_multiome                  \n",
      "lib_id_4    lib_id_4  sample_information_3_gex_multiome                  \n",
      "\n",
      "          field_type                                        field_label  \\\n",
      "record_id       text                                          Record ID   \n",
      "lib_id_1        text  ID UNIQUE TO THE SAMPLE AND MEASUREMENT. This ...   \n",
      "lib_id_2        text                                                      \n",
      "lib_id_3        text                                                      \n",
      "lib_id_4        text                                                      \n",
      "\n",
      "          select_choices_or_calculations  \\\n",
      "record_id                                  \n",
      "lib_id_1                                   \n",
      "lib_id_2                                   \n",
      "lib_id_3                                   \n",
      "lib_id_4                                   \n",
      "\n",
      "                                                  field_note  \\\n",
      "record_id  Standardized subject ID (or Sequencing Batch I...   \n",
      "lib_id_1                                                       \n",
      "lib_id_2                                                       \n",
      "lib_id_3                                                       \n",
      "lib_id_4                                                       \n",
      "\n",
      "          text_validation_type_or_show_slider_number text_validation_min  \\\n",
      "record_id                                                                  \n",
      "lib_id_1                                                                   \n",
      "lib_id_2                                                                   \n",
      "lib_id_3                                                                   \n",
      "lib_id_4                                                                   \n",
      "\n",
      "          text_validation_max identifier branching_logic required_field  \\\n",
      "record_id                                                                 \n",
      "lib_id_1                                                              y   \n",
      "lib_id_2                                                                  \n",
      "lib_id_3                                                                  \n",
      "lib_id_4                                                                  \n",
      "\n",
      "          custom_alignment question_number matrix_group_name matrix_ranking  \\\n",
      "record_id                                                                     \n",
      "lib_id_1                                                                      \n",
      "lib_id_2                                                                      \n",
      "lib_id_3                                                                      \n",
      "lib_id_4                                                                      \n",
      "\n",
      "          field_annotation  \n",
      "record_id                   \n",
      "lib_id_1                    \n",
      "lib_id_2                    \n",
      "lib_id_3                    \n",
      "lib_id_4                    \n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "project = \"Cho Lab Single Cell Sample Metadatabase\"\n",
    "api_url, token = config[project][\"url\"], config[project][\"token\"]\n",
    "drc = get_redcap_metadata(project, api_url, token)\n",
    "print(drc.keys())\n",
    "data_dict = pd.concat([pd.Series(x, name=x[\"field_name\"]) \n",
    "                       for x in drc[\"data_dictionary\"]], axis=1).T\n",
    "print(data_dict.head())\n",
    "pd.set_option(\"display.max_colwidth\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "project\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "project\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "field_name                                  project\n",
      "form_name         sample_information_3_gex_multiome\n",
      "section_header                                     \n",
      "field_type                                 dropdown\n",
      "field_label                                 Project\n",
      "Name: project, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, Ileal CD | 2, UC | 3, Zebrafish | 4, Mouse Organoid | 5, PBMC | 6, Perianal CD | 7, Ileal CD/PTGER4 | 8, PSC-IBD | 9, CRISPR Screening of Monocytes | 10, Ileal CD gp130 | 888, Other, please specify\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['CRISPR Screening' 'Zebrafish Felix_Josh' 'PBMC' 'Perianal CD'\n",
      " 'Zebrafish Shikha' 'Ileal CD gp130' 'UC_ZC_sc' 'Mouse Organoid' 'UC'\n",
      " 'Ileal CD' 'Ileal CD/PTGER4']\n",
      "False\n",
      "inflam_status\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "inflam_status\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column inflam_status to partial match: inflam_status_1\n",
      "field_name                          inflam_status_1\n",
      "form_name         sample_information_3_gex_multiome\n",
      "section_header                                     \n",
      "field_type                                    radio\n",
      "field_label                     Inflammation Status\n",
      "Name: inflam_status_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [no_of_samples_3_prime] = '1' or [no_of_samples_3_prime] = '2' or [no_of_samples_3_prime] = '3' or [no_of_samples_3_prime] = '4' or [no_of_samples_3_prime] = '5' or [no_of_samples_3_prime] = '6' or [no_of_samples_3_prime] = '7' or [no_of_samples_3_prime] = '8' or [no_of_samples_multiome] = '1' or [no_of_samples_multiome] = '2' or [no_of_samples_multiome] = '3' or [no_of_samples_multiome] = '4' or [no_of_samples_multiome] = '5' or [no_of_samples_multiome] = '6' or [no_of_samples_multiome] = '7' or [no_of_samples_multiome] = '8'\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, Inflamed | 2, Non-inflamed | 3, Healthy Control | 4, Other, please specify   {other_inflam_status}\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['Non-inflamed' 'Inflamed_acute' 'PBMC' '~Non-infl. active fistula'\n",
      " 'non-inflamed' 'Inflamed' 'Inflamed*' 'inflamed_Chronic' 'inflamed'\n",
      " 'Induced inflamed' 'Non-Inflamed' 'Healthy Control' 'inflamed_acute'\n",
      " 'inflamed_chronic']\n",
      "False\n",
      "disease\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "disease\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "field_name                                  disease\n",
      "form_name         sample_information_3_gex_multiome\n",
      "section_header                                     \n",
      "field_type                                    radio\n",
      "field_label                                 Disease\n",
      "Name: disease, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [organism] = '1'\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, Crohn's Disease | 2, Ulcerative Colitis | 3, Healthy Control | 888, Other, please specify   {other_disease}\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['CD' nan 'UC' 'Healthy']\n",
      "False\n",
      "organism\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "organism\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "field_name                                                                                                                                                  organism\n",
      "form_name                                                                                                                          sample_information_3_gex_multiome\n",
      "section_header    <div class=\"rich-text-field-label\"><div class=\"rich-text-field-label\"> <p style=\"text-align: left;\">Clinical/Organism Information</p> </div></div>\n",
      "field_type                                                                                                                                                     radio\n",
      "field_label                                                                                                                                                 Organism\n",
      "Name: organism, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, Human | 2, Zebrafish | 3, Mouse\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['Human' 'Zebrafish' 'Mouse']\n",
      "False\n",
      "disease_status\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "disease_status\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "field_name                           disease_status\n",
      "form_name         sample_information_3_gex_multiome\n",
      "section_header                                     \n",
      "field_type                                    radio\n",
      "field_label                          Disease Status\n",
      "Name: disease_status, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [organism] = '1' and [disease] = '1' or [disease] = '2' or [disease] = '888'\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, Active | 2, Inactive | 3, In remission | 888, Other | 999, N/A\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['Remisson' nan 'Active' 'active' 'Remission' 'Active + Fistula'\n",
      " 'Remission + Fistula' 'Active + Fistula?' 'Active + stenosis'\n",
      " 'Active + fistula']\n",
      "False\n",
      "index_kit\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "index_kit\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column index_kit to partial match: index_kit_1\n",
      "field_name                        index_kit_1\n",
      "form_name         library_prep_3_gex_multiome\n",
      "section_header                               \n",
      "field_type                              radio\n",
      "field_label                         Index Kit\n",
      "Name: index_kit_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [type_of_experiment(3prime)] = '1'\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, Dual Index TT | 2, Dual Index TS\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['SI-TT-E2' 'SI-TT-D1' 'SI-TT-D2' 'SI-TT-D3' 'SI-TT-D4' 'SI-TT-D7'\n",
      " 'SI-NA-C2' 'SI-TT-E5' 'SI-NA-F2' 'SI-TT-E6' 'SI-NA-G2' 'SI-TT-E1'\n",
      " 'SI-TT-A11' 'SI-TT-A12' 'SI-TT-G7' 'SI-TT-G8' 'SI-TT-A1' 'SI-TT-A2'\n",
      " 'SI-NA-A1' 'SI-NA-B1' 'SI-TT-A9' 'SI-TT-A10' 'SI-TT-A7' 'SI-TT-A8'\n",
      " 'SI-NA-C1' 'SI-NA-D1' 'SI-TT-B1' 'SI-TT-B2' 'SI-TT-B9' 'SI-TT-B10'\n",
      " 'SI-TT-B4' 'SI-TT-B5' 'SI-TT-B8' 'SI-TT-B11' 'SI-TT-C3' 'SI-TT-C4'\n",
      " 'SI-NA-E1' 'SI-NA-F1' 'SI-TT-C1' 'SI-TT-C2' 'SI-TT-C5' 'SI-TT-C6'\n",
      " 'SI-NA-G1' 'SI-NA-H1' 'SI-TT-C9' 'SI-TT-C10' 'SI-TT-D5' 'SI-TT-D6'\n",
      " 'SI-NA-A2' 'SI-NA-B2' 'SI-TT-D10' 'SI-TT-D11' 'SI-TT-D8' 'SI-TT-D9'\n",
      " 'SI-NA-D2' 'SI-NA-E2' 'SI-TT-D12' 'SI-TT-E3' 'SI-TT-E4' 'SI-TT-F5'\n",
      " 'SI-N-D3' 'SI-TT-F3' 'SI-TT-F4' 'SI-TT-G10' 'SI-TT-G11' nan 'SI-TT-H1'\n",
      " 'SI-TT-H2' 'SI-TT-H3' 'SI-TT-H4' 'SI-TT-A3' 'SI-TT-A4' 'SI-TT-A5'\n",
      " 'SI-TT-A6' 'SI-TT-B6' 'SI-TT-B7' 'SI-TT-H9' 'SI-TT-H10' 'SI-TT-H11'\n",
      " 'SI-TT-H12' 'SI-TT-H5' 'SI-TT-H6' 'SI-TT-H7' 'SI-TT-H8']\n",
      "False\n",
      "instrument\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "instrument\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column instrument to partial match: instrument_1\n",
      "field_name        instrument_1\n",
      "form_name           sequencing\n",
      "section_header                \n",
      "field_type               radio\n",
      "field_label         Instrument\n",
      "Name: instrument_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, NovaSeq 6000 | 2, NextSeq 2000 | 3, Not Sequenced\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['NovaSeq S4' 'NovaSeq SP' 'NovaSeq S1' 'Not Sequenced' 'NovaSeq S2' nan]\n",
      "False\n",
      "x_chem_version_sc\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "x_chem_version_sc\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column x_chem_version_sc to partial match: x_chem_version_sc_1\n",
      "field_name                          x_chem_version_sc_1\n",
      "form_name             sample_information_3_gex_multiome\n",
      "section_header                                         \n",
      "field_type                                     dropdown\n",
      "field_label       10x Chemistry Version: Single Cell 3'\n",
      "Name: x_chem_version_sc_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [type_of_experiment(3prime)] = '1'\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, v1 | 2, v2 | 3, v3 | 4, v3.1\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " [3.1 1.  3.  2. ]\n",
      "False\n",
      "tissue_origin\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "tissue_origin\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column tissue_origin to partial match: tissue_origin_1\n",
      "field_name                          tissue_origin_1\n",
      "form_name         sample_information_3_gex_multiome\n",
      "section_header                                     \n",
      "field_type                                 dropdown\n",
      "field_label           Tissue Origin (if applicable)\n",
      "Name: tissue_origin_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [no_of_samples_3_prime] = '1' or [no_of_samples_3_prime] = '2' or [no_of_samples_3_prime] = '3' or [no_of_samples_3_prime] = '4' or [no_of_samples_3_prime] = '5' or [no_of_samples_3_prime] = '6' or [no_of_samples_3_prime] = '7' or [no_of_samples_3_prime] = '8' or [no_of_samples_multiome] = '1' or [no_of_samples_multiome] = '2' or [no_of_samples_multiome] = '3' or [no_of_samples_multiome] = '4' or [no_of_samples_multiome] = '5' or [no_of_samples_multiome] = '6' or [no_of_samples_multiome] = '7' or [no_of_samples_multiome] = '8'\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, Terminal Ileum | 2, Ascending colon | 3, Transverse colon | 4, Descending colon | 5, Sigmoid colon | 6, Sigmoid-rectum | 7, Rectum | 888, Other | 999, N/A\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['PBMC' 'Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes'\n",
      " 'Rectum' 'Sigmoid' 'Rectum, proctectomy, biopsies'\n",
      " 'Sigmoid, proctectomy, biopsies' 'Rectum, colonoscopy, biopsies'\n",
      " 'Terminal ileum, colonoscopy, biopsies'\n",
      " 'Sigmoid colon, colonoscopy, biopsies' 'Rectum, proectectomy, biopsies'\n",
      " 'Fistula tract lining, proctectomy, biopsies'\n",
      " 'Rectum, proctectomy --> biopsies' 'Fistula, proctectomy --> biopsies'\n",
      " 'Larval intestinal dissection' 'Terminal ileum' 'PBMCs' 'sigmoid, biopsy'\n",
      " 'rectum, biopsy' 'Transverse Colon, biopsy'\n",
      " 'Colon organoid (excl. cecum)' 'Rectum (10cm)-Inflamed Biopsy'\n",
      " 'Sigmoid (35cm)- Uninflamed Biopsy' 'Rectum (10cm)-  Inflamed Biopsy'\n",
      " 'Sigmoid (25cm)- Uninflamed Biopsy' 'Ileum resection'\n",
      " 'Terminal Ileum Resection, Biopsies ' 'Whole blood'\n",
      " 'Colectomy, Biopsies from sigmoid colon'\n",
      " 'Colectomy, Biopsies from transverse colon' 'Ileal resection'\n",
      " 'Terminal Ileal Resection, Biopsies ']\n"
     ]
    }
   ],
   "source": [
    "fields_cat = list(data_dict[data_dict.field_type.isin([\"radio\", \"dropdown\"])].index)\n",
    "fields_cat = list(set(pd.unique([re.sub(\"_[0-9]+\", \"\", x) \n",
    "                                 for x in fields_cat])).intersection(dff.columns))\n",
    "for x in fields_cat:\n",
    "    investigate_fields(x, data_rc=data_dict, data_meta=dff, pattern=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Information\n",
    "\n",
    "## Repeated Measures\n",
    "\n",
    "### Improperly Repeated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   duplicates standard_sample_id     record_id  \\\n",
      "lib_id                                                           \n",
      "LC0001     standard_sample_id        FC_Hu_sCD_1     FC_Hu_sCD   \n",
      "LC0002     standard_sample_id        FC_Hu_sCD_1     FC_Hu_sCD   \n",
      "LC0003     standard_sample_id        FC_Hu_sUC_1     FC_Hu_sUC   \n",
      "LC0004     standard_sample_id        FC_Hu_sUC_1     FC_Hu_sUC   \n",
      "LC0005     standard_sample_id         FC_Hu_sH_1      FC_Hu_sH   \n",
      "LC0006     standard_sample_id         FC_Hu_sH_1      FC_Hu_sH   \n",
      "RL0001     standard_sample_id      RL_Hu_AA2_Inf     RL_Hu_AA2   \n",
      "RL0001_re  standard_sample_id      RL_Hu_AA2_Inf     RL_Hu_AA2   \n",
      "RL0002     standard_sample_id      RL_Hu_AA2_Non     RL_Hu_AA2   \n",
      "RL0002_re  standard_sample_id      RL_Hu_AA2_Non     RL_Hu_AA2   \n",
      "RL0005     standard_sample_id      RL_Hu_AA3_Inf     RL_Hu_AA3   \n",
      "RL0006     standard_sample_id      RL_Hu_AA3_Non     RL_Hu_AA3   \n",
      "RL0007     standard_sample_id      RL_Hu_AA3_Inf     RL_Hu_AA3   \n",
      "RL0008     standard_sample_id      RL_Hu_AA3_Non     RL_Hu_AA3   \n",
      "RL0009     standard_sample_id      RL_Hu_AA3_Inf     RL_Hu_AA3   \n",
      "RL0010     standard_sample_id      RL_Hu_AA3_Non     RL_Hu_AA3   \n",
      "RL0011     standard_sample_id     RL_Hu_EA2_Rect     RL_Hu_EA2   \n",
      "RL0012     standard_sample_id      RL_Hu_EA2_Non     RL_Hu_EA2   \n",
      "RL0013     standard_sample_id     RL_Hu_EA2_Rect     RL_Hu_EA2   \n",
      "RL0014     standard_sample_id      RL_Hu_EA2_Non     RL_Hu_EA2   \n",
      "RL0015     standard_sample_id     RL_Hu_EA2_Rect     RL_Hu_EA2   \n",
      "RL0016     standard_sample_id      RL_Hu_EA2_Non     RL_Hu_EA2   \n",
      "RL0023     standard_sample_id     RL_Hu_AA6_Rect     RL_Hu_AA6   \n",
      "RL0024     standard_sample_id      RL_Hu_AA6_Non     RL_Hu_AA6   \n",
      "RL0025     standard_sample_id     RL_Hu_AA6_Rect     RL_Hu_AA6   \n",
      "RL0026     standard_sample_id      RL_Hu_AA6_Non     RL_Hu_AA6   \n",
      "RL0027     standard_sample_id     RL_Hu_AA6_Rect     RL_Hu_AA6   \n",
      "RL0028     standard_sample_id      RL_Hu_AA6_Non     RL_Hu_AA6   \n",
      "RL0029     standard_sample_id     RL_Hu_EA4_Rect     RL_Hu_EA4   \n",
      "RL0030     standard_sample_id      RL_Hu_EA4_Non     RL_Hu_EA4   \n",
      "RL0031     standard_sample_id     RL_Hu_EA4_Rect     RL_Hu_EA4   \n",
      "RL0032     standard_sample_id      RL_Hu_EA4_Non     RL_Hu_EA4   \n",
      "RL0033     standard_sample_id     RL_Hu_EA4_Rect     RL_Hu_EA4   \n",
      "RL0034     standard_sample_id      RL_Hu_EA4_Non     RL_Hu_EA4   \n",
      "RL0037     standard_sample_id     RL_Hu_EA5_Rect     RL_Hu_EA5   \n",
      "RL0038     standard_sample_id      RL_Hu_EA5_Non     RL_Hu_EA5   \n",
      "RL0039     standard_sample_id     RL_Hu_EA5_Rect     RL_Hu_EA5   \n",
      "RL0040     standard_sample_id      RL_Hu_EA5_Non     RL_Hu_EA5   \n",
      "RL0041     standard_sample_id     RL_Hu_EA5_Rect     RL_Hu_EA5   \n",
      "RL0042     standard_sample_id      RL_Hu_EA5_Non     RL_Hu_EA5   \n",
      "RL0043     standard_sample_id     RL_Hu_AA7_Rect     RL_Hu_AA7   \n",
      "RL0044     standard_sample_id      RL_Hu_AA7_Non     RL_Hu_AA7   \n",
      "RL0045     standard_sample_id     RL_Hu_AA7_Rect     RL_Hu_AA7   \n",
      "RL0046     standard_sample_id      RL_Hu_AA7_Non     RL_Hu_AA7   \n",
      "RL0047     standard_sample_id     RL_Hu_AA7_Rect     RL_Hu_AA7   \n",
      "RL0048     standard_sample_id      RL_Hu_AA7_Non     RL_Hu_AA7   \n",
      "RL0051     standard_sample_id        RL_Hu_EA7_R     RL_Hu_EA7   \n",
      "RL0052     standard_sample_id        RL_Hu_EA7_R     RL_Hu_EA7   \n",
      "RL0054     standard_sample_id        RL_Hu_EA7_R     RL_Hu_EA7   \n",
      "SN0009     standard_sample_id      SN_Ze_WT2_Non     SN_Ze_WT2   \n",
      "SN0010     standard_sample_id      SN_Ze_WT2_DSS     SN_Ze_WT2   \n",
      "QQ0035     standard_sample_id       FC_Ze_WT_DSS    FC_Ze_WT03   \n",
      "QQ0036     standard_sample_id       FC_Ze_WT_DSS  FC_Ze_WTJM02   \n",
      "QQ0039     standard_sample_id    FC_Ze_WT_hGMCSF    FC_Ze_WT02   \n",
      "QQ0040     standard_sample_id    FC_Ze_WT_hGMCSF  FC_Ze_WTJM03   \n",
      "QQ0041     standard_sample_id       FC_Ze_WT_Non    FC_Ze_WT01   \n",
      "QQ0042     standard_sample_id       FC_Ze_WT_Non    FC_Ze_WT05   \n",
      "QQ0043     standard_sample_id       FC_Ze_WT_Non  FC_Ze_WTJM01   \n",
      "QQ0051     standard_sample_id      SN_Ze_WT2_DSS     SN_Ze_WT2   \n",
      "QQ0052     standard_sample_id      SN_Ze_WT2_Non     SN_Ze_WT2   \n",
      "\n",
      "                  record_id1       grid patient_id  \n",
      "lib_id                                              \n",
      "LC0001     Sabic_Project_022  1010893.0       sCD1  \n",
      "LC0002     Sabic_Project_021  1010893.0       sCD1  \n",
      "LC0003     Sabic_Project_022  1010933.0       sUC1  \n",
      "LC0004     Sabic_Project_021  1010933.0       sUC1  \n",
      "LC0005     Sabic_Project_022  1010934.0         sH  \n",
      "LC0006     Sabic_Project_021  1010934.0         sH  \n",
      "RL0001     Sabic_Project_011  1010711.0        AA4  \n",
      "RL0001_re  Sabic_Project_013  1010711.0        AA4  \n",
      "RL0002     Sabic_Project_011  1010711.0        AA4  \n",
      "RL0002_re  Sabic_Project_011  1010711.0        AA4  \n",
      "RL0005     Sabic_Project_013  1010733.0        AA5  \n",
      "RL0006     Sabic_Project_016  1010733.0        AA5  \n",
      "RL0007                   NaN  1010733.0        AA5  \n",
      "RL0008     Sabic_Project_016  1010733.0        AA5  \n",
      "RL0009                   NaN  1010733.0        AA5  \n",
      "RL0010     Sabic_Project_015  1010733.0        AA5  \n",
      "RL0011     Sabic_Project_013  1010758.0        EA3  \n",
      "RL0012     Sabic_Project_013  1010758.0        EA3  \n",
      "RL0013     Sabic_Project_016  1010758.0        EA3  \n",
      "RL0014     Sabic_Project_016  1010758.0        EA3  \n",
      "RL0015     Sabic_Project_015  1010758.0        EA3  \n",
      "RL0016     Sabic_Project_015  1010758.0        EA3  \n",
      "RL0023     Sabic_Project_016  1002363.0        AA8  \n",
      "RL0024     Sabic_Project_016  1002363.0        AA8  \n",
      "RL0025     Sabic_Project_016  1002363.0        AA8  \n",
      "RL0026     Sabic_Project_016  1002363.0        AA8  \n",
      "RL0027     Sabic_Project_015  1002363.0        AA8  \n",
      "RL0028     Sabic_Project_015  1002363.0        AA8  \n",
      "RL0029     Sabic_Project_016  1010800.0        EA5  \n",
      "RL0030     Sabic_Project_016  1010800.0        EA5  \n",
      "RL0031     Sabic_Project_016  1010800.0        EA5  \n",
      "RL0032     Sabic_Project_016  1010800.0        EA5  \n",
      "RL0033     Sabic_Project_015  1010800.0        EA5  \n",
      "RL0034     Sabic_Project_015  1010800.0        EA5  \n",
      "RL0037     Sabic_Project_020  1010890.0        EA6  \n",
      "RL0038     Sabic_Project_020  1010890.0        EA6  \n",
      "RL0039     Sabic_Project_021  1010890.0        EA6  \n",
      "RL0040     Sabic_Project_021  1010890.0        EA6  \n",
      "RL0041     Sabic_Project_020  1010890.0        EA6  \n",
      "RL0042     Sabic_Project_020  1010890.0        EA6  \n",
      "RL0043     Sabic_Project_020  1010895.0        AA9  \n",
      "RL0044     Sabic_Project_020  1010895.0        AA9  \n",
      "RL0045     Sabic_Project_021  1010895.0        AA9  \n",
      "RL0046     Sabic_Project_021  1010895.0        AA9  \n",
      "RL0047     Sabic_Project_020  1010895.0        AA9  \n",
      "RL0048     Sabic_Project_020  1010895.0        AA9  \n",
      "RL0051     Sabic_Project_022  1010558.0        EA8  \n",
      "RL0052     Sabic_Project_025  1010558.0        EA8  \n",
      "RL0054     Sabic_Project_022  1010558.0        EA8  \n",
      "SN0009     Sabic_Project_013        NaN        NaN  \n",
      "SN0010     Sabic_Project_013        NaN        NaN  \n",
      "QQ0035                   NaN        NaN        NaN  \n",
      "QQ0036                   NaN        NaN        NaN  \n",
      "QQ0039                   NaN        NaN        NaN  \n",
      "QQ0040                   NaN        NaN        NaN  \n",
      "QQ0041                   NaN        NaN        NaN  \n",
      "QQ0042                   NaN        NaN        NaN  \n",
      "QQ0043                   NaN        NaN        NaN  \n",
      "QQ0051                   NaN        NaN        NaN  \n",
      "QQ0052                   NaN        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "dups = pd.concat([dff.duplicated(subset=x, keep=False) for x in cols_should_be_unique], \n",
    "                 keys=cols_should_be_unique, axis=1)  # detect improper duplicates\n",
    "dups = dups[dups.T.any().T]  # only keep rows where at least 1 improper duplicate\n",
    "dups = dups.apply(lambda x: x.replace(True, x.name).replace(False, np.nan)).apply(\n",
    "    lambda y: str(y.dropna().iloc[0]) if any(pd.isnull(y)) else \", \".join(list(y)), \n",
    "    axis=1)  # series with text saying which columns duplicated for each row\n",
    "dff_dup = dff.loc[dups.index].join(dups.to_frame(\"duplicates\"))\n",
    "print(dff_dup[[\"duplicates\"] + key_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Expand/Already Expanded REDCap Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard_sample_id: ['standard_sample_id_1', 'standard_sample_id_2', 'standard_sample_id_3', 'standard_sample_id_4', 'standard_sample_id_5', 'standard_sample_id_6', 'standard_sample_id_7', 'standard_sample_id_8']\n",
      "inflam_status: ['inflam_status_1', 'other_inflam_status_1', 'inflam_status_chronicity_1', 'inflam_status_2', 'other_inflam_status_2', 'inflam_status_chronicity_2', 'inflam_status_3', 'other_inflam_status_3', 'inflam_status_chronicity_3', 'inflam_status_4', 'other_inflam_status_4', 'inflam_status_5', 'other_inflam_status_5', 'inflam_status_6', 'other_inflam_status_6', 'inflam_status_7', 'other_inflam_status_7', 'inflam_status_8', 'other_inflam_status_8']\n",
      "no_live_cells: ['no_live_cells_1', 'no_live_cells_2', 'no_live_cells_3', 'no_live_cells_4', 'no_live_cells_5', 'no_live_cells_6', 'no_live_cells_7', 'no_live_cells_8']\n",
      "cell_viability_percentage: ['cell_viability_percentage_1', 'cell_viability_percentage_2', 'cell_viability_percentage_3', 'cell_viability_percentage_4', 'cell_viability_percentage_5', 'cell_viability_percentage_6', 'cell_viability_percentage_7', 'cell_viability_percentage_8']\n",
      "index_kit: ['index_kit_1', 'index_kit_2', 'index_kit_3', 'index_kit_4', 'index_kit_5', 'index_kit_6', 'index_kit_7', 'index_kit_8', 'index_kit_scm']\n",
      "record_id1: []\n",
      "type_of_experiment: []\n",
      "no_live_nuclei: ['no_live_nuclei_1', 'no_live_nuclei_2', 'no_live_nuclei_3', 'no_live_nuclei_4', 'no_live_nuclei_5', 'no_live_nuclei_6', 'no_live_nuclei_7', 'no_live_nuclei_8']\n",
      "no_nuclei: ['no_nuclei_1', 'no_nuclei_2', 'no_nuclei_3', 'no_nuclei_4', 'no_nuclei_5', 'no_nuclei_6', 'no_nuclei_7', 'no_nuclei_8']\n",
      "date_sent: ['date_sent_1', 'date_sent_2', 'date_sent_3', 'date_sent_4', 'date_sent_5', 'date_sent_6', 'date_sent_7', 'date_sent_8']\n",
      "instrument: ['instrument_1', 'instrument_2', 'instrument_3', 'instrument_4', 'instrument_5', 'instrument_6', 'instrument_7', 'instrument_8']\n",
      "ref_genome: []\n",
      "tissue_origin: ['tissue_origin_1', 'other_tissue_origin_1', 'tissue_origin_2', 'other_tissue_origin_2', 'tissue_origin_3', 'other_tissue_origin_3', 'tissue_origin_4', 'other_tissue_origin_4', 'tissue_origin_5', 'other_tissue_origin_5', 'tissue_origin_6', 'other_tissue_origin_6', 'tissue_origin_7', 'other_tissue_origin_7', 'tissue_origin_8', 'other_tissue_origin_8']\n",
      "data_link: []\n",
      "sc_process_date: ['sc_process_date_1', 'sc_process_date_2', 'sc_process_date_3', 'sc_process_date_4', 'sc_process_date_5', 'sc_process_date_6', 'sc_process_date_7', 'sc_process_date_8']\n",
      "inflam_treatment: []\n",
      "inflam_treatment_type: []\n",
      "pre_amp_date: ['pre_amp_date_1', 'pre_amp_date_2', 'pre_amp_date_3', 'pre_amp_date_4', 'pre_amp_date_5', 'pre_amp_date_6', 'pre_amp_date_7', 'pre_amp_date_8']\n",
      "targ_cell: ['targ_cell_1', 'targ_cell_2', 'targ_cell_3', 'targ_cell_4', 'targ_cell_5', 'targ_cell_6', 'targ_cell_7', 'targ_cell_8']\n",
      "x_chem_version_sc: ['x_chem_version_sc_1', 'x_chem_version_sc_2', 'x_chem_version_sc_3', 'x_chem_version_sc_4', 'x_chem_version_sc_5', 'x_chem_version_sc_6', 'x_chem_version_sc_7', 'x_chem_version_sc_8']\n",
      "repeat_data_release: []\n",
      "repeat_seq_platform: []\n",
      "inflam_treatment_concentration_DSS: []\n",
      "inflam_treatment_quantity_DSS: []\n",
      "inflam_treatment_quantity_BZA: []\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Create RM columns in REDCap for: type_of_experiment\n"
     ]
    }
   ],
   "source": [
    "expansion = dff.groupby(cols_subject[0]).apply(\n",
    "    lambda x: list(pd.Series([c if len(pd.unique(x[c])) > 1 else np.nan \n",
    "                         for c in dff.columns]).dropna())).apply(\n",
    "                             lambda y: np.nan if len(y) == 0 else y).dropna()\n",
    "cols_to_expand = list(pd.unique(expansion.explode()))\n",
    "for x in rm_cols_collapsed:\n",
    "    if x in cols_to_expand:\n",
    "        cols_to_expand.remove(x)\n",
    "already_expanded = dict(zip(cols_to_expand, [] * len(cols_to_expand)))\n",
    "for i in cols_to_expand:\n",
    "    already_expanded[i] = list(pd.Series([\n",
    "        d if i in d and i != d else np.nan for d in data_dict.index]).dropna())\n",
    "_ = [print(f\"{k}: {already_expanded[k]}\") for k in already_expanded]\n",
    "already_expanded_yes = list(pd.Series([k if len(\n",
    "    already_expanded[k]) > 0 else np.nan for k in already_expanded]).dropna())\n",
    "# print(expansion)\n",
    "cols_need = list(set(cols_to_expand).difference(\n",
    "    set(already_expanded_yes)).intersection(\n",
    "        data_dict.index))  # expand to accommodate repeated measures\n",
    "print(f\"\\n\\n\\n{'=' * 80}\\n\\nCreate RM columns in REDCap for: {', '.join(cols_need)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"patient_id\" in cols_need:\n",
    "    cols_need.remove(\"patient_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (In)Varying Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Invarying\n",
      "\n",
      "================================================================================\n",
      "record_id\n",
      "FC_Hu_IL1     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "FC_Hu_IL2                                                          record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "FC_Hu_IL3                                                          record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "FC_Hu_sCD                                                                           standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "FC_Hu_sH                                                     standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, date_sent, ref_genome, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "FC_Hu_sUC                                                    standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, date_sent, ref_genome, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Hu_P10                               no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Hu_P11                    no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Hu_P12                    no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Hu_P13     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Hu_P14                    no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Hu_P15     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Hu_P16     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Hu_P5                     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Hu_P6                     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Hu_P7                     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Hu_P8                     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "JM_Ze_Lck                                                                                                                              no_live_cells, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, instrument, ref_genome, tissue_origin, data_link, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "KC_Hu_CD1                                               index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "NH_Hu_P1                     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "NH_Hu_P2                     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "NH_Hu_P3                     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "NH_Hu_P4                     no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "NH_Mo_KO2                                                                                                   index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, pre_amp_date, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "NH_Mo_KO4                                                                                        index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "NH_Mo_WT1                                                                                                   index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, pre_amp_date, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "NH_Mo_WT3                                                                                        index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_AA1                                                              index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_AA2                                                                                                           type_of_experiment, no_live_nuclei, no_nuclei, instrument, ref_genome, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_AA3                                                                                                                                                                                                   no_live_nuclei, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_AA4                                                                         record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_AA5                                                          inflam_status, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_AA6                                                                                                                                                                                                                  inflam_status, no_live_nuclei, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_AA7                                                                                                                                                                                        inflam_status, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_EA1                                                                         record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_EA2                                                                                                                                                                                                                              inflam_status, no_live_nuclei, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_EA3                                                                         record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_EA4                                                                                                                                                                                                                  inflam_status, no_live_nuclei, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_EA5                                                                                                                                                                                        inflam_status, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_EA6                                                          inflam_status, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_EA7                                                                                                                                                                 inflam_status, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, targ_cell, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "RL_Hu_SA1                                                                         record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "SN_Hu_P13                                                          inflam_status, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "SN_Ze_KO1                                                                                                                                cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_quantity_BZA\n",
      "SN_Ze_KO2                                                                                                                                                               cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform\n",
      "SN_Ze_WT                                                                                                                       type_of_experiment, no_live_nuclei, no_nuclei, ref_genome, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "SN_Ze_WT1                                                                                                                 no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_quantity_BZA\n",
      "SN_Ze_WT2                                                                                                                                                                                                                                                                      type_of_experiment, no_live_nuclei, no_nuclei, ref_genome, tissue_origin, data_link, repeat_data_release, repeat_seq_platform, inflam_treatment_quantity_BZA\n",
      "SN_Ze_WT3                                                                                                                 no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_quantity_BZA\n",
      "SN_Ze_WT4                                                                                                                                cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_quantity_BZA\n",
      "SN_Ze_WT5                                                                                                                                                               cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform\n",
      "SN_Ze_nod2                                                         record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "ZC_Hu_P1                                               cell_viability_percentage, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "ZC_Hu_P2                                                             cell_viability_percentage, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome, data_link, sc_process_date, inflam_treatment, inflam_treatment_type, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "dtype: object\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Varying\n",
      "\n",
      "================================================================================\n",
      "record_id\n",
      "FC_Hu_IL1                                                                                                                                                                                                                                                                      standard_sample_id, inflam_status\n",
      "FC_Hu_IL2                                                                                                                                                                                                                 standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, index_kit\n",
      "FC_Hu_IL3                                                                                                                                                                                                                 standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, index_kit\n",
      "FC_Hu_sCD                                                                                                                                                                                                index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, ref_genome\n",
      "FC_Hu_sH                                                                                                                                                                                                                        index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, instrument\n",
      "FC_Hu_sUC                                                                                                                                                                                                                       index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, instrument\n",
      "JM_Hu_P10                                                                                                                                                                                                                                            standard_sample_id, inflam_status, tissue_origin, data_link\n",
      "JM_Hu_P11                                                                                                                                                                                                                                                       standard_sample_id, inflam_status, tissue_origin\n",
      "JM_Hu_P12                                                                                                                                                                                                                                                       standard_sample_id, inflam_status, tissue_origin\n",
      "JM_Hu_P13                                                                                                                                                                                                                                                                      standard_sample_id, inflam_status\n",
      "JM_Hu_P14                                                                                                                                                                                                                                                       standard_sample_id, inflam_status, tissue_origin\n",
      "JM_Hu_P15                                                                                                                                                                                                                                                                      standard_sample_id, inflam_status\n",
      "JM_Hu_P16                                                                                                                                                                                                                                                                      standard_sample_id, inflam_status\n",
      "JM_Hu_P5                                                                                                                                                                                                                                                        standard_sample_id, inflam_status, tissue_origin\n",
      "JM_Hu_P6                                                                                                                                                                                                                                                        standard_sample_id, inflam_status, tissue_origin\n",
      "JM_Hu_P7                                                                                                                                                                                                                                                        standard_sample_id, inflam_status, tissue_origin\n",
      "JM_Hu_P8                                                                                                                                                                                                                                                        standard_sample_id, inflam_status, tissue_origin\n",
      "JM_Ze_Lck                                                                                                                                             standard_sample_id, inflam_status, cell_viability_percentage, index_kit, date_sent, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date\n",
      "KC_Hu_CD1                                                                                                                                                                                                                            standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage\n",
      "NH_Hu_P1                                                                                                                                                                                                                                                        standard_sample_id, inflam_status, tissue_origin\n",
      "NH_Hu_P2                                                                                                                                                                                                                                                        standard_sample_id, inflam_status, tissue_origin\n",
      "NH_Hu_P3                                                                                                                                                                                                                                                        standard_sample_id, inflam_status, tissue_origin\n",
      "NH_Hu_P4                                                                                                                                                                                                                                                        standard_sample_id, inflam_status, tissue_origin\n",
      "NH_Mo_KO2                                                                                                                                                                        standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, inflam_treatment, inflam_treatment_type, targ_cell\n",
      "NH_Mo_KO4                                                                                                                                                                                   standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, inflam_treatment, inflam_treatment_type\n",
      "NH_Mo_WT1                                                                                                                                                                        standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, inflam_treatment, inflam_treatment_type, targ_cell\n",
      "NH_Mo_WT3                                                                                                                                                                                   standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, inflam_treatment, inflam_treatment_type\n",
      "RL_Hu_AA1                                                                                                                                                                                                             standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, tissue_origin\n",
      "RL_Hu_AA2                                                                                                                                                                standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, index_kit, record_id1, date_sent, tissue_origin, data_link\n",
      "RL_Hu_AA3                                                                        standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, pre_amp_date, targ_cell, x_chem_version_sc\n",
      "RL_Hu_AA4                                                                                                                                                                                                  standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, index_kit, tissue_origin\n",
      "RL_Hu_AA5                                                                                                                                                                                                                 standard_sample_id, no_live_cells, cell_viability_percentage, index_kit, tissue_origin\n",
      "RL_Hu_AA6                                                         standard_sample_id, no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_nuclei, date_sent, instrument, tissue_origin, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform\n",
      "RL_Hu_AA7                                                                                   standard_sample_id, no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, tissue_origin, pre_amp_date, targ_cell, x_chem_version_sc\n",
      "RL_Hu_EA1                                                                                                                                                                                                  standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, index_kit, tissue_origin\n",
      "RL_Hu_EA2                                             standard_sample_id, no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_nuclei, date_sent, instrument, ref_genome, tissue_origin, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform\n",
      "RL_Hu_EA3                                                                                                                                                                                                  standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, index_kit, tissue_origin\n",
      "RL_Hu_EA4                                                         standard_sample_id, no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_nuclei, date_sent, instrument, tissue_origin, pre_amp_date, targ_cell, x_chem_version_sc, repeat_data_release, repeat_seq_platform\n",
      "RL_Hu_EA5                                                                                   standard_sample_id, no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, instrument, tissue_origin, pre_amp_date, targ_cell, x_chem_version_sc\n",
      "RL_Hu_EA6                                                                                                                                                                                                                 standard_sample_id, no_live_cells, cell_viability_percentage, index_kit, tissue_origin\n",
      "RL_Hu_EA7                                                                                                          standard_sample_id, no_live_cells, cell_viability_percentage, index_kit, record_id1, type_of_experiment, no_live_nuclei, no_nuclei, date_sent, tissue_origin, pre_amp_date, x_chem_version_sc\n",
      "RL_Hu_SA1                                                                                                                                                                                                  standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, index_kit, tissue_origin\n",
      "SN_Hu_P13                                                                                                                                                                                                                 standard_sample_id, no_live_cells, cell_viability_percentage, index_kit, tissue_origin\n",
      "SN_Ze_KO1                                                                                                                                           standard_sample_id, inflam_status, no_live_cells, inflam_treatment, inflam_treatment_type, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS\n",
      "SN_Ze_KO2                                                                                                            standard_sample_id, inflam_status, no_live_cells, inflam_treatment, inflam_treatment_type, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "SN_Ze_WT                                                                                                                                                      standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, index_kit, record_id1, date_sent, instrument, pre_amp_date, targ_cell\n",
      "SN_Ze_WT1                                                                                                                                                          standard_sample_id, inflam_status, inflam_treatment, inflam_treatment_type, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS\n",
      "SN_Ze_WT2     standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, index_kit, record_id1, date_sent, instrument, sc_process_date, inflam_treatment, inflam_treatment_type, pre_amp_date, targ_cell, x_chem_version_sc, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS\n",
      "SN_Ze_WT3                                                                                                                                                          standard_sample_id, inflam_status, inflam_treatment, inflam_treatment_type, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS\n",
      "SN_Ze_WT4                                                                                                                                           standard_sample_id, inflam_status, no_live_cells, inflam_treatment, inflam_treatment_type, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS\n",
      "SN_Ze_WT5                                                                                                            standard_sample_id, inflam_status, no_live_cells, inflam_treatment, inflam_treatment_type, inflam_treatment_concentration_DSS, inflam_treatment_quantity_DSS, inflam_treatment_quantity_BZA\n",
      "SN_Ze_nod2                                                                                                                                                                                                                standard_sample_id, inflam_status, no_live_cells, cell_viability_percentage, index_kit\n",
      "ZC_Hu_P1                                                                                                                                                                                                                              standard_sample_id, inflam_status, no_live_cells, index_kit, tissue_origin\n",
      "ZC_Hu_P2                                                                                                                                                                                                                standard_sample_id, inflam_status, no_live_cells, index_kit, tissue_origin, pre_amp_date\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "unique_val_ct = dff.groupby(cols_subject[0]).apply(\n",
    "    lambda x: pd.Series([np.nan]) if len(x) == 1 else pd.Series(\n",
    "        [len(x[c].unique())for c in already_expanded], \n",
    "        index=cols_to_expand)).dropna()\n",
    "invarying_vals = unique_val_ct[unique_val_ct <= 1].dropna().groupby(cols_subject[0]).apply(\n",
    "    lambda x: \", \".join(list([str(i) for i in x.reset_index(0).index.values])))\n",
    "varying_vals = unique_val_ct[unique_val_ct > 1].dropna().groupby(cols_subject[0]).apply(\n",
    "    lambda x: \", \".join(list([str(i) for i in x.reset_index(0).index.values])))\n",
    "print(f\"\\n\\n{'=' * 80}\\n\\nInvarying\\n\\n{'=' * 80}\\n{invarying_vals}\")\n",
    "print(f\"\\n\\n{'=' * 80}\\n\\nVarying\\n\\n{'=' * 80}\\n{varying_vals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Measures Fields\n",
    "\n",
    "### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not convert string to float: 'scm'\n"
     ]
    }
   ],
   "source": [
    "data_dict_old = data_dict.copy()\n",
    "max_rm = max([max([try_float(i.split(\"_\")[-1]) for i in already_expanded[x]]) \n",
    "              if already_expanded[x] else np.nan \n",
    "              for x in already_expanded])  # maximum # repeated measures\n",
    "for x in cols_need:\n",
    "    for i in range(1, int(max_rm) + 1):\n",
    "        data_dict.loc[x + f\"_{i}\", ] = data_dict.loc[x, ]\n",
    "    data_dict = data_dict.drop(x)\n",
    "# data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO\n",
    "# TODOTODOTODOTODOTODOTODOTODOTODOTODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project: {'Ileal CD': '1', 'UC': '2', 'Zebrafish': '3', 'Mouse Organoid': '4', 'PBMC': '5', 'Perianal CD': '6', 'Ileal CD/PTGER4': '7', 'PSC-IBD': '8', 'CRISPR Screening of Monocytes': '9', 'Ileal CD gp130': '10', 'Other': '888'}\n",
      "disease: {\"Crohn's Disease\": '1', 'Ulcerative Colitis': '2', 'Healthy Control': '3', 'Other': '888'}\n",
      "disease_status: {'Active': '1', 'Inactive': '2', 'In remission': '3', 'Other': '888', 'N/A': '999'}\n",
      "organism: {'Human': '1', 'Zebrafish': '2', 'Mouse': '3'}\n",
      "inflam_status: {'Inflamed': '1', 'Non-inflamed': '2', 'Healthy Control': '3', 'Other': '4'}\n",
      "tissue_origin: {'Terminal Ileum': '1', 'Ascending colon': '2', 'Transverse colon': '3', 'Descending colon': '4', 'Sigmoid colon': '5', 'Sigmoid-rectum': '6', 'Rectum': '7', 'Other': '888', 'N/A': '999'}\n",
      "inflam_status_chronicity: {'Acute': '1', 'Chronic': '2'}\n",
      "index_kit: {'Dual Index TT': '1', 'Dual Index TS': '2'}\n",
      "instrument: {'NovaSeq 6000': '1', 'NextSeq 2000': '2', 'Not Sequenced': '3'}\n",
      "x_chem_version_sc: {'v1': '1', 'v2': '2', 'v3': '3', 'v3.1': '4'}\n"
     ]
    }
   ],
   "source": [
    "cat_fields = list(set(pd.Series([f if data_dict.loc[f].field_type in [\n",
    "    \"radio\", \"dropdown\"] else np.nan for f in data_dict.index]).dropna(\n",
    "        )).intersection(set(list(dff.columns))))  # categorical fields\n",
    "cat_dict = dict(zip(cat_fields, [\n",
    "    dict(pd.DataFrame([v.split(\", \") for v in data_dict.loc[\n",
    "        f].loc[\"select_choices_or_calculations\"].split(\" | \")]).set_index(\n",
    "            1)[0]) for f in cat_fields]))  # category options\n",
    "cat_rm = list(set(pd.Series(already_expanded).explode().dropna().apply(\n",
    "    lambda x: \"_\".join(list(np.array(x.split(\"_\"))[:-1]))).unique(\n",
    "        )))  # RM categorical fields (stripped of _#)\n",
    "cat_rm = list(pd.Series([x if data_dict.loc[x + \"_1\"].field_type in [\n",
    "    \"radio\", \"dropdown\"] else np.nan for x in cat_rm]).dropna())\n",
    "cat_dict = {**cat_dict, **dict(zip(cat_rm, [\n",
    "    dict(pd.DataFrame([v.split(\", \") for v in data_dict.loc[\n",
    "        f + \"_1\"].loc[\"select_choices_or_calculations\"].split(\" | \")]).set_index(\n",
    "            1)[0]) for f in cat_rm]))}  # category options (RM)\n",
    "print(\"\\n\".join([f\"{f}: {cat_dict[f]}\" for f in cat_dict]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Major Changes\n",
    "\n",
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         tissue_origin_old  \\\n",
      "lib_id                                                                       \n",
      "HH0001                                                                PBMC   \n",
      "J00002     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "J00003     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "J00004     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "J00005     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "LC0001                                                                PBMC   \n",
      "LC0002                                                                PBMC   \n",
      "LC0003                                                                PBMC   \n",
      "LC0004                                                                PBMC   \n",
      "LC0005                                                                PBMC   \n",
      "LC0006                                                                PBMC   \n",
      "RL0001                                                              Rectum   \n",
      "RL0001_re                                                           Rectum   \n",
      "RL0002                                                             Sigmoid   \n",
      "RL0002_re                                                          Sigmoid   \n",
      "RL0003                                       Rectum, proctectomy, biopsies   \n",
      "RL0004                                      Sigmoid, proctectomy, biopsies   \n",
      "RL0005                                       Rectum, colonoscopy, biopsies   \n",
      "RL0006                               Terminal ileum, colonoscopy, biopsies   \n",
      "RL0007                                       Rectum, colonoscopy, biopsies   \n",
      "RL0008                               Terminal ileum, colonoscopy, biopsies   \n",
      "RL0009                                       Rectum, colonoscopy, biopsies   \n",
      "RL0010                               Terminal ileum, colonoscopy, biopsies   \n",
      "RL0011                                       Rectum, colonoscopy, biopsies   \n",
      "RL0012                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0013                                       Rectum, colonoscopy, biopsies   \n",
      "RL0014                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0015                                       Rectum, colonoscopy, biopsies   \n",
      "RL0016                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0017                                       Rectum, colonoscopy, biopsies   \n",
      "RL0018                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0019                                       Rectum, colonoscopy, biopsies   \n",
      "RL0020                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0021                                       Rectum, colonoscopy, biopsies   \n",
      "RL0022                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0023                                       Rectum, colonoscopy, biopsies   \n",
      "RL0024                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0025                                       Rectum, colonoscopy, biopsies   \n",
      "RL0026                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0027                                       Rectum, colonoscopy, biopsies   \n",
      "RL0028                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0029                                       Rectum, colonoscopy, biopsies   \n",
      "RL0030                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0031                                       Rectum, colonoscopy, biopsies   \n",
      "RL0032                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0033                                       Rectum, colonoscopy, biopsies   \n",
      "RL0034                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0035                                      Rectum, proectectomy, biopsies   \n",
      "RL0036                         Fistula tract lining, proctectomy, biopsies   \n",
      "RL0037                                       Rectum, colonoscopy, biopsies   \n",
      "RL0038                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0039                                       Rectum, colonoscopy, biopsies   \n",
      "RL0040                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0041                                       Rectum, colonoscopy, biopsies   \n",
      "RL0042                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0043                                       Rectum, colonoscopy, biopsies   \n",
      "RL0044                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0045                                       Rectum, colonoscopy, biopsies   \n",
      "RL0046                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0047                                       Rectum, colonoscopy, biopsies   \n",
      "RL0048                                Sigmoid colon, colonoscopy, biopsies   \n",
      "RL0049                                    Rectum, proctectomy --> biopsies   \n",
      "RL0050                                   Fistula, proctectomy --> biopsies   \n",
      "RL0051                                    Rectum, proctectomy --> biopsies   \n",
      "RL0052                                    Rectum, proctectomy --> biopsies   \n",
      "RL0053                                   Fistula, proctectomy --> biopsies   \n",
      "RL0054                                    Rectum, proctectomy --> biopsies   \n",
      "SN0001                                        Larval intestinal dissection   \n",
      "SN0002                                        Larval intestinal dissection   \n",
      "SN0003                                        Larval intestinal dissection   \n",
      "SN0004                                        Larval intestinal dissection   \n",
      "SN0005                                        Larval intestinal dissection   \n",
      "SN0006                                        Larval intestinal dissection   \n",
      "SN0007                                        Larval intestinal dissection   \n",
      "SN0008                                        Larval intestinal dissection   \n",
      "SN0009                                        Larval intestinal dissection   \n",
      "SN0010                                        Larval intestinal dissection   \n",
      "SN0011                                        Larval intestinal dissection   \n",
      "SN0012                                        Larval intestinal dissection   \n",
      "SN0013                                                      Terminal ileum   \n",
      "SN0014                                                               PBMCs   \n",
      "UC0001                                                     sigmoid, biopsy   \n",
      "UC0002                                                      rectum, biopsy   \n",
      "UC0003                                            Transverse Colon, biopsy   \n",
      "UC0004                                                      rectum, biopsy   \n",
      "NH0001                                        Colon organoid (excl. cecum)   \n",
      "NH0002                                        Colon organoid (excl. cecum)   \n",
      "NH0003                                        Colon organoid (excl. cecum)   \n",
      "NH0004                                        Colon organoid (excl. cecum)   \n",
      "NH0005                                        Colon organoid (excl. cecum)   \n",
      "NH0006                                        Colon organoid (excl. cecum)   \n",
      "NH0007                                        Colon organoid (excl. cecum)   \n",
      "NH0008                                        Colon organoid (excl. cecum)   \n",
      "NH0009                                       Rectum (10cm)-Inflamed Biopsy   \n",
      "NH0010                                   Sigmoid (35cm)- Uninflamed Biopsy   \n",
      "NH0011                                       Rectum (10cm)-Inflamed Biopsy   \n",
      "NH0012                                   Sigmoid (35cm)- Uninflamed Biopsy   \n",
      "NH0013                                     Rectum (10cm)-  Inflamed Biopsy   \n",
      "NH0014                                   Sigmoid (25cm)- Uninflamed Biopsy   \n",
      "NH0015                                     Rectum (10cm)-  Inflamed Biopsy   \n",
      "NH0016                                   Sigmoid (35cm)- Uninflamed Biopsy   \n",
      "QQ0001                                                     Ileum resection   \n",
      "QQ0002                                                     Ileum resection   \n",
      "QQ0003                                                                PBMC   \n",
      "QQ0004                                                     Ileum resection   \n",
      "QQ0005                                                     Ileum resection   \n",
      "QQ0006                                                                PBMC   \n",
      "QQ0007                                                     Ileum resection   \n",
      "QQ0008                                                     Ileum resection   \n",
      "QQ0009                                                                PBMC   \n",
      "QQ0010                                                     Ileum resection   \n",
      "QQ0011                                                     Ileum resection   \n",
      "QQ0012                                                     Ileum resection   \n",
      "QQ0013                                                     Ileum resection   \n",
      "QQ0014                                                                PBMC   \n",
      "QQ0015                                                     Ileum resection   \n",
      "QQ0016                                                     Ileum resection   \n",
      "QQ0017                                                     Ileum resection   \n",
      "QQ0018                                                     Ileum resection   \n",
      "QQ0019                                                     Ileum resection   \n",
      "QQ0020                                                     Ileum resection   \n",
      "QQ0021                                                                PBMC   \n",
      "QQ0022                                                     Ileum resection   \n",
      "QQ0023                                                                PBMC   \n",
      "QQ0024                                                     Ileum resection   \n",
      "QQ0025                                                     Ileum resection   \n",
      "QQ0026                                                     Ileum resection   \n",
      "QQ0027                                                                PBMC   \n",
      "QQ0028                                                     Ileum resection   \n",
      "QQ0029                                                     Ileum resection   \n",
      "QQ0030                                                                PBMC   \n",
      "QQ0031                                 Terminal Ileum Resection, Biopsies    \n",
      "QQ0032                                 Terminal Ileum Resection, Biopsies    \n",
      "QQ0033                                                         Whole blood   \n",
      "QQ0034                                                         Whole blood   \n",
      "AA1inf                              Colectomy, Biopsies from sigmoid colon   \n",
      "AA1non                           Colectomy, Biopsies from transverse colon   \n",
      "QQ0035                                        Larval intestinal dissection   \n",
      "QQ0036     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "QQ0037     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "QQ0038                                        Larval intestinal dissection   \n",
      "QQ0039                                        Larval intestinal dissection   \n",
      "QQ0040     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "QQ0041                                        Larval intestinal dissection   \n",
      "QQ0042                                        Larval intestinal dissection   \n",
      "QQ0043     Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes   \n",
      "QQ0044                                        Larval intestinal dissection   \n",
      "QQ0045                                        Larval intestinal dissection   \n",
      "QQ0046                                        Larval intestinal dissection   \n",
      "QQ0047                                        Larval intestinal dissection   \n",
      "QQ0048                                        Larval intestinal dissection   \n",
      "QQ0049                                        Larval intestinal dissection   \n",
      "QQ0050                                        Larval intestinal dissection   \n",
      "QQ0051                                        Larval intestinal dissection   \n",
      "QQ0052                                        Larval intestinal dissection   \n",
      "QQ0053                                        Larval intestinal dissection   \n",
      "QQ0054                                        Larval intestinal dissection   \n",
      "QQ0055                                        Larval intestinal dissection   \n",
      "QQ0056                                        Larval intestinal dissection   \n",
      "QQ0057                                        Larval intestinal dissection   \n",
      "QQ0058                                        Larval intestinal dissection   \n",
      "QQ0059                                        Larval intestinal dissection   \n",
      "KC0004                                                     Ileal resection   \n",
      "KC0002                                                     Ileal resection   \n",
      "KC0003                                                     Ileal resection   \n",
      "KC0005                                                     Ileal resection   \n",
      "KC0001                                                     Ileal resection   \n",
      "CD0001                                 Terminal Ileal Resection, Biopsies    \n",
      "CD0002                                 Terminal Ileal Resection, Biopsies    \n",
      "CD0003                                 Terminal Ileal Resection, Biopsies    \n",
      "CD0004                                 Terminal Ileal Resection, Biopsies    \n",
      "\n",
      "              tissue_origin  \n",
      "lib_id                       \n",
      "HH0001                  NaN  \n",
      "J00002                  NaN  \n",
      "J00003                  NaN  \n",
      "J00004                  NaN  \n",
      "J00005                  NaN  \n",
      "LC0001                  NaN  \n",
      "LC0002                  NaN  \n",
      "LC0003                  NaN  \n",
      "LC0004                  NaN  \n",
      "LC0005                  NaN  \n",
      "LC0006                  NaN  \n",
      "RL0001               Rectum  \n",
      "RL0001_re            Rectum  \n",
      "RL0002        Sigmoid colon  \n",
      "RL0002_re     Sigmoid colon  \n",
      "RL0003               Rectum  \n",
      "RL0004        Sigmoid colon  \n",
      "RL0005               Rectum  \n",
      "RL0006       Terminal Ileum  \n",
      "RL0007               Rectum  \n",
      "RL0008       Terminal Ileum  \n",
      "RL0009               Rectum  \n",
      "RL0010       Terminal Ileum  \n",
      "RL0011               Rectum  \n",
      "RL0012        Sigmoid colon  \n",
      "RL0013               Rectum  \n",
      "RL0014        Sigmoid colon  \n",
      "RL0015               Rectum  \n",
      "RL0016        Sigmoid colon  \n",
      "RL0017               Rectum  \n",
      "RL0018        Sigmoid colon  \n",
      "RL0019               Rectum  \n",
      "RL0020        Sigmoid colon  \n",
      "RL0021               Rectum  \n",
      "RL0022        Sigmoid colon  \n",
      "RL0023               Rectum  \n",
      "RL0024        Sigmoid colon  \n",
      "RL0025               Rectum  \n",
      "RL0026        Sigmoid colon  \n",
      "RL0027               Rectum  \n",
      "RL0028        Sigmoid colon  \n",
      "RL0029               Rectum  \n",
      "RL0030        Sigmoid colon  \n",
      "RL0031               Rectum  \n",
      "RL0032        Sigmoid colon  \n",
      "RL0033               Rectum  \n",
      "RL0034        Sigmoid colon  \n",
      "RL0035               Rectum  \n",
      "RL0036                Other  \n",
      "RL0037               Rectum  \n",
      "RL0038        Sigmoid colon  \n",
      "RL0039               Rectum  \n",
      "RL0040        Sigmoid colon  \n",
      "RL0041               Rectum  \n",
      "RL0042        Sigmoid colon  \n",
      "RL0043               Rectum  \n",
      "RL0044        Sigmoid colon  \n",
      "RL0045               Rectum  \n",
      "RL0046        Sigmoid colon  \n",
      "RL0047               Rectum  \n",
      "RL0048        Sigmoid colon  \n",
      "RL0049               Rectum  \n",
      "RL0050                Other  \n",
      "RL0051               Rectum  \n",
      "RL0052               Rectum  \n",
      "RL0053                Other  \n",
      "RL0054               Rectum  \n",
      "SN0001                  NaN  \n",
      "SN0002                  NaN  \n",
      "SN0003                  NaN  \n",
      "SN0004                  NaN  \n",
      "SN0005                  NaN  \n",
      "SN0006                  NaN  \n",
      "SN0007                  NaN  \n",
      "SN0008                  NaN  \n",
      "SN0009                  NaN  \n",
      "SN0010                  NaN  \n",
      "SN0011                  NaN  \n",
      "SN0012                  NaN  \n",
      "SN0013       Terminal Ileum  \n",
      "SN0014                  NaN  \n",
      "UC0001        Sigmoid colon  \n",
      "UC0002               Rectum  \n",
      "UC0003     Transverse colon  \n",
      "UC0004               Rectum  \n",
      "NH0001                  NaN  \n",
      "NH0002                  NaN  \n",
      "NH0003                  NaN  \n",
      "NH0004                  NaN  \n",
      "NH0005                  NaN  \n",
      "NH0006                  NaN  \n",
      "NH0007                  NaN  \n",
      "NH0008                  NaN  \n",
      "NH0009               Rectum  \n",
      "NH0010        Sigmoid colon  \n",
      "NH0011               Rectum  \n",
      "NH0012        Sigmoid colon  \n",
      "NH0013               Rectum  \n",
      "NH0014        Sigmoid colon  \n",
      "NH0015               Rectum  \n",
      "NH0016        Sigmoid colon  \n",
      "QQ0001       Terminal Ileum  \n",
      "QQ0002       Terminal Ileum  \n",
      "QQ0003                  NaN  \n",
      "QQ0004       Terminal Ileum  \n",
      "QQ0005       Terminal Ileum  \n",
      "QQ0006                  NaN  \n",
      "QQ0007       Terminal Ileum  \n",
      "QQ0008       Terminal Ileum  \n",
      "QQ0009                  NaN  \n",
      "QQ0010       Terminal Ileum  \n",
      "QQ0011       Terminal Ileum  \n",
      "QQ0012       Terminal Ileum  \n",
      "QQ0013       Terminal Ileum  \n",
      "QQ0014                  NaN  \n",
      "QQ0015       Terminal Ileum  \n",
      "QQ0016       Terminal Ileum  \n",
      "QQ0017       Terminal Ileum  \n",
      "QQ0018       Terminal Ileum  \n",
      "QQ0019       Terminal Ileum  \n",
      "QQ0020       Terminal Ileum  \n",
      "QQ0021                  NaN  \n",
      "QQ0022       Terminal Ileum  \n",
      "QQ0023                  NaN  \n",
      "QQ0024       Terminal Ileum  \n",
      "QQ0025       Terminal Ileum  \n",
      "QQ0026       Terminal Ileum  \n",
      "QQ0027                  NaN  \n",
      "QQ0028       Terminal Ileum  \n",
      "QQ0029       Terminal Ileum  \n",
      "QQ0030                  NaN  \n",
      "QQ0031       Terminal Ileum  \n",
      "QQ0032       Terminal Ileum  \n",
      "QQ0033                  NaN  \n",
      "QQ0034                  NaN  \n",
      "AA1inf        Sigmoid colon  \n",
      "AA1non     Transverse colon  \n",
      "QQ0035                  NaN  \n",
      "QQ0036                  NaN  \n",
      "QQ0037                  NaN  \n",
      "QQ0038                  NaN  \n",
      "QQ0039                  NaN  \n",
      "QQ0040                  NaN  \n",
      "QQ0041                  NaN  \n",
      "QQ0042                  NaN  \n",
      "QQ0043                  NaN  \n",
      "QQ0044                  NaN  \n",
      "QQ0045                  NaN  \n",
      "QQ0046                  NaN  \n",
      "QQ0047                  NaN  \n",
      "QQ0048                  NaN  \n",
      "QQ0049                  NaN  \n",
      "QQ0050                  NaN  \n",
      "QQ0051                  NaN  \n",
      "QQ0052                  NaN  \n",
      "QQ0053                  NaN  \n",
      "QQ0054                  NaN  \n",
      "QQ0055                  NaN  \n",
      "QQ0056                  NaN  \n",
      "QQ0057                  NaN  \n",
      "QQ0058                  NaN  \n",
      "QQ0059                  NaN  \n",
      "KC0004       Terminal Ileum  \n",
      "KC0002       Terminal Ileum  \n",
      "KC0003       Terminal Ileum  \n",
      "KC0005       Terminal Ileum  \n",
      "KC0001       Terminal Ileum  \n",
      "CD0001       Terminal Ileum  \n",
      "CD0002       Terminal Ileum  \n",
      "CD0003       Terminal Ileum  \n",
      "CD0004       Terminal Ileum  \n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Conversions\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** sc_process_date\n",
      "05-18-2022 -> 05/18/2022\n",
      "03-01-2022 -> 03/01/2022\n",
      "04-01-2022 -> 04/01/2022\n",
      "07-11-2022 -> 07/11/2022\n",
      "05-01-2021 -> 05/01/2021\n",
      "06-01-2021 -> 06/01/2021\n",
      "07-01-2021 -> 07/01/2021\n",
      "08-01-2021 -> 08/01/2021\n",
      "09-01-2021 -> 09/01/2021\n",
      "10-01-2021 -> 10/01/2021\n",
      "06-01-2022 -> 06/01/2022\n",
      "12-01-2022 -> 12/01/2022\n",
      "03-24-2021 -> 03/24/2021\n",
      "02-01-2020 -> 02/01/2020\n",
      "01-01-2017 -> 01/01/2017\n",
      "06-01-2018 -> 06/01/2018\n",
      "07-01-2018 -> 07/01/2018\n",
      "10-01-2018 -> 10/01/2018\n",
      "03-01-2017 -> 03/01/2017\n",
      "05-01-2017 -> 05/01/2017\n",
      "07-01-2017 -> 07/01/2017\n",
      "08-01-2017 -> 08/01/2017\n",
      "11-01-2017 -> 11/01/2017\n",
      "12-01-2017 -> 12/01/2017\n",
      "12-01-2016 -> 12/01/2016\n",
      "02-01-2017 -> 02/01/2017\n",
      "10-01-2020 -> 10/01/2020\n",
      "08-01-2020 -> 08/01/2020\n",
      "09-01-2020 -> 09/01/2020\n",
      "02-01-2022 -> 02/01/2022\n",
      "07-01-2020 -> 07/01/2020\n",
      "03-01-2018 -> 03/01/2018\n",
      "10-01-2022 -> 10/01/2022\n",
      "03-01-2021 -> 03/01/2021\n",
      "\n",
      "\n",
      "*** pre_amp_date\n",
      "05-23-2022 -> 05/23/2022\n",
      "03-08-2022 -> 03/08/2022\n",
      "03-11-2022 -> 03/11/2022\n",
      "03-17-2022 -> 03/17/2022\n",
      "03-31-2022 -> 03/31/2022\n",
      "04-27-2022 -> 04/27/2022\n",
      "07-12-2022 -> 07/12/2022\n",
      "06-01-2021 -> 06/01/2021\n",
      "06-17-2021 -> 06/17/2021\n",
      "06-28-2021 -> 06/28/2021\n",
      "07-08-2021 -> 07/08/2021\n",
      "07-26-2021 -> 07/26/2021\n",
      "07-27-2021 -> 07/27/2021\n",
      "09-01-2021 -> 09/01/2021\n",
      "09-16-2021 -> 09/16/2021\n",
      "09-28-2021 -> 09/28/2021\n",
      "10-12-2021 -> 10/12/2021\n",
      "10-04-2021 -> 10/04/2021\n",
      "10-18-2021 -> 10/18/2021\n",
      "04-22-2022 -> 04/22/2022\n",
      "04-29-2022 -> 04/29/2022\n",
      "06-15-2022 -> 06/15/2022\n",
      "12-21-2022 -> 12/21/2022\n",
      "12-19-2022 -> 12/19/2022\n",
      "06-09-2021 -> 06/09/2021\n",
      "07-20-2021 -> 07/20/2021\n",
      "04-01-2021 -> 04/01/2021\n",
      "\n",
      "\n",
      "*** date_sent\n",
      "07-11-2022 -> 07/11/2022\n",
      "03-08-2022 -> 03/08/2022\n",
      "03-21-2022 -> 03/21/2022\n",
      "04-05-2022 -> 04/05/2022\n",
      "04-28-2022 -> 04/28/2022\n",
      "04-27-2022 -> 04/27/2022\n",
      "07-12-2022 -> 07/12/2022\n",
      "06-08-2021 -> 06/08/2021\n",
      "06-09-2021 -> 06/09/2021\n",
      "06-22-2021 -> 06/22/2021\n",
      "07-13-2021 -> 07/13/2021\n",
      "07-15-2021 -> 07/15/2021\n",
      "07-14-2021 -> 07/14/2021\n",
      "07-29-2021 -> 07/29/2021\n",
      "07-28-2021 -> 07/28/2021\n",
      "07-30-2021 -> 07/30/2021\n",
      "10-05-2021 -> 10/05/2021\n",
      "10-07-2021 -> 10/07/2021\n",
      "10-14-2021 -> 10/14/2021\n",
      "10-18-2021 -> 10/18/2021\n",
      "05-18-2022 -> 05/18/2022\n",
      "12-27-2022 -> 12/27/2022\n",
      "06-13-2023 -> 06/13/2023\n",
      "12-21-2022 -> 12/21/2022\n",
      "06-14-2021 -> 06/14/2021\n",
      "07-22-2021 -> 07/22/2021\n",
      "04-08-2021 -> 04/08/2021\n",
      "\n",
      "\n",
      "*** project\n",
      "CRISPR Screening -> CRISPR Screening of Monocytes\n",
      "Zebrafish Felix_Josh -> Zebrafish\n",
      "Zebrafish Shikha -> Zebrafish\n",
      "UC_ZC_sc -> UC\n",
      "\n",
      "\n",
      "*** disease_status\n",
      "Remisson -> In remission\n",
      "Remission -> In remission\n",
      "Active + Fistula -> Active\n",
      "Remission + Fistula -> In remission\n",
      "Active + Fistula? -> Active\n",
      "Active + stenosis -> Active\n",
      "Active + fistula -> Active\n",
      "\n",
      "\n",
      "*** disease\n",
      "CD -> Crohn's Disease\n",
      "UC -> Ulcerative Colitis\n",
      "Healthy -> Healthy Control\n",
      "\n",
      "\n",
      "*** x_chem_version_sc\n",
      "3.1 -> v3.1\n",
      "1.0 -> v1\n",
      "3.0 -> v3\n",
      "2.0 -> v2\n",
      "\n",
      "\n",
      "*** index_kit\n",
      "SI-TT-E2 -> Dual Index TT\n",
      "SI-TT-D1 -> Dual Index TT\n",
      "SI-TT-D2 -> Dual Index TT\n",
      "SI-TT-D3 -> Dual Index TT\n",
      "SI-TT-D4 -> Dual Index TT\n",
      "SI-TT-D7 -> Dual Index TT\n",
      "SI-NA-C2 -> Dual Index TS\n",
      "SI-TT-E5 -> Dual Index TT\n",
      "SI-NA-F2 -> Dual Index TS\n",
      "SI-TT-E6 -> Dual Index TT\n",
      "SI-NA-G2 -> Dual Index TS\n",
      "SI-TT-E1 -> Dual Index TT\n",
      "SI-TT-A11 -> Dual Index TT\n",
      "SI-TT-A12 -> Dual Index TT\n",
      "SI-TT-G7 -> Dual Index TT\n",
      "SI-TT-G8 -> Dual Index TT\n",
      "SI-TT-A1 -> Dual Index TT\n",
      "SI-TT-A2 -> Dual Index TT\n",
      "SI-NA-A1 -> Dual Index TS\n",
      "SI-NA-B1 -> Dual Index TS\n",
      "SI-TT-A9 -> Dual Index TT\n",
      "SI-TT-A10 -> Dual Index TT\n",
      "SI-TT-A7 -> Dual Index TT\n",
      "SI-TT-A8 -> Dual Index TT\n",
      "SI-NA-C1 -> Dual Index TS\n",
      "SI-NA-D1 -> Dual Index TS\n",
      "SI-TT-B1 -> Dual Index TT\n",
      "SI-TT-B2 -> Dual Index TT\n",
      "SI-TT-B9 -> Dual Index TT\n",
      "SI-TT-B10 -> Dual Index TT\n",
      "SI-TT-B4 -> Dual Index TT\n",
      "SI-TT-B5 -> Dual Index TT\n",
      "SI-TT-B8 -> Dual Index TT\n",
      "SI-TT-B11 -> Dual Index TT\n",
      "SI-TT-C3 -> Dual Index TT\n",
      "SI-TT-C4 -> Dual Index TT\n",
      "SI-NA-E1 -> Dual Index TS\n",
      "SI-NA-F1 -> Dual Index TS\n",
      "SI-TT-C1 -> Dual Index TT\n",
      "SI-TT-C2 -> Dual Index TT\n",
      "SI-TT-C5 -> Dual Index TT\n",
      "SI-TT-C6 -> Dual Index TT\n",
      "SI-NA-G1 -> Dual Index TS\n",
      "SI-NA-H1 -> Dual Index TS\n",
      "SI-TT-C9 -> Dual Index TT\n",
      "SI-TT-C10 -> Dual Index TT\n",
      "SI-TT-D5 -> Dual Index TT\n",
      "SI-TT-D6 -> Dual Index TT\n",
      "SI-NA-A2 -> Dual Index TS\n",
      "SI-NA-B2 -> Dual Index TS\n",
      "SI-TT-D10 -> Dual Index TT\n",
      "SI-TT-D11 -> Dual Index TT\n",
      "SI-TT-D8 -> Dual Index TT\n",
      "SI-TT-D9 -> Dual Index TT\n",
      "SI-NA-D2 -> Dual Index TS\n",
      "SI-NA-E2 -> Dual Index TS\n",
      "SI-TT-D12 -> Dual Index TT\n",
      "SI-TT-E3 -> Dual Index TT\n",
      "SI-TT-E4 -> Dual Index TT\n",
      "SI-TT-F5 -> Dual Index TT\n",
      "SI-N-D3 -> Dual Index TS\n",
      "SI-TT-F3 -> Dual Index TT\n",
      "SI-TT-F4 -> Dual Index TT\n",
      "SI-TT-G10 -> Dual Index TT\n",
      "SI-TT-G11 -> Dual Index TT\n",
      "SI-TT-H1 -> Dual Index TT\n",
      "SI-TT-H2 -> Dual Index TT\n",
      "SI-TT-H3 -> Dual Index TT\n",
      "SI-TT-H4 -> Dual Index TT\n",
      "SI-TT-A3 -> Dual Index TT\n",
      "SI-TT-A4 -> Dual Index TT\n",
      "SI-TT-A5 -> Dual Index TT\n",
      "SI-TT-A6 -> Dual Index TT\n",
      "SI-TT-B6 -> Dual Index TT\n",
      "SI-TT-B7 -> Dual Index TT\n",
      "SI-TT-H9 -> Dual Index TT\n",
      "SI-TT-H10 -> Dual Index TT\n",
      "SI-TT-H11 -> Dual Index TT\n",
      "SI-TT-H12 -> Dual Index TT\n",
      "SI-TT-H5 -> Dual Index TT\n",
      "SI-TT-H6 -> Dual Index TT\n",
      "SI-TT-H7 -> Dual Index TT\n",
      "SI-TT-H8 -> Dual Index TT\n",
      "\n",
      "\n",
      "*** instrument\n",
      "NovaSeq S4 -> NovaSeq 6000\n",
      "NovaSeq SP -> NovaSeq 6000\n",
      "NovaSeq S1 -> NovaSeq 6000\n",
      "NovaSeq S2 -> NovaSeq 6000\n",
      "\n",
      "\n",
      "*** tissue_origin\n",
      "PBMC -> nan\n",
      "Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes -> nan\n",
      "Sigmoid -> Sigmoid colon\n",
      "Rectum, proctectomy, biopsies -> Rectum\n",
      "Sigmoid, proctectomy, biopsies -> Sigmoid colon\n",
      "Rectum, colonoscopy, biopsies -> Rectum\n",
      "Terminal ileum, colonoscopy, biopsies -> Terminal Ileum\n",
      "Sigmoid colon, colonoscopy, biopsies -> Sigmoid colon\n",
      "Rectum, proectectomy, biopsies -> Rectum\n",
      "Fistula tract lining, proctectomy, biopsies -> Other\n",
      "Rectum, proctectomy --> biopsies -> Rectum\n",
      "Fistula, proctectomy --> biopsies -> Other\n",
      "Larval intestinal dissection -> nan\n",
      "PBMCs -> nan\n",
      "sigmoid, biopsy -> Sigmoid colon\n",
      "rectum, biopsy -> Rectum\n",
      "Transverse Colon, biopsy -> Transverse colon\n",
      "Colon organoid (excl. cecum) -> nan\n",
      "Rectum (10cm)-Inflamed Biopsy -> Rectum\n",
      "Sigmoid (35cm)- Uninflamed Biopsy -> Sigmoid colon\n",
      "Rectum (10cm)-  Inflamed Biopsy -> Rectum\n",
      "Sigmoid (25cm)- Uninflamed Biopsy -> Sigmoid colon\n",
      "Ileum resection -> Terminal Ileum\n",
      "Terminal Ileum Resection, Biopsies  -> Terminal Ileum\n",
      "Whole blood -> nan\n",
      "Colectomy, Biopsies from sigmoid colon -> Sigmoid colon\n",
      "Colectomy, Biopsies from transverse colon -> Transverse colon\n",
      "Ileal resection -> Terminal Ileum\n",
      "Terminal Ileal Resection, Biopsies  -> Terminal Ileum\n",
      "\n",
      "\n",
      "\n",
      "DROP VARIABLES (not in REDCap):\n",
      "\n",
      "['record_id1', 'inflam_treatment', 'inflam_treatment_type', 'inflam_treatment_concentration_DSS', 'inflam_treatment_quantity_DSS', 'inflam_treatment_quantity_hGMCSF', 'inflam_treatment_quantity_BZA', 'age', 'sex', 'race', 'repeat_data_release', 'repeat_seq_platform', 'ref_genome', 'data_link']\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "if any((\"_old\" in c for c in dff.columns)):\n",
    "    raise NotImplementedError(\"Change code!!! '_old' is already in >= 1 original variable\")\n",
    "data = dff.copy()\n",
    "labels_uninflamed = [\"uninflamed\", \"noninflamed\", \"non-infl\", \"non-inflamed\", \"un-inflamed\"]\n",
    "labels_inflamed = [\"inflamed\"]\n",
    "\n",
    "# Dates\n",
    "for x in [\"sc_process_date\", \"pre_amp_date\", \"date_sent\"]:\n",
    "    data.loc[:, f\"{x}_old\"] = data.loc[:, x].copy()\n",
    "    data.loc[:, x] = data.loc[:, x].apply(\n",
    "        lambda x: x if pd.isnull(x) else \"/\".join(x.split(\"-\")))\n",
    "\n",
    "# Project\n",
    "data.loc[:, \"project_old\"] = data.loc[:, \"project\"].copy()\n",
    "data.loc[:, \"project\"] = data.loc[:, \"project\"].apply(\n",
    "    lambda x: \"Zebrafish\" if isinstance(\n",
    "        x, str) and \"zebrafish\" in x.lower() else x)\n",
    "data.loc[:, \"project\"] = data.loc[:, \"project\"].apply(\n",
    "    lambda x: \"CRISPR Screening of Monocytes\" if isinstance(\n",
    "        x, str) and \"crispr\" in x.lower() else x)\n",
    "data.loc[:, \"project\"] = data.loc[:, \"project\"].apply(\n",
    "    lambda x: \"UC\" if isinstance(x, str) and \"UC_ZC_sc\" in x else x)\n",
    "\n",
    "# Project Owner ID\n",
    "# concatenation of libid_ssids separated by comma, e.g., \"CD01_FC01, CD02_FC02\"\n",
    "data = data.assign(libbbbbbbb=data.index.values)  # rename old column\n",
    "data = data.join(data.apply(lambda r: f\"{r['project_owner_id']}_{r['libbbbbbbb']}\", \n",
    "                         axis=1).to_frame(\"project_owner_id_lib_id\")).drop(\n",
    "                             \"libbbbbbbb\", axis=1)  # owner_libid\n",
    "data = data.join(data.groupby(\n",
    "    cols_subject[0]).apply(lambda x: \",\".join(\n",
    "        x[\"project_owner_id_lib_id\"])).to_frame(\"project_owner_id\"), \n",
    "    lsuffix=\"_old\", on=cols_subject[0])[list(data.drop(\n",
    "        \"project_owner_id_lib_id\", axis=1).columns) + [\n",
    "            \"project_owner_id_old\"]]  # ownder1_libid1,owner2_libid2, etc.\n",
    "data = data.drop(\"project_owner_id_old\", axis=1)\n",
    "\n",
    "# Disease & Disease Status\n",
    "data.loc[:, \"disease_status_old\"] = data.loc[:, \"disease_status\"].copy()\n",
    "data.loc[:, \"disease_old\"] = data.loc[:, \"disease\"].copy()\n",
    "data = data.replace({\"disease\": {\n",
    "    \"CD\": \"Crohn's Disease\", \"UC\": \"Ulcerative Colitis\", \n",
    "    \"Healthy Mice\": \"Healthy Control\", \n",
    "    \"Healthy\": \"Healthy Control\"}})\n",
    "# cats_disease_status = extract_categories(\"disease_status\", data_dict)\n",
    "# for c in cats_disease_status:\n",
    "data.loc[:, \"disease_status\"] = data[\"disease_status\"].apply(\n",
    "    lambda x: \"In remission\" if \"rem\" in str(\n",
    "        x).lower() else x)  # standardize \"in remission\" variants\n",
    "data.loc[:, \"disease_status\"] = data[\"disease_status\"].apply(\n",
    "    lambda x: \"Active\" if \"active\" in str(\n",
    "        x).lower() else x)  # standardize \"in remission\" variants\n",
    "# data.loc[:, \"disease\"] = data.apply(lambda x:  if (pd.isnull(\n",
    "#     x[\"disease\"])) & (x[\"organism\"] != \"Human\") else x)  # \"other\" for fish\n",
    "data.loc[:, \"disease\"] = data.disease.apply(lambda x: \"Healthy Control\" if any(\n",
    "    (\"healthy\" in str(x).lower() for i in [\"healthy\", \"hc\", \"control\"])) else x)\n",
    "\n",
    "# Inflammation Status\n",
    "data.loc[:, \"inflam_status_old\"] = data.loc[:, \"inflam_status\"].copy()\n",
    "data.loc[:, \"inflam_status_new\"] = data[\"inflam_status\"].apply(\n",
    "    lambda x: np.nan if pd.isnull(x) else str(\"Non-inflamed\" if any(\n",
    "        (p in str(x).strip(\"-\").lower() for p in labels_uninflamed)) else str(\n",
    "            \"Inflamed\" if any(\n",
    "        (q in str(x).strip(\"-\").lower() for q in labels_inflamed)) else np.nan)))\n",
    "data.loc[:, \"inflam_status_chronicity\"] = data[\"inflam_status\"].apply(\n",
    "    lambda x: np.nan if pd.isnull(x) else str(\"Acute\" if \"acute\" in x.lower(\n",
    "        ) else str(\"Chronic\" if \"chronic\" in x.lower() else np.nan)))\n",
    "data.loc[:, \"inflam_status\"] = data.loc[:, \"inflam_status_new\"]\n",
    "data = data.drop(\"inflam_status_new\", axis=1)\n",
    "data = data.drop(\"inflam_status_old\", axis=1)\n",
    "data.loc[(pd.isnull(data.inflam_status)) & (  # HCs NAs for inflam_status\n",
    "    data.disease == \"Healthy Control\"), \"inflam_status\"] = \"Healthy Control\"\n",
    "\n",
    "# Chemistry Version\n",
    "data.loc[:, \"x_chem_version_sc_old\"] = data[\"x_chem_version_sc\"].copy()\n",
    "data.loc[:, \"x_chem_version_sc\"] = data[\"x_chem_version_sc\"].apply(\n",
    "    lambda x: \"NovaSeq 6000\" if \"nova\" in str(x).lower() else x)\n",
    "# print(data[[\"x_chem_version_sc_old\", \"x_chem_version_sc\"]])\n",
    "\n",
    "# Index Kit\n",
    "data.loc[:, \"index_kit_old\"] = data[\"index_kit\"].copy()\n",
    "data.loc[:, \"index_kit\"] = data[\"index_kit\"].apply(\n",
    "    lambda x: \"Dual Index TT\" if \"-tt-\" in str(\n",
    "        x).lower() else np.nan if pd.isnull(x) else \"Dual Index TS\")\n",
    "# print(data[[\"index_kit_old\", \"index_kit\"]])\n",
    "\n",
    "# Instrument\n",
    "data.loc[:, \"instrument_old\"] = data[\"instrument\"].copy()\n",
    "data.loc[:, \"instrument\"] = data.instrument.apply(\n",
    "    lambda x: np.nan if pd.isnull(x) else \n",
    "    \"NovaSeq 6000\" if \"novaseq\" in x.lower() else x)\n",
    "data.loc[:, \"novaseq\"] = data.instrument_old.apply(\n",
    "    lambda x: np.nan if pd.isnull(x) or \"novaseq\" not in x.lower() else \n",
    "    \"SP\" if \"sp\" in x.lower() else \"S4\" if \"s4\" in x.lower() else \n",
    "    \"S2\" if \"s2\" in x.lower() else \"S1\" if \"s1\" in x.lower() else np.nan)\n",
    "data.loc[:, \"nextseq\"] = data.instrument_old.apply(\n",
    "    lambda x: np.nan if pd.isnull(x) or \"novaseq\" in x.lower() else \n",
    "    \"P1\" if \"p1\" in x.lower() else \"p2\" if \"p2\" in x.lower() else \n",
    "    \"p3\" if \"p3\" in x.lower() else np.nan)\n",
    "# Later rename to novaseq_6000 and nextseq_2000\n",
    "# Otherwise, weirdness in trying to extract nextseq_2000_2, etc.\n",
    "\n",
    "# Tissue Origin\n",
    "data.loc[:, \"tissue_origin_old\"] = data[\"tissue_origin\"].copy()\n",
    "tiss_orig = data[\"tissue_origin\"]\n",
    "data = data.replace({\"tissue_origin\": {\n",
    "    \"Terminal Ileal Resection\": \"terminal ileum resection\"}})\n",
    "# cats_tissue = extract_categories(\"tissue_origin_1\", data_dict)\n",
    "cats_tissue = {\"Terminal Ileum\": [\"ileum\", \"ileal\"],\n",
    "               \"Ascending colon\": [\"ascending colon\"], \n",
    "               \"Transverse colon\": [\"transverse colon\", \"transverse\"], \n",
    "               \"Descending colon\": [\"descending colon\"], \n",
    "               \"Sigmoid colon\": [\"sigmoid colon\", \"sigmoid\"], \n",
    "               \"Sigmoid-rectum\": [\"sigmoid-rectum\"], \n",
    "               \"Rectum\": [\"rectum\", \"rectal\"], \n",
    "               \"Other\": [\"fistula\"]}\n",
    "data.loc[:, \"tissue_origin\"] = data.tissue_origin.apply(\n",
    "    lambda x: np.nan if pd.isnull(x) else list(\n",
    "        pd.Series([c if any([u.lower() in x.lower() \n",
    "                             for u in cats_tissue[c]]) else np.nan \n",
    "                   for c in cats_tissue]).dropna())).apply(\n",
    "                       lambda y: y if not isinstance(y, list) else np.nan if len(\n",
    "                           y) == 0 else \"WARNING\" if len(y) > 1 else y[0])\n",
    "if any(data.loc[:, \"tissue_origin\"].isin([\"WARNING\"])):\n",
    "    raise ValueError(\"WARNING in tissue_origin\")\n",
    "print(data[[\"tissue_origin_old\", \"tissue_origin\"]])\n",
    "\n",
    "# Chemistry Version\n",
    "data.loc[:, \"x_chem_version_sc_old\"] = data[\"x_chem_version_sc\"].copy()\n",
    "data[\"x_chem_version_sc\"] = data[\"x_chem_version_sc\"].apply(\n",
    "    lambda x: np.nan if pd.isnull(x) else \n",
    "    f\"v{x}\" if \"v\" not in str(x) else x)  # put \"v\" in front of version #\n",
    "data[\"x_chem_version_sc\"] = data[\"x_chem_version_sc\"].apply(\n",
    "    lambda x: np.nan if pd.isnull(x) else \n",
    "    re.sub(\"[.]0\", \"\", x))  # remove \".0\" from version #s\n",
    "\n",
    "\n",
    "# Print Conversions\n",
    "print(f\"\\n\\n\\n{'=' * 80}\\n\\nConversions\\n\\n{'=' * 80}\\n\\n\")\n",
    "changed_variables = list(np.array(data.columns)[\n",
    "    np.where([\"_old\" in c for c in data.columns])[0]])\n",
    "for y in [re.sub(\"_old\", \"\", c) for c in changed_variables]:\n",
    "    print(f\"\\n\\n*** {y}\")\n",
    "    conv = data.apply(lambda x: str(x[f\"{y}_old\"]) + \" -> \" + str(x[y]) if str(x[\n",
    "        y]).lower() != str(x[f\"{y}_old\"]).lower() else np.nan, axis=1).dropna().unique()\n",
    "    print(\"\\n\".join(list(conv)))\n",
    "\n",
    "# Dropped Variables\n",
    "drop_variables = []\n",
    "for i in dff.columns:\n",
    "    fields = search_fields(\"^\" + i, data_dict, header=False, print_output=False)\n",
    "    if len(fields) == 0:\n",
    "        drop_variables += [i]\n",
    "print(f\"\\n\\n\\nDROP VARIABLES (not in REDCap):\\n\\n{drop_variables}\")\n",
    "data = data.drop(drop_variables, axis=1).drop(changed_variables, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>organism</th>\n",
       "      <th>project</th>\n",
       "      <th>disease</th>\n",
       "      <th>disease_status</th>\n",
       "      <th>grid</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>project_owner_id</th>\n",
       "      <th>animal_line</th>\n",
       "      <th>sc_process_date</th>\n",
       "      <th>type_of_experiment</th>\n",
       "      <th>x_chem_version_sc</th>\n",
       "      <th>standard_sample_id</th>\n",
       "      <th>inflam_status</th>\n",
       "      <th>tissue_origin</th>\n",
       "      <th>no_live_cells</th>\n",
       "      <th>cell_viability_percentage</th>\n",
       "      <th>targ_cell</th>\n",
       "      <th>no_live_nuclei</th>\n",
       "      <th>no_nuclei</th>\n",
       "      <th>index_kit</th>\n",
       "      <th>pre_amp_date</th>\n",
       "      <th>date_sent</th>\n",
       "      <th>instrument</th>\n",
       "      <th>inflam_status_chronicity</th>\n",
       "      <th>novaseq</th>\n",
       "      <th>nextseq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lib_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [record_id, organism, project, disease, disease_status, grid, patient_id, project_owner_id, animal_line, sc_process_date, type_of_experiment, x_chem_version_sc, standard_sample_id, inflam_status, tissue_origin, no_live_cells, cell_viability_percentage, targ_cell, no_live_nuclei, no_nuclei, index_kit, pre_amp_date, date_sent, instrument, inflam_status_chronicity, novaseq, nextseq]\n",
       "Index: []"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.loc[:, \"tissue_origin\"].isin([\"WARNING\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories\n",
    "\n",
    "Display remaining entries that don't conform to available REDCap categories for applicable fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_mistakes = data[cat_fields].apply(lambda x: x.apply(\n",
    "#     lambda y: y if y not in cat_dict[\n",
    "#         x.name].keys() else np.nan).dropna()).stack().to_frame(\"Entry\").join(\n",
    "#             data[cat_fields].apply(lambda x: x.apply(\n",
    "#                 lambda y: \", \".join(cat_dict[x.name].keys()) if y not in cat_dict[\n",
    "#                     x.name].keys() else np.nan).dropna()).stack().to_frame(\n",
    "#                         \"Categories\")).reorder_levels([1, 0]).sort_index()\n",
    "# cat_mistakes = cat_mistakes.rename_axis([\"Field\", cat_mistakes.index.names[1]])\n",
    "# # cat_mistakes = cat_mistakes.reset_index(1, drop=True).drop_duplicates().set_index(\n",
    "# #     \"Entry\", append=True).join(cat_mistakes.reset_index().groupby(\n",
    "# #         [\"Field\", \"Entry\"]).apply(\n",
    "# #             lambda x: \", \".join(x[cat_mistakes.index.names[1]])).to_frame(\n",
    "# #                 cat_mistakes.index.names[1]), rsuffix=\"_r\")  # concatenate lib_ids\n",
    "# cat_mistakes = cat_mistakes.reset_index(1, drop=True).drop_duplicates().set_index(\n",
    "#     \"Entry\", append=True).join(cat_mistakes.reset_index().groupby(\n",
    "#         [\"Field\", \"Entry\"]).apply(\n",
    "#             lambda x: \", \".join(x[cat_mistakes.index.names[1]])),\n",
    "#         rsuffix=\"_r\")  # concatenate lib_ids\n",
    "# cat_mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        instrument  index_kit\n",
      "lib_id                       \n",
      "SN0003  instrument  index_kit\n",
      "SN0004  instrument  index_kit\n",
      "NH0001  instrument  index_kit\n",
      "NH0002  instrument  index_kit\n",
      "NH0003  instrument  index_kit\n",
      "NH0004  instrument  index_kit\n",
      "NH0005  instrument  index_kit\n",
      "NH0006  instrument  index_kit\n",
      "NH0007  instrument  index_kit\n",
      "NH0008  instrument  index_kit\n",
      "NH0009  instrument  index_kit\n",
      "NH0010  instrument  index_kit\n",
      "NH0011  instrument  index_kit\n",
      "NH0012  instrument  index_kit\n",
      "NH0013  instrument  index_kit\n",
      "NH0014  instrument  index_kit\n",
      "NH0015  instrument  index_kit\n",
      "NH0016  instrument  index_kit\n",
      "QQ0001  instrument  index_kit\n",
      "QQ0002  instrument  index_kit\n",
      "QQ0003  instrument  index_kit\n",
      "QQ0004  instrument  index_kit\n",
      "QQ0005  instrument  index_kit\n",
      "QQ0006  instrument  index_kit\n",
      "QQ0007  instrument  index_kit\n",
      "QQ0008  instrument  index_kit\n",
      "QQ0009  instrument  index_kit\n",
      "QQ0010  instrument  index_kit\n",
      "QQ0011  instrument  index_kit\n",
      "QQ0012  instrument  index_kit\n",
      "QQ0013  instrument  index_kit\n",
      "QQ0014  instrument  index_kit\n",
      "QQ0015  instrument  index_kit\n",
      "QQ0016  instrument  index_kit\n",
      "QQ0017  instrument  index_kit\n",
      "QQ0018  instrument  index_kit\n",
      "QQ0019  instrument  index_kit\n",
      "QQ0020  instrument  index_kit\n",
      "QQ0021  instrument  index_kit\n",
      "QQ0022  instrument  index_kit\n",
      "QQ0023  instrument  index_kit\n",
      "QQ0024  instrument  index_kit\n",
      "QQ0025  instrument  index_kit\n",
      "QQ0026  instrument  index_kit\n",
      "QQ0027  instrument  index_kit\n",
      "QQ0028  instrument  index_kit\n",
      "QQ0029  instrument  index_kit\n",
      "QQ0030  instrument  index_kit\n",
      "QQ0031  instrument  index_kit\n",
      "QQ0032  instrument  index_kit\n",
      "QQ0033  instrument  index_kit\n",
      "QQ0034  instrument  index_kit\n",
      "AA1inf  instrument  index_kit\n",
      "AA1non  instrument  index_kit\n",
      "QQ0035  instrument  index_kit\n",
      "QQ0036  instrument  index_kit\n",
      "QQ0037  instrument  index_kit\n",
      "QQ0038  instrument  index_kit\n",
      "QQ0039  instrument  index_kit\n",
      "QQ0040  instrument  index_kit\n",
      "QQ0041  instrument  index_kit\n",
      "QQ0042  instrument  index_kit\n",
      "QQ0043  instrument  index_kit\n",
      "QQ0044  instrument  index_kit\n",
      "QQ0045  instrument  index_kit\n",
      "QQ0046  instrument  index_kit\n",
      "QQ0047  instrument  index_kit\n",
      "QQ0048  instrument  index_kit\n",
      "QQ0049  instrument  index_kit\n",
      "QQ0050  instrument  index_kit\n",
      "QQ0051  instrument  index_kit\n",
      "QQ0052  instrument  index_kit\n",
      "QQ0053  instrument  index_kit\n",
      "QQ0054  instrument  index_kit\n",
      "QQ0055  instrument  index_kit\n",
      "QQ0056  instrument  index_kit\n",
      "QQ0057  instrument  index_kit\n",
      "QQ0058  instrument  index_kit\n",
      "QQ0059  instrument  index_kit\n",
      "KC0004  instrument  index_kit\n",
      "KC0002  instrument  index_kit\n",
      "KC0003  instrument  index_kit\n",
      "KC0005  instrument  index_kit\n",
      "KC0001  instrument  index_kit\n",
      "['SN0003' 'SN0004' 'NH0001' 'NH0002' 'NH0003' 'NH0004' 'NH0005' 'NH0006'\n",
      " 'NH0007' 'NH0008' 'NH0009' 'NH0010' 'NH0011' 'NH0012' 'NH0013' 'NH0014'\n",
      " 'NH0015' 'NH0016' 'QQ0001' 'QQ0002' 'QQ0003' 'QQ0004' 'QQ0005' 'QQ0006'\n",
      " 'QQ0007' 'QQ0008' 'QQ0009' 'QQ0010' 'QQ0011' 'QQ0012' 'QQ0013' 'QQ0014'\n",
      " 'QQ0015' 'QQ0016' 'QQ0017' 'QQ0018' 'QQ0019' 'QQ0020' 'QQ0021' 'QQ0022'\n",
      " 'QQ0023' 'QQ0024' 'QQ0025' 'QQ0026' 'QQ0027' 'QQ0028' 'QQ0029' 'QQ0030'\n",
      " 'QQ0031' 'QQ0032' 'QQ0033' 'QQ0034' 'AA1inf' 'AA1non' 'QQ0035' 'QQ0036'\n",
      " 'QQ0037' 'QQ0038' 'QQ0039' 'QQ0040' 'QQ0041' 'QQ0042' 'QQ0043' 'QQ0044'\n",
      " 'QQ0045' 'QQ0046' 'QQ0047' 'QQ0048' 'QQ0049' 'QQ0050' 'QQ0051' 'QQ0052'\n",
      " 'QQ0053' 'QQ0054' 'QQ0055' 'QQ0056' 'QQ0057' 'QQ0058' 'QQ0059' 'KC0004'\n",
      " 'KC0002' 'KC0003' 'KC0005' 'KC0001']\n"
     ]
    }
   ],
   "source": [
    "ixs = [np.nan, np.nan]\n",
    "for x, i in enumerate([\"instrument\", \"index_kit\"]):\n",
    "    nab = data[pd.isnull(data[i])][[i]]  # all NAs\n",
    "    ixs[x] = pd.Series(nab.index.values).to_frame(\n",
    "        nab.index.names[0]).assign(missing=i).set_index(\n",
    "            nab.index.names[0]).missing\n",
    "ixs = pd.concat(ixs, keys=[\"instrument\", \"index_kit\"], axis=1)\n",
    "print(ixs)\n",
    "print(ixs.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "tissue_origin\n",
      "\n",
      "--\n",
      "\n",
      "HH0001, J00002, J00003, J00004, J00005, LC0001, LC0002, LC0003, LC0004, LC0005, LC0006, SN0001, SN0002, SN0003, SN0004, SN0005, SN0006, SN0007, SN0008, SN0009, SN0010, SN0011, SN0012, SN0014, NH0001, NH0002, NH0003, NH0004, NH0005, NH0006, NH0007, NH0008, QQ0003, QQ0006, QQ0009, QQ0014, QQ0021, QQ0023, QQ0027, QQ0030, QQ0033, QQ0034, QQ0035, QQ0036, QQ0037, QQ0038, QQ0039, QQ0040, QQ0041, QQ0042, QQ0043, QQ0044, QQ0045, QQ0046, QQ0047, QQ0048, QQ0049, QQ0050, QQ0051, QQ0052, QQ0053, QQ0054, QQ0055, QQ0056, QQ0057, QQ0058, QQ0059\n",
      "\n",
      "\n",
      "False\n",
      "tissue_origin\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "tissue_origin\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column tissue_origin to partial match: tissue_origin_1\n",
      "field_name                          tissue_origin_1\n",
      "form_name         sample_information_3_gex_multiome\n",
      "section_header                                     \n",
      "field_type                                 dropdown\n",
      "field_label           Tissue Origin (if applicable)\n",
      "Name: tissue_origin_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [no_of_samples_3_prime] = '1' or [no_of_samples_3_prime] = '2' or [no_of_samples_3_prime] = '3' or [no_of_samples_3_prime] = '4' or [no_of_samples_3_prime] = '5' or [no_of_samples_3_prime] = '6' or [no_of_samples_3_prime] = '7' or [no_of_samples_3_prime] = '8' or [no_of_samples_multiome] = '1' or [no_of_samples_multiome] = '2' or [no_of_samples_multiome] = '3' or [no_of_samples_multiome] = '4' or [no_of_samples_multiome] = '5' or [no_of_samples_multiome] = '6' or [no_of_samples_multiome] = '7' or [no_of_samples_multiome] = '8'\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, Terminal Ileum | 2, Ascending colon | 3, Transverse colon | 4, Descending colon | 5, Sigmoid colon | 6, Sigmoid-rectum | 7, Rectum | 888, Other | 999, N/A\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['PBMC' 'Larval intestinal dissection; Tyto sorting for GFP+ lymphocytes'\n",
      " 'Rectum' 'Sigmoid' 'Rectum, proctectomy, biopsies'\n",
      " 'Sigmoid, proctectomy, biopsies' 'Rectum, colonoscopy, biopsies'\n",
      " 'Terminal ileum, colonoscopy, biopsies'\n",
      " 'Sigmoid colon, colonoscopy, biopsies' 'Rectum, proectectomy, biopsies'\n",
      " 'Fistula tract lining, proctectomy, biopsies'\n",
      " 'Rectum, proctectomy --> biopsies' 'Fistula, proctectomy --> biopsies'\n",
      " 'Larval intestinal dissection' 'Terminal ileum' 'PBMCs' 'sigmoid, biopsy'\n",
      " 'rectum, biopsy' 'Transverse Colon, biopsy'\n",
      " 'Colon organoid (excl. cecum)' 'Rectum (10cm)-Inflamed Biopsy'\n",
      " 'Sigmoid (35cm)- Uninflamed Biopsy' 'Rectum (10cm)-  Inflamed Biopsy'\n",
      " 'Sigmoid (25cm)- Uninflamed Biopsy' 'Ileum resection'\n",
      " 'Terminal Ileum Resection, Biopsies ' 'Whole blood'\n",
      " 'Colectomy, Biopsies from sigmoid colon'\n",
      " 'Colectomy, Biopsies from transverse colon' 'Ileal resection'\n",
      " 'Terminal Ileal Resection, Biopsies ']\n",
      "None\n",
      "\n",
      "\n",
      "no_live_cells\n",
      "\n",
      "--\n",
      "\n",
      "NH0009, NH0010, NH0011, NH0012, NH0013, NH0014, NH0015, NH0016, QQ0001, QQ0002, QQ0003, QQ0004, QQ0005, QQ0006, QQ0007, QQ0008, QQ0009, QQ0010, QQ0011, QQ0012, QQ0013, QQ0014, QQ0015, QQ0016, QQ0017, QQ0018, QQ0019, QQ0020, QQ0021, QQ0022, QQ0023, QQ0024, QQ0025, QQ0026, QQ0027, QQ0028, QQ0029, QQ0030, QQ0031, QQ0032, QQ0033, QQ0034, QQ0035, QQ0036, QQ0037, QQ0038, QQ0039, QQ0040, QQ0041, QQ0042, QQ0043, QQ0049, QQ0050, QQ0051, QQ0052, QQ0053, QQ0054\n",
      "\n",
      "\n",
      "False\n",
      "no_live_cells\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "no_live_cells\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column no_live_cells to partial match: no_live_cells_1\n",
      "field_name                                                   no_live_cells_1\n",
      "form_name                                  sample_information_3_gex_multiome\n",
      "section_header    Single Cell 3': Standard Sample ID: [standard_sample_id_1]\n",
      "field_type                                                              text\n",
      "field_label                                    Number of live cells isolated\n",
      "Name: no_live_cells_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [type_of_experiment(3prime)] = '1' and ([no_of_samples_3_prime] = '1' or [no_of_samples_3_prime] = '2' or [no_of_samples_3_prime] = '3' or [no_of_samples_3_prime] = '4' or [no_of_samples_3_prime] = '5' or [no_of_samples_3_prime] = '6' or [no_of_samples_3_prime] = '7' or [no_of_samples_3_prime] = '8')\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " [9.40e+04 3.00e+03 4.47e+05 1.40e+06 1.07e+06 6.34e+05 1.24e+06 1.03e+06\n",
      " 2.12e+06 2.23e+05 6.71e+05 8.04e+04 6.11e+05 3.76e+05 4.25e+05 7.26e+04\n",
      " 1.84e+05 1.05e+05 2.37e+04 6.44e+05 4.96e+05 1.60e+06 6.97e+05 5.20e+06\n",
      " 1.58e+07 9.95e+05 6.25e+05 3.38e+06 1.75e+06 6.02e+05 3.66e+05 4.08e+05\n",
      " 6.75e+05 1.15e+05 1.16e+06 2.86e+05 1.87e+05 1.49e+05 2.57e+05 3.36e+05\n",
      " 2.11e+05 6.50e+05 4.11e+05 6.29e+05 1.83e+06 1.17e+06 5.34e+05 5.85e+05\n",
      " 5.70e+05 9.96e+05 5.48e+05 7.47e+05 7.87e+05 9.51e+05 5.14e+05 6.49e+05\n",
      " 8.84e+05 8.65e+05      nan 6.48e+06 7.12e+06 4.33e+05 2.66e+05 1.44e+05\n",
      " 3.62e+05 4.04e+05 2.02e+05 2.48e+05 2.60e+05 1.94e+05 1.00e+06 1.34e+06\n",
      " 9.00e+05 8.00e+05 4.17e+05 1.00e+05 6.17e+04 2.96e+05]\n",
      "None\n",
      "\n",
      "\n",
      "cell_viability_percentage\n",
      "\n",
      "--\n",
      "\n",
      "RL0007, RL0008, RL0009, RL0010, RL0013, RL0014, RL0015, RL0016, RL0025, RL0026, RL0027, RL0028, RL0031, RL0032, RL0033, RL0034, RL0037, RL0038, RL0039, RL0040, UC0001, UC0002, UC0003, UC0004, QQ0001, QQ0002, QQ0003, QQ0004, QQ0005, QQ0006, QQ0007, QQ0008, QQ0009, QQ0010, QQ0011, QQ0012, QQ0013, QQ0014, QQ0015, QQ0016, QQ0017, QQ0018, QQ0019, QQ0020, QQ0021, QQ0022, QQ0023, QQ0024, QQ0025, QQ0026, QQ0027, QQ0028, QQ0029, QQ0030, QQ0031, QQ0032, QQ0033, QQ0034, QQ0035, QQ0036, QQ0037, QQ0038, QQ0039, QQ0040, QQ0041, QQ0042, QQ0043, QQ0044, QQ0045, QQ0046, QQ0047, QQ0048, QQ0049, QQ0050, QQ0051, QQ0052, QQ0053, QQ0054, QQ0055, QQ0056, QQ0057, QQ0058, QQ0059\n",
      "\n",
      "\n",
      "False\n",
      "cell_viability_percentage\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "cell_viability_percentage\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column cell_viability_percentage to partial match: cell_viability_percentage_1\n",
      "field_name              cell_viability_percentage_1\n",
      "form_name         sample_information_3_gex_multiome\n",
      "section_header                                     \n",
      "field_type                                     text\n",
      "field_label               Cell Viability Percentage\n",
      "Name: cell_viability_percentage_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [type_of_experiment(3prime)] = '1' and ([no_of_samples_3_prime] = '1' or [no_of_samples_3_prime] = '2' or [no_of_samples_3_prime] = '3' or [no_of_samples_3_prime] = '4' or [no_of_samples_3_prime] = '5' or [no_of_samples_3_prime] = '6' or [no_of_samples_3_prime] = '7' or [no_of_samples_3_prime] = '8')\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " [76.6 95.  92.  88.  78.  94.  93.7 77.8 76.7 64.9 53.2 83.3 89.4  nan\n",
      " 82.4 79.3 90.  89.8 85.9 87.6 84.1 54.  67.9 69.2 74.1 58.2 73.9 57.2\n",
      " 68.1  0.7  0.2 61.7 69.8 84.5 89.5 88.2 43.7 40.3 58.9 49.8 41.6 46.5\n",
      " 43.1 52.3 41.8 36.4 36.7 85.3 96.  80.3 79.9 81.3 77.  64.5 72.  63.4\n",
      " 70.  50.8 63.3 74.2 67.2 71.3 60.5 65.2 63.7 72.5]\n",
      "None\n",
      "\n",
      "\n",
      "targ_cell\n",
      "\n",
      "--\n",
      "\n",
      "QQ0001, QQ0002, QQ0003, QQ0004, QQ0005, QQ0006, QQ0007, QQ0008, QQ0009, QQ0010, QQ0011, QQ0012, QQ0013, QQ0014, QQ0015, QQ0016, QQ0017, QQ0018, QQ0019, QQ0020, QQ0021, QQ0022, QQ0023, QQ0024, QQ0025, QQ0026, QQ0027, QQ0028, QQ0029, QQ0030, QQ0031, QQ0032, QQ0033, QQ0034\n",
      "\n",
      "\n",
      "False\n",
      "targ_cell\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "targ_cell\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column targ_cell to partial match: targ_cell_1\n",
      "field_name                              targ_cell_1\n",
      "form_name         sample_information_3_gex_multiome\n",
      "section_header                                     \n",
      "field_type                                     text\n",
      "field_label                  Targeted Cell Recovery\n",
      "Name: targ_cell_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [type_of_experiment(3prime)] = '1' and ([no_of_samples_3_prime] = '1' or [no_of_samples_3_prime] = '2' or [no_of_samples_3_prime] = '3' or [no_of_samples_3_prime] = '4' or [no_of_samples_3_prime] = '5' or [no_of_samples_3_prime] = '6' or [no_of_samples_3_prime] = '7' or [no_of_samples_3_prime] = '8')\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['6000' '3000' '10000' '5000' 'No load' '9000' '8000' '4000' nan '1000']\n",
      "None\n",
      "\n",
      "\n",
      "no_live_nuclei\n",
      "\n",
      "--\n",
      "\n",
      "HH0001, J00002, J00003, J00004, J00005, LC0001, LC0003, LC0005, RL0001, RL0001_re, RL0002, RL0002_re, RL0003, RL0004, RL0005, RL0006, RL0007, RL0008, RL0009, RL0010, RL0011, RL0012, RL0013, RL0014, RL0015, RL0016, RL0017, RL0018, RL0019, RL0020, RL0021, RL0022, RL0023, RL0024, RL0025, RL0026, RL0027, RL0028, RL0029, RL0030, RL0031, RL0032, RL0033, RL0034, RL0035, RL0036, RL0041, RL0042, RL0047, RL0048, RL0049, RL0050, RL0053, RL0054, SN0001, SN0002, SN0003, SN0004, SN0005, SN0006, SN0007, SN0008, SN0009, SN0010, SN0011, SN0012, SN0013, SN0014, UC0001, UC0002, UC0003, UC0004, NH0001, NH0002, NH0003, NH0004, NH0005, NH0006, NH0007, NH0008, NH0009, NH0010, NH0011, NH0012, NH0013, NH0014, NH0015, NH0016, QQ0001, QQ0002, QQ0003, QQ0004, QQ0005, QQ0006, QQ0007, QQ0008, QQ0009, QQ0010, QQ0011, QQ0012, QQ0013, QQ0014, QQ0015, QQ0016, QQ0017, QQ0018, QQ0019, QQ0020, QQ0021, QQ0022, QQ0023, QQ0024, QQ0025, QQ0026, QQ0027, QQ0028, QQ0029, QQ0030, QQ0031, QQ0032, QQ0033, QQ0034, AA1inf, AA1non, QQ0035, QQ0036, QQ0037, QQ0038, QQ0039, QQ0040, QQ0041, QQ0042, QQ0043, QQ0044, QQ0045, QQ0046, QQ0047, QQ0048, QQ0049, QQ0050, QQ0051, QQ0052, QQ0053, QQ0054, QQ0055, QQ0056, QQ0057, QQ0058, QQ0059, KC0004, KC0002, KC0003, KC0005, KC0001, CD0001, CD0002, CD0003, CD0004\n",
      "\n",
      "\n",
      "False\n",
      "no_live_nuclei\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "no_live_nuclei\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column no_live_nuclei to partial match: no_live_nuclei_1\n",
      "field_name                                                                               no_live_nuclei_1\n",
      "form_name                                                               sample_information_3_gex_multiome\n",
      "section_header    Single Cell Multiome ATAC + Gene Expression: Standard Sample ID: [standard_sample_id_1]\n",
      "field_type                                                                                           text\n",
      "field_label                                                                     Number of nuclei isolated\n",
      "Name: no_live_nuclei_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [type_of_experiment(atac)] = '1' and ([no_of_samples_multiome] = '1' or [no_of_samples_multiome] = '2' or [no_of_samples_multiome] = '3' or [no_of_samples_multiome] = '4' or [no_of_samples_multiome] = '5' or [no_of_samples_multiome] = '6' or [no_of_samples_multiome] = '7' or [no_of_samples_multiome] = '8')\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " [nan '447000' '99900' '64000' 'Est: 497.5K' 'Est: 213.5K' '2940000'\n",
      " '1510000' '1030000']\n",
      "None\n",
      "\n",
      "\n",
      "no_nuclei\n",
      "\n",
      "--\n",
      "\n",
      "HH0001, J00002, J00003, J00004, J00005, LC0001, LC0003, LC0005, RL0001, RL0001_re, RL0002, RL0002_re, RL0003, RL0004, RL0005, RL0006, RL0007, RL0011, RL0012, RL0017, RL0018, RL0019, RL0020, RL0021, RL0022, RL0023, RL0024, RL0029, RL0030, RL0035, RL0036, RL0041, RL0042, RL0047, RL0048, RL0049, RL0050, RL0053, RL0054, SN0001, SN0002, SN0003, SN0004, SN0005, SN0006, SN0007, SN0008, SN0009, SN0010, SN0011, SN0012, SN0013, SN0014, UC0001, UC0002, UC0003, UC0004, NH0001, NH0002, NH0003, NH0004, NH0005, NH0006, NH0007, NH0008, NH0009, NH0010, NH0011, NH0012, NH0013, NH0014, NH0015, NH0016, QQ0001, QQ0002, QQ0003, QQ0004, QQ0005, QQ0006, QQ0007, QQ0008, QQ0009, QQ0010, QQ0011, QQ0012, QQ0013, QQ0014, QQ0015, QQ0016, QQ0017, QQ0018, QQ0019, QQ0020, QQ0021, QQ0022, QQ0023, QQ0024, QQ0025, QQ0026, QQ0027, QQ0028, QQ0029, QQ0030, QQ0031, QQ0032, QQ0033, QQ0034, AA1inf, AA1non, QQ0035, QQ0036, QQ0037, QQ0038, QQ0039, QQ0040, QQ0041, QQ0042, QQ0043, QQ0044, QQ0045, QQ0046, QQ0047, QQ0048, QQ0049, QQ0050, QQ0051, QQ0052, QQ0053, QQ0054, QQ0055, QQ0056, QQ0057, QQ0058, QQ0059, KC0004, KC0002, KC0003, KC0005, KC0001, CD0001, CD0002, CD0003, CD0004\n",
      "\n",
      "\n",
      "False\n",
      "no_nuclei\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "no_nuclei\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column no_nuclei to partial match: no_nuclei_1\n",
      "field_name                              no_nuclei_1\n",
      "form_name         sample_information_3_gex_multiome\n",
      "section_header                                     \n",
      "field_type                                     text\n",
      "field_label                 Number of Nuclei Loaded\n",
      "Name: no_nuclei_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [type_of_experiment(atac)] = '1' and ([no_of_samples_multiome] = '1' or [no_of_samples_multiome] = '2' or [no_of_samples_multiome] = '3' or [no_of_samples_multiome] = '4' or [no_of_samples_multiome] = '5' or [no_of_samples_multiome] = '6' or [no_of_samples_multiome] = '7' or [no_of_samples_multiome] = '8')\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " [   nan 10000.]\n",
      "None\n",
      "\n",
      "\n",
      "index_kit\n",
      "\n",
      "--\n",
      "\n",
      "SN0003, SN0004, NH0001, NH0002, NH0003, NH0004, NH0005, NH0006, NH0007, NH0008, NH0009, NH0010, NH0011, NH0012, NH0013, NH0014, NH0015, NH0016, QQ0001, QQ0002, QQ0003, QQ0004, QQ0005, QQ0006, QQ0007, QQ0008, QQ0009, QQ0010, QQ0011, QQ0012, QQ0013, QQ0014, QQ0015, QQ0016, QQ0017, QQ0018, QQ0019, QQ0020, QQ0021, QQ0022, QQ0023, QQ0024, QQ0025, QQ0026, QQ0027, QQ0028, QQ0029, QQ0030, QQ0031, QQ0032, QQ0033, QQ0034, AA1inf, AA1non, QQ0035, QQ0036, QQ0037, QQ0038, QQ0039, QQ0040, QQ0041, QQ0042, QQ0043, QQ0044, QQ0045, QQ0046, QQ0047, QQ0048, QQ0049, QQ0050, QQ0051, QQ0052, QQ0053, QQ0054, QQ0055, QQ0056, QQ0057, QQ0058, QQ0059, KC0004, KC0002, KC0003, KC0005, KC0001\n",
      "\n",
      "\n",
      "False\n",
      "index_kit\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "index_kit\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column index_kit to partial match: index_kit_1\n",
      "field_name                        index_kit_1\n",
      "form_name         library_prep_3_gex_multiome\n",
      "section_header                               \n",
      "field_type                              radio\n",
      "field_label                         Index Kit\n",
      "Name: index_kit_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [type_of_experiment(3prime)] = '1'\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, Dual Index TT | 2, Dual Index TS\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['SI-TT-E2' 'SI-TT-D1' 'SI-TT-D2' 'SI-TT-D3' 'SI-TT-D4' 'SI-TT-D7'\n",
      " 'SI-NA-C2' 'SI-TT-E5' 'SI-NA-F2' 'SI-TT-E6' 'SI-NA-G2' 'SI-TT-E1'\n",
      " 'SI-TT-A11' 'SI-TT-A12' 'SI-TT-G7' 'SI-TT-G8' 'SI-TT-A1' 'SI-TT-A2'\n",
      " 'SI-NA-A1' 'SI-NA-B1' 'SI-TT-A9' 'SI-TT-A10' 'SI-TT-A7' 'SI-TT-A8'\n",
      " 'SI-NA-C1' 'SI-NA-D1' 'SI-TT-B1' 'SI-TT-B2' 'SI-TT-B9' 'SI-TT-B10'\n",
      " 'SI-TT-B4' 'SI-TT-B5' 'SI-TT-B8' 'SI-TT-B11' 'SI-TT-C3' 'SI-TT-C4'\n",
      " 'SI-NA-E1' 'SI-NA-F1' 'SI-TT-C1' 'SI-TT-C2' 'SI-TT-C5' 'SI-TT-C6'\n",
      " 'SI-NA-G1' 'SI-NA-H1' 'SI-TT-C9' 'SI-TT-C10' 'SI-TT-D5' 'SI-TT-D6'\n",
      " 'SI-NA-A2' 'SI-NA-B2' 'SI-TT-D10' 'SI-TT-D11' 'SI-TT-D8' 'SI-TT-D9'\n",
      " 'SI-NA-D2' 'SI-NA-E2' 'SI-TT-D12' 'SI-TT-E3' 'SI-TT-E4' 'SI-TT-F5'\n",
      " 'SI-N-D3' 'SI-TT-F3' 'SI-TT-F4' 'SI-TT-G10' 'SI-TT-G11' nan 'SI-TT-H1'\n",
      " 'SI-TT-H2' 'SI-TT-H3' 'SI-TT-H4' 'SI-TT-A3' 'SI-TT-A4' 'SI-TT-A5'\n",
      " 'SI-TT-A6' 'SI-TT-B6' 'SI-TT-B7' 'SI-TT-H9' 'SI-TT-H10' 'SI-TT-H11'\n",
      " 'SI-TT-H12' 'SI-TT-H5' 'SI-TT-H6' 'SI-TT-H7' 'SI-TT-H8']\n",
      "None\n",
      "\n",
      "\n",
      "pre_amp_date\n",
      "\n",
      "--\n",
      "\n",
      "SN0003, SN0004, NH0001, NH0002, NH0003, NH0004, NH0005, NH0006, NH0007, NH0008, NH0009, NH0010, NH0011, NH0012, NH0013, NH0014, NH0015, NH0016, QQ0001, QQ0002, QQ0003, QQ0004, QQ0005, QQ0006, QQ0007, QQ0008, QQ0009, QQ0010, QQ0011, QQ0012, QQ0013, QQ0014, QQ0015, QQ0016, QQ0017, QQ0018, QQ0019, QQ0020, QQ0021, QQ0022, QQ0023, QQ0024, QQ0025, QQ0026, QQ0027, QQ0028, QQ0029, QQ0030, QQ0031, QQ0032, QQ0033, QQ0034, AA1inf, AA1non, QQ0035, QQ0036, QQ0037, QQ0038, QQ0039, QQ0040, QQ0041, QQ0042, QQ0043, QQ0044, QQ0045, QQ0046, QQ0047, QQ0048, QQ0049, QQ0050, QQ0051, QQ0052, QQ0053, QQ0054, QQ0055, QQ0056, QQ0057, QQ0058, QQ0059, KC0004, KC0002, KC0003, KC0005, KC0001\n",
      "\n",
      "\n",
      "False\n",
      "pre_amp_date\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "pre_amp_date\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column pre_amp_date to partial match: pre_amp_date_1\n",
      "field_name                                     pre_amp_date_1\n",
      "form_name                         library_prep_3_gex_multiome\n",
      "section_header    Single Cell Multiome ATAC + Gene Expression\n",
      "field_type                                               text\n",
      "field_label                                    Pre-Amp Date 1\n",
      "Name: pre_amp_date_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [type_of_experiment(atac)] = '1'\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['05-23-2022' '03-08-2022' '03-11-2022' '03-17-2022' '03-31-2022'\n",
      " '04-27-2022' '07-12-2022' '06-01-2021' '06-17-2021' '06-28-2021'\n",
      " '07-08-2021' '07-26-2021' '07-27-2021' '09-01-2021' '09-16-2021'\n",
      " '09-28-2021' '10-12-2021' '10-04-2021' '10-18-2021' '04-22-2022'\n",
      " '04-29-2022' '06-15-2022' '12-21-2022' '12-19-2022' '06-09-2021' nan\n",
      " '07-20-2021' '04-01-2021']\n",
      "None\n",
      "\n",
      "\n",
      "date_sent\n",
      "\n",
      "--\n",
      "\n",
      "SN0003, SN0004, NH0001, NH0002, NH0003, NH0004, NH0005, NH0006, NH0007, NH0008, NH0009, NH0010, NH0011, NH0012, NH0013, NH0014, NH0015, NH0016, QQ0001, QQ0002, QQ0003, QQ0004, QQ0005, QQ0006, QQ0007, QQ0008, QQ0009, QQ0010, QQ0011, QQ0012, QQ0013, QQ0014, QQ0015, QQ0016, QQ0017, QQ0018, QQ0019, QQ0020, QQ0021, QQ0022, QQ0023, QQ0024, QQ0025, QQ0026, QQ0027, QQ0028, QQ0029, QQ0030, QQ0031, QQ0032, QQ0033, QQ0034, AA1inf, AA1non, QQ0035, QQ0036, QQ0037, QQ0038, QQ0039, QQ0040, QQ0041, QQ0042, QQ0043, QQ0044, QQ0045, QQ0046, QQ0047, QQ0048, QQ0049, QQ0050, QQ0051, QQ0052, QQ0053, QQ0054, QQ0055, QQ0056, QQ0057, QQ0058, QQ0059, KC0004, KC0002, KC0003, KC0005, KC0001\n",
      "\n",
      "\n",
      "False\n",
      "date_sent\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "date_sent\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column date_sent to partial match: date_sent_1\n",
      "field_name         date_sent_1\n",
      "form_name           sequencing\n",
      "section_header                \n",
      "field_type                text\n",
      "field_label       Date Sent: 1\n",
      "Name: date_sent_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['07-11-2022' '03-08-2022' '03-21-2022' '04-05-2022' '04-28-2022'\n",
      " '04-27-2022' '07-12-2022' '06-08-2021' '06-09-2021' '06-22-2021'\n",
      " '07-13-2021' '07-15-2021' '07-14-2021' '07-29-2021' '07-28-2021'\n",
      " '07-30-2021' '10-05-2021' '10-07-2021' '10-14-2021' '10-18-2021'\n",
      " '05-18-2022' '12-27-2022' '06-13-2023' '12-21-2022' '06-14-2021' nan\n",
      " '07-22-2021' '04-08-2021']\n",
      "None\n",
      "\n",
      "\n",
      "instrument\n",
      "\n",
      "--\n",
      "\n",
      "SN0003, SN0004, NH0001, NH0002, NH0003, NH0004, NH0005, NH0006, NH0007, NH0008, NH0009, NH0010, NH0011, NH0012, NH0013, NH0014, NH0015, NH0016, QQ0001, QQ0002, QQ0003, QQ0004, QQ0005, QQ0006, QQ0007, QQ0008, QQ0009, QQ0010, QQ0011, QQ0012, QQ0013, QQ0014, QQ0015, QQ0016, QQ0017, QQ0018, QQ0019, QQ0020, QQ0021, QQ0022, QQ0023, QQ0024, QQ0025, QQ0026, QQ0027, QQ0028, QQ0029, QQ0030, QQ0031, QQ0032, QQ0033, QQ0034, AA1inf, AA1non, QQ0035, QQ0036, QQ0037, QQ0038, QQ0039, QQ0040, QQ0041, QQ0042, QQ0043, QQ0044, QQ0045, QQ0046, QQ0047, QQ0048, QQ0049, QQ0050, QQ0051, QQ0052, QQ0053, QQ0054, QQ0055, QQ0056, QQ0057, QQ0058, QQ0059, KC0004, KC0002, KC0003, KC0005, KC0001\n",
      "\n",
      "\n",
      "False\n",
      "instrument\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "instrument\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column instrument to partial match: instrument_1\n",
      "field_name        instrument_1\n",
      "form_name           sequencing\n",
      "section_header                \n",
      "field_type               radio\n",
      "field_label         Instrument\n",
      "Name: instrument_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " \n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, NovaSeq 6000 | 2, NextSeq 2000 | 3, Not Sequenced\n",
      "\n",
      "********************************************************************************\n",
      "Unique Metadatabase Values:\n",
      "\n",
      " ['NovaSeq S4' 'NovaSeq SP' 'NovaSeq S1' 'Not Sequenced' 'NovaSeq S2' nan]\n",
      "None\n",
      "\n",
      "\n",
      "novaseq\n",
      "\n",
      "--\n",
      "\n",
      "RL0007, RL0009, SN0003, SN0004, NH0001, NH0002, NH0003, NH0004, NH0005, NH0006, NH0007, NH0008, NH0009, NH0010, NH0011, NH0012, NH0013, NH0014, NH0015, NH0016, QQ0001, QQ0002, QQ0003, QQ0004, QQ0005, QQ0006, QQ0007, QQ0008, QQ0009, QQ0010, QQ0011, QQ0012, QQ0013, QQ0014, QQ0015, QQ0016, QQ0017, QQ0018, QQ0019, QQ0020, QQ0021, QQ0022, QQ0023, QQ0024, QQ0025, QQ0026, QQ0027, QQ0028, QQ0029, QQ0030, QQ0031, QQ0032, QQ0033, QQ0034, AA1inf, AA1non, QQ0035, QQ0036, QQ0037, QQ0038, QQ0039, QQ0040, QQ0041, QQ0042, QQ0043, QQ0044, QQ0045, QQ0046, QQ0047, QQ0048, QQ0049, QQ0050, QQ0051, QQ0052, QQ0053, QQ0054, QQ0055, QQ0056, QQ0057, QQ0058, QQ0059, KC0004, KC0002, KC0003, KC0005, KC0001\n",
      "\n",
      "\n",
      "False\n",
      "novaseq\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "novaseq\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column novaseq to partial match: novaseq_6000_1\n",
      "field_name                   novaseq_6000_1\n",
      "form_name                        sequencing\n",
      "section_header                             \n",
      "field_type                            radio\n",
      "field_label       Flow Cell: NovaSeq 6000 1\n",
      "Name: novaseq_6000_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [instrument_1]='1'\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, S4 | 2, S2 | 3, S1 | 4, SP | 5, Not Sequenced\n",
      "novaseq not in metadatabase column names\n",
      "None\n",
      "\n",
      "\n",
      "nextseq\n",
      "\n",
      "--\n",
      "\n",
      "HH0001, J00002, J00003, J00004, J00005, LC0001, LC0002, LC0003, LC0004, LC0005, LC0006, RL0001, RL0001_re, RL0002, RL0002_re, RL0003, RL0004, RL0005, RL0006, RL0007, RL0008, RL0009, RL0010, RL0011, RL0012, RL0013, RL0014, RL0015, RL0016, RL0017, RL0018, RL0019, RL0020, RL0021, RL0022, RL0023, RL0024, RL0025, RL0026, RL0027, RL0028, RL0029, RL0030, RL0031, RL0032, RL0033, RL0034, RL0035, RL0036, RL0037, RL0038, RL0039, RL0040, RL0041, RL0042, RL0043, RL0044, RL0045, RL0046, RL0047, RL0048, RL0049, RL0050, RL0051, RL0052, RL0053, RL0054, SN0001, SN0002, SN0003, SN0004, SN0005, SN0006, SN0007, SN0008, SN0009, SN0010, SN0011, SN0012, SN0013, SN0014, UC0001, UC0002, UC0003, UC0004, NH0001, NH0002, NH0003, NH0004, NH0005, NH0006, NH0007, NH0008, NH0009, NH0010, NH0011, NH0012, NH0013, NH0014, NH0015, NH0016, QQ0001, QQ0002, QQ0003, QQ0004, QQ0005, QQ0006, QQ0007, QQ0008, QQ0009, QQ0010, QQ0011, QQ0012, QQ0013, QQ0014, QQ0015, QQ0016, QQ0017, QQ0018, QQ0019, QQ0020, QQ0021, QQ0022, QQ0023, QQ0024, QQ0025, QQ0026, QQ0027, QQ0028, QQ0029, QQ0030, QQ0031, QQ0032, QQ0033, QQ0034, AA1inf, AA1non, QQ0035, QQ0036, QQ0037, QQ0038, QQ0039, QQ0040, QQ0041, QQ0042, QQ0043, QQ0044, QQ0045, QQ0046, QQ0047, QQ0048, QQ0049, QQ0050, QQ0051, QQ0052, QQ0053, QQ0054, QQ0055, QQ0056, QQ0057, QQ0058, QQ0059, KC0004, KC0002, KC0003, KC0005, KC0001, CD0001, CD0002, CD0003, CD0004\n",
      "\n",
      "\n",
      "False\n",
      "nextseq\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "nextseq\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Changing column nextseq to partial match: nextseq_2000_1\n",
      "field_name                   nextseq_2000_1\n",
      "form_name                        sequencing\n",
      "section_header                             \n",
      "field_type                            radio\n",
      "field_label       Flow Cell: Nextseq 2000 1\n",
      "Name: nextseq_2000_1, dtype: object\n",
      "\n",
      "********************************************************************************\n",
      "Branching Logic:\n",
      "\n",
      " [instrument_1]='2'\n",
      "\n",
      "********************************************************************************\n",
      "Categories:\n",
      "\n",
      " 1, P1 | 2, P2 | 3, P3 | 4, Not Sequenced\n",
      "nextseq not in metadatabase column names\n",
      "None\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Missingness\n",
      "\n",
      "================================================================================\n",
      "\n",
      "disease: 0\n",
      "disease_status: 0\n",
      "grid: 0\n",
      "patient_id: 0\n",
      "animal_line: 0\n",
      "tissue_origin: 67\n",
      "no_live_cells: 57\n",
      "cell_viability_percentage: 83\n",
      "targ_cell: 34\n",
      "no_live_nuclei: 158\n",
      "no_nuclei: 143\n",
      "index_kit: 84\n",
      "pre_amp_date: 84\n",
      "date_sent: 84\n",
      "instrument: 84\n",
      "novaseq: 86\n",
      "nextseq: 171\n"
     ]
    }
   ],
   "source": [
    "# Missingness\n",
    "missing_bad = {\"grid\": data.organism == \"Human\",\n",
    "               \"patient_id\": data.organism == \"Human\",\n",
    "               \"animal_line\": data.organism != \"Human\",\n",
    "               \"disease\": data.organism == \"Human\",\n",
    "               \"disease_status\": data.apply(\n",
    "                   lambda x: (x[\"organism\"].lower() == \"human\") and (\n",
    "                       \"healthy\" not in x[\"disease\"].lower()), axis=1)}\n",
    "missingness = data.apply(lambda x: sum(pd.isnull(x)))\n",
    "nawah = dict()\n",
    "for i in missingness[missingness > 0].index.values:\n",
    "    if i in missing_bad:\n",
    "        nab = data[pd.isnull(data[i]) & (missing_bad[i])][list(\n",
    "                missing_bad.keys())]  # only if NAs unexpected\n",
    "    else:\n",
    "        nab = data[pd.isnull(data[i])][[i]]  # all NAs\n",
    "    nawah.update({i: nab})\n",
    "    if nab.shape[0] > 0:\n",
    "        print(f\"\\n\\n{i}\\n\\n--\\n\\n{', '.join(nab.index.values)}\\n\\n\")\n",
    "        print(investigate_fields(i, data_rc=data_dict, \n",
    "                                data_meta=dff, pattern=True))\n",
    "na_counts = \"\\n\".join([f\"{i}: {nawah[i].shape[0]}\" for i in nawah])\n",
    "print(f\"\\n\\n{'=' * 80}\\n\\nMissingness\\n\\n{'=' * 80}\\n\\n{na_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeated Measures Transformation: Google Data to Wide Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_362937/2940228326.py:46: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  data_wide = data_wide.astype(object).pivot(\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_new[i] = np.nan\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 497.5K\n",
      "497500.0 \n",
      "\n",
      "\n",
      "Est: 213.5K\n",
      "213500.0 \n",
      "\n",
      "\n",
      "Est: 497.5K\n",
      "497500.0 \n",
      "\n",
      "\n",
      "Est: 213.5K\n",
      "213500.0 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
      "/tmp/ipykernel_362937/2940228326.py:99: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>pre_amp_date_5</th>\n",
       "      <th>no_nuclei_3</th>\n",
       "      <th>index_kit_3</th>\n",
       "      <th>instrument_3</th>\n",
       "      <th>instrument_5</th>\n",
       "      <th>standard_sample_id_6</th>\n",
       "      <th>targ_cell_2</th>\n",
       "      <th>targ_cell_3</th>\n",
       "      <th>experiment_6</th>\n",
       "      <th>x_chem_version_sc_5</th>\n",
       "      <th>date_sent_1</th>\n",
       "      <th>sc_process_date_1</th>\n",
       "      <th>inflam_status_6</th>\n",
       "      <th>standard_sample_id_3</th>\n",
       "      <th>lib_id_2</th>\n",
       "      <th>standard_sample_id_4</th>\n",
       "      <th>experiment_2</th>\n",
       "      <th>targ_cell_5</th>\n",
       "      <th>no_live_nuclei_1</th>\n",
       "      <th>inflam_status_3</th>\n",
       "      <th>no_live_nuclei_2</th>\n",
       "      <th>disease</th>\n",
       "      <th>sc_process_date_6</th>\n",
       "      <th>inflam_status_chronicity_2</th>\n",
       "      <th>...</th>\n",
       "      <th>cell_viability_percentage_1</th>\n",
       "      <th>cell_viability_percentage_4</th>\n",
       "      <th>sc_process_date_2</th>\n",
       "      <th>pre_amp_date_2</th>\n",
       "      <th>inflam_status_2</th>\n",
       "      <th>pre_amp_date_1</th>\n",
       "      <th>lib_id_1</th>\n",
       "      <th>sc_process_date_3</th>\n",
       "      <th>no_live_cells_2</th>\n",
       "      <th>tissue_origin_3</th>\n",
       "      <th>experiment_5</th>\n",
       "      <th>tissue_origin_2</th>\n",
       "      <th>cell_viability_percentage_5</th>\n",
       "      <th>cell_viability_percentage_6</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>lib_id_4</th>\n",
       "      <th>x_chem_version_sc_1</th>\n",
       "      <th>date_sent_3</th>\n",
       "      <th>no_live_cells_6</th>\n",
       "      <th>no_live_cells_5</th>\n",
       "      <th>standard_sample_id_1</th>\n",
       "      <th>instrument_6</th>\n",
       "      <th>no_nuclei_4</th>\n",
       "      <th>type_of_experiment___atac</th>\n",
       "      <th>type_of_experiment___3prime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FC_Hu_AA</th>\n",
       "      <td>forms_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/01/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Healthy Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QQ0033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FC_Hu_AA_PBMC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FC_Hu_EA</th>\n",
       "      <td>forms_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/01/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Healthy Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QQ0034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FC_Hu_EA_PBMC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FC_Hu_IL1</th>\n",
       "      <td>forms_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/01/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QQ0032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CITE-seq</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Crohn's Disease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/01/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-inflamed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QQ0031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Terminal Ileum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FC_Hu_IL1_Inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FC_Hu_IL2</th>\n",
       "      <td>forms_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/08/2021</td>\n",
       "      <td>03/01/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CD0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CITE-seq</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Crohn's Disease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/01/2021</td>\n",
       "      <td>04/01/2021</td>\n",
       "      <td>Non-inflamed</td>\n",
       "      <td>04/01/2021</td>\n",
       "      <td>CD0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Terminal Ileum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FC_Hu_IL2_Inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FC_Hu_IL3</th>\n",
       "      <td>forms_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/08/2021</td>\n",
       "      <td>03/01/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CD0004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CITE-seq</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Crohn's Disease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/01/2021</td>\n",
       "      <td>04/01/2021</td>\n",
       "      <td>Non-inflamed</td>\n",
       "      <td>04/01/2021</td>\n",
       "      <td>CD0003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Terminal Ileum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FC_Hu_IL3_Inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          redcap_event_name pre_amp_date_5  no_nuclei_3 index_kit_3  \\\n",
       "record_id                                                             \n",
       "FC_Hu_AA        forms_arm_1            NaN         <NA>         NaN   \n",
       "FC_Hu_EA        forms_arm_1            NaN         <NA>         NaN   \n",
       "FC_Hu_IL1       forms_arm_1            NaN         <NA>         NaN   \n",
       "FC_Hu_IL2       forms_arm_1            NaN         <NA>         NaN   \n",
       "FC_Hu_IL3       forms_arm_1            NaN         <NA>         NaN   \n",
       "\n",
       "          instrument_3 instrument_5 standard_sample_id_6  targ_cell_2  \\\n",
       "record_id                                                               \n",
       "FC_Hu_AA           NaN          NaN                  NaN         <NA>   \n",
       "FC_Hu_EA           NaN          NaN                  NaN         <NA>   \n",
       "FC_Hu_IL1          NaN          NaN                  NaN         <NA>   \n",
       "FC_Hu_IL2          NaN          NaN                  NaN         5000   \n",
       "FC_Hu_IL3          NaN          NaN                  NaN         5000   \n",
       "\n",
       "           targ_cell_3 experiment_6 x_chem_version_sc_5 date_sent_1  \\\n",
       "record_id                                                             \n",
       "FC_Hu_AA          <NA>          NaN                 NaN         NaN   \n",
       "FC_Hu_EA          <NA>          NaN                 NaN         NaN   \n",
       "FC_Hu_IL1         <NA>          NaN                 NaN         NaN   \n",
       "FC_Hu_IL2         <NA>          NaN                 NaN  04/08/2021   \n",
       "FC_Hu_IL3         <NA>          NaN                 NaN  04/08/2021   \n",
       "\n",
       "          sc_process_date_1 inflam_status_6 standard_sample_id_3 lib_id_2  \\\n",
       "record_id                                                                   \n",
       "FC_Hu_AA         08/01/2020             NaN                  NaN      NaN   \n",
       "FC_Hu_EA         08/01/2020             NaN                  NaN      NaN   \n",
       "FC_Hu_IL1        10/01/2020             NaN                  NaN   QQ0032   \n",
       "FC_Hu_IL2        03/01/2021             NaN                  NaN   CD0002   \n",
       "FC_Hu_IL3        03/01/2021             NaN                  NaN   CD0004   \n",
       "\n",
       "          standard_sample_id_4 experiment_2  targ_cell_5  no_live_nuclei_1  \\\n",
       "record_id                                                                    \n",
       "FC_Hu_AA                   NaN          NaN         <NA>              <NA>   \n",
       "FC_Hu_EA                   NaN          NaN         <NA>              <NA>   \n",
       "FC_Hu_IL1                  NaN     CITE-seq         <NA>              <NA>   \n",
       "FC_Hu_IL2                  NaN     CITE-seq         <NA>              <NA>   \n",
       "FC_Hu_IL3                  NaN     CITE-seq         <NA>              <NA>   \n",
       "\n",
       "          inflam_status_3  no_live_nuclei_2          disease  \\\n",
       "record_id                                                      \n",
       "FC_Hu_AA              NaN              <NA>  Healthy Control   \n",
       "FC_Hu_EA              NaN              <NA>  Healthy Control   \n",
       "FC_Hu_IL1             NaN              <NA>  Crohn's Disease   \n",
       "FC_Hu_IL2             NaN              <NA>  Crohn's Disease   \n",
       "FC_Hu_IL3             NaN              <NA>  Crohn's Disease   \n",
       "\n",
       "          sc_process_date_6 inflam_status_chronicity_2  ...  \\\n",
       "record_id                                               ...   \n",
       "FC_Hu_AA                NaN                        NaN  ...   \n",
       "FC_Hu_EA                NaN                        NaN  ...   \n",
       "FC_Hu_IL1               NaN                        NaN  ...   \n",
       "FC_Hu_IL2               NaN                        NaN  ...   \n",
       "FC_Hu_IL3               NaN                        NaN  ...   \n",
       "\n",
       "           cell_viability_percentage_1 cell_viability_percentage_4  \\\n",
       "record_id                                                            \n",
       "FC_Hu_AA                           NaN                         NaN   \n",
       "FC_Hu_EA                           NaN                         NaN   \n",
       "FC_Hu_IL1                          NaN                         NaN   \n",
       "FC_Hu_IL2                         65.2                         NaN   \n",
       "FC_Hu_IL3                         69.2                         NaN   \n",
       "\n",
       "          sc_process_date_2 pre_amp_date_2  inflam_status_2 pre_amp_date_1  \\\n",
       "record_id                                                                    \n",
       "FC_Hu_AA                NaN            NaN              NaN            NaN   \n",
       "FC_Hu_EA                NaN            NaN              NaN            NaN   \n",
       "FC_Hu_IL1        10/01/2020            NaN     Non-inflamed            NaN   \n",
       "FC_Hu_IL2        03/01/2021     04/01/2021     Non-inflamed     04/01/2021   \n",
       "FC_Hu_IL3        03/01/2021     04/01/2021     Non-inflamed     04/01/2021   \n",
       "\n",
       "          lib_id_1 sc_process_date_3 no_live_cells_2 tissue_origin_3  \\\n",
       "record_id                                                              \n",
       "FC_Hu_AA    QQ0033               NaN            <NA>             NaN   \n",
       "FC_Hu_EA    QQ0034               NaN            <NA>             NaN   \n",
       "FC_Hu_IL1   QQ0031               NaN            <NA>             NaN   \n",
       "FC_Hu_IL2   CD0001               NaN          100000             NaN   \n",
       "FC_Hu_IL3   CD0003               NaN          296000             NaN   \n",
       "\n",
       "          experiment_5 tissue_origin_2 cell_viability_percentage_5  \\\n",
       "record_id                                                            \n",
       "FC_Hu_AA           NaN             NaN                         NaN   \n",
       "FC_Hu_EA           NaN             NaN                         NaN   \n",
       "FC_Hu_IL1          NaN  Terminal Ileum                         NaN   \n",
       "FC_Hu_IL2          NaN  Terminal Ileum                         NaN   \n",
       "FC_Hu_IL3          NaN  Terminal Ileum                         NaN   \n",
       "\n",
       "           cell_viability_percentage_6 patient_id  lib_id_4  \\\n",
       "record_id                                                     \n",
       "FC_Hu_AA                           NaN         AA       NaN   \n",
       "FC_Hu_EA                           NaN         EA       NaN   \n",
       "FC_Hu_IL1                          NaN        IL1       NaN   \n",
       "FC_Hu_IL2                          NaN        IL2       NaN   \n",
       "FC_Hu_IL3                          NaN        IL3       NaN   \n",
       "\n",
       "          x_chem_version_sc_1 date_sent_3  no_live_cells_6 no_live_cells_5  \\\n",
       "record_id                                                                    \n",
       "FC_Hu_AA                 v3.1         NaN             <NA>            <NA>   \n",
       "FC_Hu_EA                 v3.1         NaN             <NA>            <NA>   \n",
       "FC_Hu_IL1                v3.1         NaN             <NA>            <NA>   \n",
       "FC_Hu_IL2                v3.1         NaN             <NA>            <NA>   \n",
       "FC_Hu_IL3                v3.1         NaN             <NA>            <NA>   \n",
       "\n",
       "          standard_sample_id_1 instrument_6 no_nuclei_4  \\\n",
       "record_id                                                 \n",
       "FC_Hu_AA         FC_Hu_AA_PBMC          NaN        <NA>   \n",
       "FC_Hu_EA         FC_Hu_EA_PBMC          NaN        <NA>   \n",
       "FC_Hu_IL1        FC_Hu_IL1_Inf          NaN        <NA>   \n",
       "FC_Hu_IL2        FC_Hu_IL2_Inf          NaN        <NA>   \n",
       "FC_Hu_IL3        FC_Hu_IL3_Inf          NaN        <NA>   \n",
       "\n",
       "          type_of_experiment___atac type_of_experiment___3prime  \n",
       "record_id                                                        \n",
       "FC_Hu_AA                          1                           0  \n",
       "FC_Hu_EA                          1                           0  \n",
       "FC_Hu_IL1                         1                           0  \n",
       "FC_Hu_IL2                         1                           0  \n",
       "FC_Hu_IL3                         1                           0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for Transformation\n",
    "col_rm = \"sample\"\n",
    "data_new = data.groupby(cols_subject[0], group_keys=True).apply(\n",
    "    lambda x: x.assign(sample=np.arange(1, len(x) + 1))).reset_index(\n",
    "        data.index.names).set_index(\n",
    "        \"sample\", append=True)  # set uniform 1:n \"measurement\" column for RMs\n",
    "if cols_subject[0] in data_new.columns:\n",
    "    data_new = data_new.drop(cols_subject[0], axis=1)\n",
    "data_new.head()\n",
    "\n",
    "# Fields Overlapping between Google & REDCap\n",
    "fields_overlap = [data_dict.index.values[np.where([\n",
    "    re.search(\"^\" + i + \"(_[0-9]+)\", x) \n",
    "    for x in data_dict.index.values])[0]] for i in data_new.columns]\n",
    "fields_overlap = pd.Series(fields_overlap, index=pd.Index(\n",
    "    data_new.columns, name=\"Google\")).explode().dropna().to_frame(\"REDCap\")\n",
    "# print(fields_overlap)\n",
    "\n",
    "# Repeated Measures Fields\n",
    "fields_rm_num = fields_overlap.groupby(\"Google\").apply(\n",
    "    lambda x: pd.Series(list(x[\"REDCap\"].str.strip(\n",
    "        f\"{x.name}_\").astype(int).reset_index(0, drop=True)), \n",
    "                        index=pd.Index(x[\"REDCap\"], name=\"REDCap\")).to_frame(\n",
    "            \"Number\") if len(x[\"REDCap\"]) > 1 else np.nan)  # measurement #\n",
    "google_rm_num = data_new.groupby(cols_subject[0]).apply(lambda x: x.apply(\n",
    "    lambda y: len(y.unique()))).stack()  # Google sheet: # unique values / subject\n",
    "google_rm_num = google_rm_num[google_rm_num > 1]  # within-subject-varying only\n",
    "google_rm_num.index.names = [cols_subject[0], \"Field\"]\n",
    "cols_needed = google_rm_num.reset_index(0, drop=True).groupby(\"Field\").apply(\n",
    "    max)  # maximum # unique values / Google column = # REDCap RM categories needed\n",
    "fields_rm_num.Number.groupby(\"Google\").max().min()\n",
    "rm_num = fields_rm_num.Number.groupby(\"Google\").max().to_frame(\"REDCap\").join(\n",
    "    cols_needed.to_frame(\"Google\"))  # # of REDCap RM categories vs. # needed\n",
    "if any(rm_num.Google > rm_num.REDCap):\n",
    "    print(rm_num[rm_num.Google < rm_num.REDCap])\n",
    "    raise ValueError(\"Code to add more REDCap repeated measures fields required!\")\n",
    "# cols_needs_fields = list(set(pd.unique(\n",
    "#     google_rm_num.reset_index(0).index.values)).intersection(\n",
    "#         data_dict.field_name))  # Google RM columns that need fields in RC\n",
    "# print(f\"{'=' * 80}\\n\\n\\nNeed new RC RM fields:\\n\\n{cols_needs_fields}\\n\\n\")\n",
    "\n",
    "# Long to Wide Format\n",
    "data_wide = data_new.reset_index()[pd.unique([cols_subject[0], col_rm] + list(\n",
    "    rm_num.index.values))].reset_index()\n",
    "# data_wide[\"column_name\"] = data_wide[col_rm].astype(str)\n",
    "data_wide = data_wide.astype(object).pivot(\n",
    "    index=cols_subject[0], columns=col_rm, values=rm_num.index.values)\n",
    "data_wide.columns = [f\"{c[0]}_{c[1]}\" for c in data_wide.columns]\n",
    "repeat_fin = data_new.drop(rm_num.index.values, axis=1).groupby(\n",
    "    cols_subject[0]).apply(\n",
    "    lambda s: s.apply(lambda x: len(x.unique()) > 1)).stack()\n",
    "if repeat_fin.any():\n",
    "    print(repeat_fin[repeat_fin].reset_index(1)[\"level_1\"].unique())\n",
    "    raise ValueError(\"Columns varying w/i-subject retained in data_new!\")\n",
    "data_new = data_wide.join(data_new.drop(rm_num.index.values, axis=1).groupby(\n",
    "    cols_subject[0]).apply(lambda s: s.apply(\n",
    "        lambda x: x.unique()[0])))  # join bt- & wi-subject columns (wide)\n",
    "data_new = data_new.replace({\"nan\": np.nan})\n",
    "data_new = data_new.assign(redcap_event_name=redcap_event_name)\n",
    "for i in data_dict.index.difference(data_new.columns):\n",
    "    data_new[i] = np.nan\n",
    "data_new = data_new[[\"redcap_event_name\"] + list(\n",
    "    set(data_dict.index.values[1:]))]\n",
    "\n",
    "# type_of_experiment\n",
    "data_new = data_new.join(data_new[[f\"type_of_experiment_{x}\" for x in range(\n",
    "    1, int(max_rm) + 1)]].apply(lambda x: False if all(x.isnull()) else any(\n",
    "        (not pd.isnull(i) and str(i).lower() != \"scrna\" for i in x)\n",
    "        ), axis=1).replace(False, 0).replace(True, 1).to_frame(\n",
    "            \"type_of_experiment___atac\"))\n",
    "data_new = data_new.join(data_new[[f\"type_of_experiment_{x}\" for x in range(\n",
    "    1, int(max_rm) + 1)]].apply(lambda x: False if all(x.isnull()) else any(\n",
    "        (not pd.isnull(i) and str(i).lower() == \"scrna\" for i in x)\n",
    "        ), axis=1).replace(False, 0).replace(True, 1).to_frame(\n",
    "            \"type_of_experiment___3prime\"))\n",
    "\n",
    "# Renaming\n",
    "data_new = data_new.rename(dict(zip([f\"type_of_experiment_{i}\" for i in range(1, int(max_rm) + 1)], [f\"experiment_{i}\" for i in range(1, int(max_rm) + 1)])), axis=1)\n",
    "data_new = data_new.rename(dict([(f\"nextseq_{i}\", f\"nextseq_2000_{i}\") for i in range(1, int(max_rm) + 1)]), axis=1)\n",
    "data_new = data_new.rename(dict([(f\"novaseq_{i}\", f\"novaseq_6000_{i}\") for i in range(1, int(max_rm) + 1)]), axis=1)\n",
    "data_new = data_new.rename(dict([(\"nextseq_{i}\", f\"nextseq_2000_{i}\") for i in range(1, int(max_rm) + 1)]), axis=1)\n",
    "\n",
    "# Numbers of Cells/Nuclei\n",
    "for x in [\"no_live_cells\", \"no_live_nuclei\", \"no_nuclei\", \"targ_cell\"]:\n",
    "    for i in range(1, int(max_rm) + 1):\n",
    "        # data_new = data_new.astype({f\"{x}_{i}\": \"Int64\"})\n",
    "        data_new[f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].astype(object)\n",
    "        if any((\"Est\" in str(i) for i in data_new.loc[:, f\"{x}_{i}\"])):\n",
    "            for q in data_new.loc[:, f\"{x}_{i}\"].index.values:\n",
    "                if \"Est\" in str(data_new.loc[q, f\"{x}_{i}\"]):\n",
    "                    thou = \"K\" in str(data_new.loc[q, f\"{x}_{i}\"])\n",
    "                    print(data_new.loc[q, f\"{x}_{i}\"])\n",
    "                    data_new.loc[q, f\"{x}_{i}\"] = re.sub(\"Est: \", \"\", re.sub(\n",
    "                        \"K\", \"\", data_new.loc[q, f\"{x}_{i}\"]))\n",
    "                    if thou:\n",
    "                        data_new.loc[q, f\"{x}_{i}\"] = float(data_new.loc[q, f\"{x}_{i}\"]) * 1000\n",
    "                    print(data_new.loc[q, f\"{x}_{i}\"], \"\\n\\n\")\n",
    "        data_new.loc[:, f\"{x}_{i}\"] = data_new.loc[:, f\"{x}_{i}\"].replace(\"No load\", 0)\n",
    "        data_new.loc[:, f\"{x}_{i}\"] = data_new[f\"{x}_{i}\"].replace(\n",
    "            \"\", np.nan).astype(float).astype(\"Int64\")\n",
    "        # data_new.loc[:, f\"{x}_{i}\"] = data_new.loc[:, f\"{x}_{i}\"].replace(\n",
    "        #     np.nan, \"\").apply(lambda x: x if x == \"\" else re.sub(\n",
    "        #         \".0\", \"\", str(x))).astype(str)\n",
    "    \n",
    "data_new = data_new.dropna(how=\"all\", axis=1)\n",
    "\n",
    "# Save New Data & Dictionary\n",
    "# data_dict.to_csv(\"data_dictionary_new.csv\", na_rep=\"\")\n",
    "data_new.to_csv(\"data_new.csv\", na_rep=\"\")\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Form Name Section Header Field Type  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_1            library_prep_3_gex_multiome            NaN      radio   \n",
      "\n",
      "                      Field Label Choices, Calculations, OR Slider Labels  \\\n",
      "Variable / Field Name                                                       \n",
      "index_kit_1             Index Kit     1, Dual Index TT | 2, Dual Index TS   \n",
      "\n",
      "                      Field Note Text Validation Type OR Show Slider Number  \\\n",
      "Variable / Field Name                                                         \n",
      "index_kit_1                  NaN                                        NaN   \n",
      "\n",
      "                       Text Validation Min  Text Validation Max  Identifier?  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_1                            NaN                  NaN          NaN   \n",
      "\n",
      "                      Branching Logic (Show field only if...) Required Field?  \\\n",
      "Variable / Field Name                                                           \n",
      "index_kit_1                [type_of_experiment(3prime)] = '1'             NaN   \n",
      "\n",
      "                      Custom Alignment  Question Number (surveys only)  \\\n",
      "Variable / Field Name                                                    \n",
      "index_kit_1                        NaN                             NaN   \n",
      "\n",
      "                       Matrix Group Name  Matrix Ranking? Field Annotation  \n",
      "Variable / Field Name                                                       \n",
      "index_kit_1                          NaN              NaN              NaN  \n",
      "                                         Form Name Section Header Field Type  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_2            library_prep_3_gex_multiome            NaN      radio   \n",
      "\n",
      "                      Field Label Choices, Calculations, OR Slider Labels  \\\n",
      "Variable / Field Name                                                       \n",
      "index_kit_2             Index Kit     1, Dual Index TT | 2, Dual Index TS   \n",
      "\n",
      "                      Field Note Text Validation Type OR Show Slider Number  \\\n",
      "Variable / Field Name                                                         \n",
      "index_kit_2                  NaN                                        NaN   \n",
      "\n",
      "                       Text Validation Min  Text Validation Max  Identifier?  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_2                            NaN                  NaN          NaN   \n",
      "\n",
      "                      Branching Logic (Show field only if...) Required Field?  \\\n",
      "Variable / Field Name                                                           \n",
      "index_kit_2                [type_of_experiment(3prime)] = '1'             NaN   \n",
      "\n",
      "                      Custom Alignment  Question Number (surveys only)  \\\n",
      "Variable / Field Name                                                    \n",
      "index_kit_2                        NaN                             NaN   \n",
      "\n",
      "                       Matrix Group Name  Matrix Ranking? Field Annotation  \n",
      "Variable / Field Name                                                       \n",
      "index_kit_2                          NaN              NaN              NaN  \n",
      "                                         Form Name Section Header Field Type  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_3            library_prep_3_gex_multiome            NaN      radio   \n",
      "\n",
      "                      Field Label Choices, Calculations, OR Slider Labels  \\\n",
      "Variable / Field Name                                                       \n",
      "index_kit_3             Index Kit     1, Dual Index TT | 2, Dual Index TS   \n",
      "\n",
      "                      Field Note Text Validation Type OR Show Slider Number  \\\n",
      "Variable / Field Name                                                         \n",
      "index_kit_3                  NaN                                        NaN   \n",
      "\n",
      "                       Text Validation Min  Text Validation Max  Identifier?  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_3                            NaN                  NaN          NaN   \n",
      "\n",
      "                      Branching Logic (Show field only if...) Required Field?  \\\n",
      "Variable / Field Name                                                           \n",
      "index_kit_3                [type_of_experiment(3prime)] = '1'             NaN   \n",
      "\n",
      "                      Custom Alignment  Question Number (surveys only)  \\\n",
      "Variable / Field Name                                                    \n",
      "index_kit_3                        NaN                             NaN   \n",
      "\n",
      "                       Matrix Group Name  Matrix Ranking? Field Annotation  \n",
      "Variable / Field Name                                                       \n",
      "index_kit_3                          NaN              NaN              NaN  \n",
      "                                         Form Name Section Header Field Type  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_4            library_prep_3_gex_multiome            NaN      radio   \n",
      "\n",
      "                      Field Label Choices, Calculations, OR Slider Labels  \\\n",
      "Variable / Field Name                                                       \n",
      "index_kit_4             Index Kit     1, Dual Index TT | 2, Dual Index TS   \n",
      "\n",
      "                      Field Note Text Validation Type OR Show Slider Number  \\\n",
      "Variable / Field Name                                                         \n",
      "index_kit_4                  NaN                                        NaN   \n",
      "\n",
      "                       Text Validation Min  Text Validation Max  Identifier?  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_4                            NaN                  NaN          NaN   \n",
      "\n",
      "                      Branching Logic (Show field only if...) Required Field?  \\\n",
      "Variable / Field Name                                                           \n",
      "index_kit_4                [type_of_experiment(3prime)] = '1'             NaN   \n",
      "\n",
      "                      Custom Alignment  Question Number (surveys only)  \\\n",
      "Variable / Field Name                                                    \n",
      "index_kit_4                        NaN                             NaN   \n",
      "\n",
      "                       Matrix Group Name  Matrix Ranking? Field Annotation  \n",
      "Variable / Field Name                                                       \n",
      "index_kit_4                          NaN              NaN              NaN  \n",
      "                                         Form Name Section Header Field Type  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_5            library_prep_3_gex_multiome            NaN      radio   \n",
      "\n",
      "                      Field Label Choices, Calculations, OR Slider Labels  \\\n",
      "Variable / Field Name                                                       \n",
      "index_kit_5             Index Kit     1, Dual Index TT | 2, Dual Index TS   \n",
      "\n",
      "                      Field Note Text Validation Type OR Show Slider Number  \\\n",
      "Variable / Field Name                                                         \n",
      "index_kit_5                  NaN                                        NaN   \n",
      "\n",
      "                       Text Validation Min  Text Validation Max  Identifier?  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_5                            NaN                  NaN          NaN   \n",
      "\n",
      "                      Branching Logic (Show field only if...) Required Field?  \\\n",
      "Variable / Field Name                                                           \n",
      "index_kit_5                [type_of_experiment(3prime)] = '1'             NaN   \n",
      "\n",
      "                      Custom Alignment  Question Number (surveys only)  \\\n",
      "Variable / Field Name                                                    \n",
      "index_kit_5                        NaN                             NaN   \n",
      "\n",
      "                       Matrix Group Name  Matrix Ranking? Field Annotation  \n",
      "Variable / Field Name                                                       \n",
      "index_kit_5                          NaN              NaN              NaN  \n",
      "                                         Form Name Section Header Field Type  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_6            library_prep_3_gex_multiome            NaN      radio   \n",
      "\n",
      "                      Field Label Choices, Calculations, OR Slider Labels  \\\n",
      "Variable / Field Name                                                       \n",
      "index_kit_6             Index Kit     1, Dual Index TT | 2, Dual Index TS   \n",
      "\n",
      "                      Field Note Text Validation Type OR Show Slider Number  \\\n",
      "Variable / Field Name                                                         \n",
      "index_kit_6                  NaN                                        NaN   \n",
      "\n",
      "                       Text Validation Min  Text Validation Max  Identifier?  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_6                            NaN                  NaN          NaN   \n",
      "\n",
      "                      Branching Logic (Show field only if...) Required Field?  \\\n",
      "Variable / Field Name                                                           \n",
      "index_kit_6                [type_of_experiment(3prime)] = '1'             NaN   \n",
      "\n",
      "                      Custom Alignment  Question Number (surveys only)  \\\n",
      "Variable / Field Name                                                    \n",
      "index_kit_6                        NaN                             NaN   \n",
      "\n",
      "                       Matrix Group Name  Matrix Ranking? Field Annotation  \n",
      "Variable / Field Name                                                       \n",
      "index_kit_6                          NaN              NaN              NaN  \n",
      "                                         Form Name Section Header Field Type  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_7            library_prep_3_gex_multiome            NaN      radio   \n",
      "\n",
      "                      Field Label Choices, Calculations, OR Slider Labels  \\\n",
      "Variable / Field Name                                                       \n",
      "index_kit_7             Index Kit     1, Dual Index TT | 2, Dual Index TS   \n",
      "\n",
      "                      Field Note Text Validation Type OR Show Slider Number  \\\n",
      "Variable / Field Name                                                         \n",
      "index_kit_7                  NaN                                        NaN   \n",
      "\n",
      "                       Text Validation Min  Text Validation Max  Identifier?  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_7                            NaN                  NaN          NaN   \n",
      "\n",
      "                      Branching Logic (Show field only if...) Required Field?  \\\n",
      "Variable / Field Name                                                           \n",
      "index_kit_7                [type_of_experiment(3prime)] = '1'             NaN   \n",
      "\n",
      "                      Custom Alignment  Question Number (surveys only)  \\\n",
      "Variable / Field Name                                                    \n",
      "index_kit_7                        NaN                             NaN   \n",
      "\n",
      "                       Matrix Group Name  Matrix Ranking? Field Annotation  \n",
      "Variable / Field Name                                                       \n",
      "index_kit_7                          NaN              NaN              NaN  \n",
      "                                         Form Name Section Header Field Type  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_8            library_prep_3_gex_multiome            NaN      radio   \n",
      "\n",
      "                      Field Label Choices, Calculations, OR Slider Labels  \\\n",
      "Variable / Field Name                                                       \n",
      "index_kit_8             Index Kit     1, Dual Index TT | 2, Dual Index TS   \n",
      "\n",
      "                      Field Note Text Validation Type OR Show Slider Number  \\\n",
      "Variable / Field Name                                                         \n",
      "index_kit_8                  NaN                                        NaN   \n",
      "\n",
      "                       Text Validation Min  Text Validation Max  Identifier?  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_8                            NaN                  NaN          NaN   \n",
      "\n",
      "                      Branching Logic (Show field only if...) Required Field?  \\\n",
      "Variable / Field Name                                                           \n",
      "index_kit_8                [type_of_experiment(3prime)] = '1'             NaN   \n",
      "\n",
      "                      Custom Alignment  Question Number (surveys only)  \\\n",
      "Variable / Field Name                                                    \n",
      "index_kit_8                        NaN                             NaN   \n",
      "\n",
      "                       Matrix Group Name  Matrix Ranking? Field Annotation  \n",
      "Variable / Field Name                                                       \n",
      "index_kit_8                          NaN              NaN              NaN  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Form Name Section Header Field Type  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_scm          library_prep_3_gex_multiome            NaN      radio   \n",
      "\n",
      "                      Field Label  \\\n",
      "Variable / Field Name               \n",
      "index_kit_scm           Index Kit   \n",
      "\n",
      "                                             Choices, Calculations, OR Slider Labels  \\\n",
      "Variable / Field Name                                                                  \n",
      "index_kit_scm          1, Dual Index TT | 2, Dual Index TS | 3, Single Index Plate N   \n",
      "\n",
      "                      Field Note Text Validation Type OR Show Slider Number  \\\n",
      "Variable / Field Name                                                         \n",
      "index_kit_scm                NaN                                        NaN   \n",
      "\n",
      "                       Text Validation Min  Text Validation Max  Identifier?  \\\n",
      "Variable / Field Name                                                          \n",
      "index_kit_scm                          NaN                  NaN          NaN   \n",
      "\n",
      "                      Branching Logic (Show field only if...) Required Field?  \\\n",
      "Variable / Field Name                                                           \n",
      "index_kit_scm                [type_of_experiment(atac)] = '1'             NaN   \n",
      "\n",
      "                      Custom Alignment  Question Number (surveys only)  \\\n",
      "Variable / Field Name                                                    \n",
      "index_kit_scm                      NaN                             NaN   \n",
      "\n",
      "                       Matrix Group Name  Matrix Ranking? Field Annotation  \n",
      "Variable / Field Name                                                       \n",
      "index_kit_scm                        NaN              NaN              NaN  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Form Name</th>\n",
       "      <th>Section Header</th>\n",
       "      <th>Field Type</th>\n",
       "      <th>Field Label</th>\n",
       "      <th>Choices, Calculations, OR Slider Labels</th>\n",
       "      <th>Field Note</th>\n",
       "      <th>Text Validation Type OR Show Slider Number</th>\n",
       "      <th>Text Validation Min</th>\n",
       "      <th>Text Validation Max</th>\n",
       "      <th>Identifier?</th>\n",
       "      <th>Branching Logic (Show field only if...)</th>\n",
       "      <th>Required Field?</th>\n",
       "      <th>Custom Alignment</th>\n",
       "      <th>Question Number (surveys only)</th>\n",
       "      <th>Matrix Group Name</th>\n",
       "      <th>Matrix Ranking?</th>\n",
       "      <th>Field Annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable / Field Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>record_id</th>\n",
       "      <td>sample_information_3_gex_multiome</td>\n",
       "      <td></td>\n",
       "      <td>text</td>\n",
       "      <td>Record ID</td>\n",
       "      <td></td>\n",
       "      <td>Standardized subject ID (or Sequencing Batch ID if applicable). Please follow the convention: SN_Ze_KO1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lib_id_1</th>\n",
       "      <td>sample_information_3_gex_multiome</td>\n",
       "      <td></td>\n",
       "      <td>text</td>\n",
       "      <td>ID UNIQUE TO THE SAMPLE AND MEASUREMENT. This should not ever be repeated, even for the same subject, or a different run of the same sample.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>y</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lib_id_2</th>\n",
       "      <td>sample_information_3_gex_multiome</td>\n",
       "      <td></td>\n",
       "      <td>text</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lib_id_3</th>\n",
       "      <td>sample_information_3_gex_multiome</td>\n",
       "      <td></td>\n",
       "      <td>text</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lib_id_4</th>\n",
       "      <td>sample_information_3_gex_multiome</td>\n",
       "      <td></td>\n",
       "      <td>text</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Form Name Section Header  \\\n",
       "Variable / Field Name                                                     \n",
       "record_id              sample_information_3_gex_multiome                  \n",
       "lib_id_1               sample_information_3_gex_multiome                  \n",
       "lib_id_2               sample_information_3_gex_multiome                  \n",
       "lib_id_3               sample_information_3_gex_multiome                  \n",
       "lib_id_4               sample_information_3_gex_multiome                  \n",
       "\n",
       "                      Field Type  \\\n",
       "Variable / Field Name              \n",
       "record_id                   text   \n",
       "lib_id_1                    text   \n",
       "lib_id_2                    text   \n",
       "lib_id_3                    text   \n",
       "lib_id_4                    text   \n",
       "\n",
       "                                                                                                                                                        Field Label  \\\n",
       "Variable / Field Name                                                                                                                                                 \n",
       "record_id                                                                                                                                                 Record ID   \n",
       "lib_id_1               ID UNIQUE TO THE SAMPLE AND MEASUREMENT. This should not ever be repeated, even for the same subject, or a different run of the same sample.   \n",
       "lib_id_2                                                                                                                                                              \n",
       "lib_id_3                                                                                                                                                              \n",
       "lib_id_4                                                                                                                                                              \n",
       "\n",
       "                      Choices, Calculations, OR Slider Labels  \\\n",
       "Variable / Field Name                                           \n",
       "record_id                                                       \n",
       "lib_id_1                                                        \n",
       "lib_id_2                                                        \n",
       "lib_id_3                                                        \n",
       "lib_id_4                                                        \n",
       "\n",
       "                                                                                                                    Field Note  \\\n",
       "Variable / Field Name                                                                                                            \n",
       "record_id              Standardized subject ID (or Sequencing Batch ID if applicable). Please follow the convention: SN_Ze_KO1   \n",
       "lib_id_1                                                                                                                         \n",
       "lib_id_2                                                                                                                         \n",
       "lib_id_3                                                                                                                         \n",
       "lib_id_4                                                                                                                         \n",
       "\n",
       "                      Text Validation Type OR Show Slider Number  \\\n",
       "Variable / Field Name                                              \n",
       "record_id                                                          \n",
       "lib_id_1                                                           \n",
       "lib_id_2                                                           \n",
       "lib_id_3                                                           \n",
       "lib_id_4                                                           \n",
       "\n",
       "                      Text Validation Min Text Validation Max Identifier?  \\\n",
       "Variable / Field Name                                                       \n",
       "record_id                                                                   \n",
       "lib_id_1                                                                    \n",
       "lib_id_2                                                                    \n",
       "lib_id_3                                                                    \n",
       "lib_id_4                                                                    \n",
       "\n",
       "                      Branching Logic (Show field only if...) Required Field?  \\\n",
       "Variable / Field Name                                                           \n",
       "record_id                                                                       \n",
       "lib_id_1                                                                    y   \n",
       "lib_id_2                                                                        \n",
       "lib_id_3                                                                        \n",
       "lib_id_4                                                                        \n",
       "\n",
       "                      Custom Alignment Question Number (surveys only)  \\\n",
       "Variable / Field Name                                                   \n",
       "record_id                                                               \n",
       "lib_id_1                                                                \n",
       "lib_id_2                                                                \n",
       "lib_id_3                                                                \n",
       "lib_id_4                                                                \n",
       "\n",
       "                      Matrix Group Name Matrix Ranking? Field Annotation  \n",
       "Variable / Field Name                                                     \n",
       "record_id                                                                 \n",
       "lib_id_1                                                                  \n",
       "lib_id_2                                                                  \n",
       "lib_id_3                                                                  \n",
       "lib_id_4                                                                  "
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_field_stems = [\"type_of_experiment\", \"date_sent\", \"pre_amp_date\", \n",
    "                   \"instrument\", \"sc_process_date\", \"sample\", \n",
    "                   \"novaseq_6000\", \"nextseq_2000\"\n",
    "                   #, \n",
    "                #    \"inflam_status_chronicity\", \"x_chem_version_sc\", \n",
    "                #    \"lib_id\", \"index_kit\"\n",
    "                   ]\n",
    "# new_field_stems = pd.unique([\"_\".join(f.split(\"_\")[:-1]) for f in fields])\n",
    "drc = pd.read_csv(dd_dict_csv, index_col=0).rename_axis(\n",
    "    \"Variable / Field Name\")\n",
    "for x in [\"instrument\", \"novaseq_6000\", \"nextseq_2000\"]: \n",
    "    max_choice = int(drc.loc[x][\"Choices, Calculations, OR Slider Labels\"].split(\" | \")[-1].split(\", \")[0]) + 1\n",
    "    drc.loc[x, \"Choices, Calculations, OR Slider Labels\"] = drc.loc[x][\"Choices, Calculations, OR Slider Labels\"] + f\" | {max_choice}, Not Sequenced\"\n",
    "\n",
    "for i in range(1, int(max_rm) + 1):\n",
    "    drc.loc[f\"cell_viability_percentage_{i}\", \"Text Validation Type OR Show Slider Number\"] = \"number\"\n",
    "    drc.loc[f\"cell_viability_percentage_{i}\", \"Text Validation Max\"] = 100\n",
    "    drc.loc[f\"cell_viability_percentage_{i}\", \"Text Validation Min\"] = 0\n",
    "    drc.loc[f\"cell_viability_percentage_{i}\", \"Field Type\"] = \"text\"\n",
    "\n",
    "rows = []\n",
    "for i in drc.index.values:\n",
    "    if i in new_field_stems:\n",
    "        r_s = [drc.loc[[i]]] if i in [\"type_of_experiment\", \"instrument\"] else []\n",
    "        keys = [i] if i in [\"type_of_experiment\"] else []\n",
    "        \n",
    "        # RMs\n",
    "        for q in range(1, int(max_rm) + 1):\n",
    "            ddd = drc.loc[[i]]\n",
    "            if any((s in str(ddd[\"Branching Logic (Show field only if...)\"]) for s in new_field_stems)):\n",
    "                for s in set(new_field_stems).difference([\"type_of_experiment\"]):\n",
    "                    if s in str(ddd[\"Branching Logic (Show field only if...)\"]):\n",
    "                        ddd.loc[i, \"Branching Logic (Show field only if...)\"] = re.sub(s, f\"{s}_{q}\", str(ddd[\"Branching Logic (Show field only if...)\"].loc[i]))\n",
    "            ddd.loc[i, \"Field Label\"] = f\"{ddd.loc[i, 'Field Label']} {q}\"\n",
    "            if i == \"type_of_experiment\": \n",
    "                ddd.loc[i, \"Choices, Calculations, OR Slider Labels\"] = \"1, scRNA | 2, Multiome - Gene Expression | 3, Multiome - ATAC | 5, CITE-seq | 888, Other, please specify\"\n",
    "                ddd.loc[i, \"Field Type\"] = \"dropdown\"\n",
    "                keys += [f\"experiment_{q}\"]\n",
    "            else:\n",
    "                keys += [f\"{i}_{q}\"]\n",
    "            r_s += [ddd.drop(drc.index.names[0], axis=1) if drc.index.names[0] in ddd else ddd]\n",
    "            \n",
    "        # Concatenate RMs & Add to List of Rows\n",
    "        r_s = pd.concat(r_s, keys=keys, names=list(\n",
    "            drc.index.names)).reset_index(1, drop=True)\n",
    "        rows += [r_s.loc[[i]] for i in r_s.index.values]\n",
    "    else:\n",
    "        if \"index_kit\" in i: \n",
    "            print(drc.loc[[i]])\n",
    "        rows += [drc.loc[[i]]]\n",
    "new = pd.concat(rows, names=list(drc.index.names)).replace(\n",
    "    \"nan\", \"\").replace(np.nan, \"\").apply(lambda y: y.apply(\n",
    "        lambda x: re.sub(\".0\", \"\", str(x)\n",
    "                         ) if \"Validation M\" in y.name and x != \"\" else x))\n",
    "if drc.index.names[0] in new.columns:\n",
    "    new = new.drop(drc.index.names[0], axis=1)\n",
    "# new = new.rename(dict(zip([f\"type_of_experiment_{i}\" for i in range(1, int(max_rm) + 1)], [f\"experiment_{i}\" for i in range(1, int(max_rm) + 1)])), axis=1)\n",
    "new = new.reset_index().drop_duplicates().set_index(new.index.names)\n",
    "\n",
    "new.to_csv(\"data_dictionary_new.csv\", na_rep=\"\", index=True, \n",
    "           index_label=drc.index.names[0])\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "## Updates\n",
    "\n",
    "### August 2\n",
    "\n",
    "- Code to do the following has been completed and tested\n",
    "\n",
    "      * Modify data dictionary to include new repeated measures fields (e.g., \"tissue_origin_1,\" \"tissue_origin_2,\"...)\n",
    "      * Pivot Google sheets data to wide format\n",
    "      * Detect additional potential issues preventing transformation\n",
    "      \n",
    "- We'll need to allow NA categories for repeated measures fields b/c not everyone will have max (~8) samples\n",
    "\n",
    "      * But for some of those, we won't want to allow missingness AS LONG AS any variable is recorded for that measurement occasion\n",
    "      * How to enforce? Check for _# on every other variable or something?\n",
    "\n",
    "### July 31\n",
    "\n",
    "#### Missingness\n",
    "\n",
    "- We still have pretty substantial missingness on several important categorical variables. (These numbers exclude missingness where entries should be NA (e.g., disease_status for healthy controls), at least as far as I remembered the applicable conditions.)\n",
    "    * disease_status (55)\n",
    "    * IDs (18 grid and 5 patient_id)\n",
    "    * instrument (87)\n",
    "- We also have missingness on date variables (pre_amp_date, date_sent, sc_process_date) and some non-categorical variables (no_live_cells, cell_viability_percentage, targ_cell, no_live_nuclei, no_nuclei); these missing values may or may not be appropriate (I havent investigate) and regardless won't necessarily break the transition since we can usually just put NAs for non-categorical fields, but I wanted to note it for completeness.\n",
    "\n",
    "#### Inflammation Status Categories\n",
    "Ive sent Judy an email regarding the inflammation status entries that dont fit under current inflamm_status REDCap categories (e.g., DSS-related ones).\n",
    "\n",
    "## Meetings\n",
    "\n",
    "### Chris\n",
    "\n",
    "Take out leading 00 in libid except for QQ samples\n",
    "\n",
    "Consult Judy about inflam_status \"treatment\" categories (e.g., DSS)\n",
    "\n",
    "Others must fill in NAs for certain things\n",
    "\n",
    "Allow NAs for disease_status since QQXXXX lib_ids won't ever have data for it?\n",
    "\n",
    "Issues from Todays Work @Chris Tastad \n",
    "We created a \"Healthy mice\" category for \"disease,\" but I failed to notice branching logic only lets it fill in for humans. Change branching, or remove Healthy mice category?\n",
    "\n",
    "Blanks (b/c respecting branching logic) vs. NAs -- some mixed up in Google sheet, so need to fix there or programmatically by using extracted branching logic?\n",
    "\n",
    "\n",
    "### (Email) Ksenija\n",
    "\n",
    "Once we clean the metadata, @Ksenija will make changes related to using drop-down boxes for past free-entry/other specifiers so people dont repeat random variations of free-entry choices.\n",
    "\n",
    "RE #1(a) below (inflam_status): \n",
    "\n",
    "Ksenija will standardize, e.g., collapse '2X DSS + 10uM BZA' and 2X DSS --> 10uM BZA'  into one category.\n",
    "\n",
    "We should get Judy's input on what to keep (1X vs 2X).\n",
    "\n",
    "Some info can be redirected to notes_sample_prime_1-8.\n",
    "\n",
    "#1(c): Ksenija will talk to Felix about inflam_status and disease_status.\n",
    "\n",
    "#3 (index_kit)\n",
    "\n",
    "Ksenija will fill in missing values on the Google sheets metadatabase.\n",
    "\n",
    "I will create an NA category. Also, Ksenija noticed a \"Single Index Plate N\" category, but only under Multiome-ATAC.\n",
    "\n",
    "#6 (instrument): Ksenija will fill in missing values for Martin et al. data.\n",
    "\n",
    "\n",
    "### Ksenija, Chris, and Elizabeth (07/14/2023)\n",
    "\n",
    "Inflammation status (\"inflam_status\" REDCap field)\n",
    "      (a) Didn't discuss because Ksenija answered by email, but I'm realizing I'm still not entirely certain how these should be mapped given the choices of 1, Inflamed | 2, Non-inflamed | 3, Healthy Control | 4, Other, please specify\n",
    "   \tShould these all be \"other?\"\n",
    "   \t- '350nM hGM-CSF'\n",
    "\n",
    "'0.25% DSS 1X'\n",
    "\n",
    "'0.25% DSS 1X + 350nM hGM-CSF'\n",
    "\n",
    "'2X 0.075% DSS'\n",
    "\n",
    "'2X DSS + 10uM BZA'\n",
    "\n",
    "'2X DSS --> 10uM BZA'\n",
    "\n",
    "'0.075% DSS 1X'\n",
    "\n",
    "'0.075% DSS 2X'\n",
    "\n",
    "'z'\n",
    "(b) See #5\n",
    "(c) Felix needs to fix\n",
    "\n",
    "Tissue type specification (\"tissue_origin\")\n",
    "(a) and (b) I will make larval intestinal dissection category\n",
    "(c) N/A for blood and other non-tissue\n",
    "\n",
    "Kit (\"index_kit\")\n",
    "(a) XX-TT-XX = TT; XX-NA -> new category that Ill create; TS is for fixed, but not included in metadatabase\n",
    "(b) Ksenija will fill and track people down; I will create category for NA\n",
    "\n",
    "Ksenija will fill in entries of \"pending\"\n",
    "\n",
    "Missing values for \"pre_amp_date\"\n",
    "(a) They should be blank because not multiome\n",
    "(b) Keep\n",
    "\n",
    "Instrument specifications\n",
    "      (a) \"nova_seq_6000\" field should be fed the flow cell info contained in \"instrument\"\n",
    "(b) Martin et al. we may not know, but Felix, Rachel, Shika, maybe others have missing and shouldnt. Senija will track people down and/or fix\n",
    "\n",
    "x_chem_version_sc: Some of these should be missing, but others shouldnt, so Chris changed those  done \n",
    "\n",
    "Some people improperly treated project_owner_id as sample ID rather than subject ID  should be same across different samples within-subject\n",
    "\n",
    "We need it to be the same across record IDs, or well have to create project_owner_1, etc. fields\n",
    "\n",
    "project_owner_id: concatenation of libid_ssids separated by comma, e.g., \"CD0001_FC01, CD0002_FC02\"\n",
    "\n",
    "standard_sample_id: Replicates across samples fine for different types of experiments  I'll check programmatically that this is true\n",
    "\n",
    "Rachels samples where libid = AA1inf and AA1non: Chris isnt sure these even are the libidsdont rename, just have to deal with it\n",
    "\n",
    "Implement drop-down of past specifiers?\n",
    "\n",
    "### (Email) Original\n",
    "\n",
    "Inflammation status (\"inflam_status\" REDCap field)\n",
    "\n",
    "(a) For consistency, I'd like to be able to convert all entries to the available REDCap categories of \"uninflamed\" or \"inflamed.\" There are other values entered in the meta-database, such as \"untreated.\" Some appear to be for non-human models and/or manipulations: \"Untreated,\" \"no treatment,\" \"TNF-a treatment,\" and \"DSS treated.\" (See the post-script at the end of this email for more values.) It does seem that these happen entirely or almost entirely for mouse and zebrafish samples. Let me know how I should code these (e.g., does \"DSS treated\" mean DSS-induced colitis, and should that be coded as UC, other, or should we create animal model categories)?\n",
    "(b) Some entries also have other additional information (e.g., fistula presence) that can only be entered if the \"other\" option is selected for \"status_inflam.\" Is there another variable under which people can store such additional key information if \"status_inflam\" is not \"other?\" Should we have a category for things like \"fistula\"?\n",
    "(c) Should \"PBMC\" entries be re-coded as NA?\n",
    "\n",
    "Tissue type specification (\"tissue_origin\")\n",
    "(a) How should we specify the larval tissue type or the animal intestinal dissection for the samples?\n",
    "(b) Should we alter the \"tissue_origin\" variable to have a category for animal tissue? The relevant values in the meta-database are \"larval intestinal dissection; Tyto sorting for GFP+ lymphocytes\" and \"larval intestinal dissection.\"\n",
    "(c) What about \"whole blood?\"\n",
    "\n",
    "Kit (\"index_kit\")\n",
    "(a) Entries in the meta-database take the form XX-TT-XX or XX-NA-XX (with varying letters/numbers in place of XX). Can you confirm that entries with \"TT\" correspond to \"Dual Index TT?\" What about NA? Do they correspond with \"Dual Index TS?\"\n",
    "(b) There are also a lot of missing values.\n",
    "\n",
    "\"Pending\" entries: Could you clarify the meaning and implications of entries of \"pending\" for a couple variables (one observation, I think)?\n",
    "\n",
    "Disease status (\"disease_status\")\n",
    "(a) We have come across an entry labeled as \"left side\" under the \"disease_status\" variable. Does this indicate that the disease is active specifically on the left side? Please advise.\n",
    "(b) Similar to in (1), there is extra information included (e.g., proctosigmoiditis, fistula, stenosis). Should we just ignore the extra information, create extra fields, or find a pre-existing specifier field under which to include this information?\n",
    "(c) We also appear to have some missing values for these for non-healthy control human subjects.\n",
    "(d) Also, for the \"disease\" field, should we translate \"healthy mice\" into the \"healthy control\" or \"other\" category?\n",
    "\n",
    "Missing values for \"pre_amp_date\"\n",
    "(a) Should all blank values be converted to NA?\n",
    "(b) Are we dropping this variable? It's a field in REDCap, but Chris mentioned we may not need it as it's documented elsewhere and perhaps not of prime significance.\n",
    "\n",
    "Instrument specifications\n",
    "(a) Currently, we classify any instrument as \"Nova-Seq\" or \"Next-Seq.\" We would like to confirm if you prefer to change the categorization from instrument type (Nova Seq vs. Next Seq) to the flow cell used.\n",
    "(b) Are the NA values in the database true missing values, or should these be re-coded as \"Next-Seq?\" There are no other entries that seem to correspond to \"NextSeq\" in the meta-database.\n",
    "\n",
    "\n",
    "Other missing values:\n",
    "- x_chem_version_sc\n",
    "- index_kit\n",
    "\n",
    "Thank you in advance for your help!\n",
    "\n",
    "Best,\n",
    "Elizabeth\n",
    "\n",
    "More \"inflam_status\" values:\n",
    "\n",
    "'350nM hGM-CSF'\n",
    "\n",
    "'0.25% DSS 1X'\n",
    "\n",
    "'0.25% DSS 1X + 350nM hGM-CSF'\n",
    "\n",
    "'2X 0.075% DSS'\n",
    "\n",
    "'2X DSS + 10uM BZA'\n",
    "\n",
    "'2X DSS --> 10uM BZA'\n",
    "\n",
    "'0.075% DSS 1X'\n",
    "\n",
    "'0.075% DSS 2X'\n",
    "\n",
    "'z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Status: 200\n",
      "HTTP Status: 200\n",
      "redcap_event_name\n",
      "pre_amp_date_5\n",
      "no_nuclei_3\n",
      "index_kit_3\n",
      "instrument_3\n",
      "instrument_5\n",
      "standard_sample_id_6\n",
      "targ_cell_2\n",
      "targ_cell_3\n",
      "experiment_6\n",
      "x_chem_version_sc_5\n",
      "date_sent_1\n",
      "sc_process_date_1\n",
      "inflam_status_6\n",
      "standard_sample_id_3\n",
      "lib_id_2\n",
      "standard_sample_id_4\n",
      "experiment_2\n",
      "targ_cell_5\n",
      "no_live_nuclei_1\n",
      "inflam_status_3\n",
      "no_live_nuclei_2\n",
      "disease\n",
      "sc_process_date_6\n",
      "inflam_status_chronicity_2\n",
      "no_live_cells_1\n",
      "inflam_status_chronicity_1\n",
      "lib_id_6\n",
      "experiment_3\n",
      "no_live_cells_3\n",
      "tissue_origin_1\n",
      "index_kit_6\n",
      "inflam_status_4\n",
      "organism\n",
      "x_chem_version_sc_4\n",
      "lib_id_3\n",
      "instrument_1\n",
      "inflam_status_chronicity_3\n",
      "no_nuclei_6\n",
      "tissue_origin_5\n",
      "cell_viability_percentage_3\n",
      "project\n",
      "standard_sample_id_2\n",
      "no_live_nuclei_3\n",
      "x_chem_version_sc_2\n",
      "x_chem_version_sc_6\n",
      "pre_amp_date_4\n",
      "instrument_4\n",
      "date_sent_5\n",
      "index_kit_4\n",
      "tissue_origin_4\n",
      "targ_cell_6\n",
      "sc_process_date_4\n",
      "no_live_nuclei_4\n",
      "lib_id_5\n",
      "index_kit_1\n",
      "disease_status\n",
      "no_nuclei_5\n",
      "targ_cell_4\n",
      "grid\n",
      "inflam_status_5\n",
      "index_kit_2\n",
      "animal_line\n",
      "no_nuclei_2\n",
      "sc_process_date_5\n",
      "no_live_cells_4\n",
      "index_kit_5\n",
      "no_nuclei_1\n",
      "standard_sample_id_5\n",
      "inflam_status_1\n",
      "experiment_4\n",
      "date_sent_2\n",
      "cell_viability_percentage_2\n",
      "project_owner_id\n",
      "instrument_2\n",
      "targ_cell_1\n",
      "experiment_1\n",
      "x_chem_version_sc_3\n",
      "tissue_origin_6\n",
      "date_sent_4\n",
      "pre_amp_date_6\n",
      "pre_amp_date_3\n",
      "date_sent_6\n",
      "cell_viability_percentage_1\n",
      "cell_viability_percentage_4\n",
      "sc_process_date_2\n",
      "pre_amp_date_2\n",
      "inflam_status_2\n",
      "pre_amp_date_1\n",
      "lib_id_1\n",
      "sc_process_date_3\n",
      "no_live_cells_2\n",
      "tissue_origin_3\n",
      "experiment_5\n",
      "tissue_origin_2\n",
      "cell_viability_percentage_5\n",
      "cell_viability_percentage_6\n",
      "patient_id\n",
      "lib_id_4\n",
      "x_chem_version_sc_1\n",
      "date_sent_3\n",
      "no_live_cells_6\n",
      "no_live_cells_5\n",
      "standard_sample_id_1\n",
      "instrument_6\n",
      "no_nuclei_4\n",
      "type_of_experiment___atac\n",
      "type_of_experiment___3prime\n"
     ]
    }
   ],
   "source": [
    "# Options\n",
    "unique_id = \"lib_id\"\n",
    "path_file = \"data_new.csv\"\n",
    "path_config = os.path.join(os.path.expanduser(\"~\"), \n",
    "                           \".ssh/config_redcap.json\")\n",
    "cols_should_be_unique = [\"standard_sample_id\"]\n",
    "project = \"Cho Lab Single Cell Sample Metadatabase\"\n",
    "remove_leading_zeros_lib_id = True\n",
    "overwriteBehavior = \"normal\"  # so blank doesn't overwrite filled\n",
    "\n",
    "# Load Google Sheets Database\n",
    "dff = data_new\n",
    "# dff = pd.read_csv(path_file)\n",
    "if remove_leading_zeros_lib_id:\n",
    "    for i in range(1, 9):\n",
    "        if f\"lib_id_{i}\" in dff.columns:\n",
    "            dff[f\"lib_id_{i}\"] = dff[f\"lib_id_{i}\"].apply(\n",
    "                lambda x: x if pd.isnull(x) else x.lstrip(\n",
    "                    \"00\"))  # remove leading zeros from unique ID\n",
    "\n",
    "# Load Data Dictionary\n",
    "with open(path_config, \"r\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "api_url, token = config[project][\"url\"], config[project][\"token\"]\n",
    "drc = get_redcap_metadata(project, api_url, token)\n",
    "# data_dict = pd.concat([pd.Series(x, name=x[\"field_name\"]) \n",
    "#                        for x in drc[\"data_dictionary\"]], axis=1).T\n",
    "\n",
    "\n",
    "# # Convert Categorical Values to REDCap Codes\n",
    "# for f in dff.columns:\n",
    "#     print(f)\n",
    "#     if f in data_dict.index.values and data_dict.loc[f].field_type in [\n",
    "#         \"radio\", \"dropdown\"]:\n",
    "#             cats = data_dict.loc[f].loc[\n",
    "#                 \"select_choices_or_calculations\"].split(\" | \")\n",
    "#             dff = dff.drop(f, axis=1).join(\n",
    "#                 dff[f].apply(lambda x: x if pd.isnull(x) else dict(\n",
    "#                     pd.DataFrame([v.split(\", \") for v in cats]).set_index(1)[0])[x]))\n",
    "\n",
    "data_dict = new\n",
    "col = \"Choices, Calculations, OR Slider Labels\"\n",
    "\n",
    "# Convert Categorical Values to REDCap Codes\n",
    "for f in dff.columns:\n",
    "    print(f)\n",
    "    if f in data_dict.index.values and data_dict.loc[f][\"Field Type\"] in [\n",
    "        \"radio\", \"dropdown\"]:\n",
    "            cats = data_dict.loc[f].loc[col].split(\" | \")\n",
    "            dff = dff.drop(f, axis=1).join(\n",
    "                dff[f].apply(lambda x: x if pd.isnull(x) else dict(\n",
    "                    pd.DataFrame([v.split(\", \") for v in cats]).set_index(1)[0])[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorized Data New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index_kit_1', 'index_kit_2', 'index_kit_3', 'index_kit_4',\n",
      "       'index_kit_5', 'index_kit_6', 'pre_amp_date_1', 'pre_amp_date_2',\n",
      "       'pre_amp_date_3', 'pre_amp_date_4', 'pre_amp_date_5', 'pre_amp_date_6',\n",
      "       'type_of_experiment___3prime', 'type_of_experiment___atac'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_362937/2938659295.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_n.loc[:, \"redcap_event_name\"] = arms_dict[x]\n",
      "/tmp/ipykernel_362937/2938659295.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_n.loc[:, \"redcap_event_name\"] = arms_dict[x]\n",
      "/tmp/ipykernel_362937/2938659295.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_n.loc[:, \"redcap_event_name\"] = arms_dict[x]\n",
      "/tmp/ipykernel_362937/2938659295.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d_n.loc[:, \"redcap_event_name\"] = \"forms_arm_1\"\n"
     ]
    }
   ],
   "source": [
    "form_cols = []\n",
    "arms_dict = {\"sample_information_3_gex_multiome\": \"forms_arm_1\", \n",
    "             \"sequencing\": \"forms_arm_2\", \n",
    "             \"sequencing_qc\": \"forms_arm_3\"}\n",
    "for x in new[\"Form Name\"].unique():\n",
    "    d_n = dff[new[new[\"Form Name\"] == x].index.intersection(dff.columns)]\n",
    "    if x in arms_dict:\n",
    "        d_n.loc[:, \"redcap_event_name\"] = arms_dict[x]\n",
    "        d_n.to_csv(f\"data_new_{arms_dict[x]}.csv\", na_rep=\"\", index_label=dff.index.names[0])\n",
    "        form_cols += list(d_n.columns)\n",
    "    # else:\n",
    "        # print(f\"{'=' * 80}\\n\\n{x}\\n{d_n.columns}\")\n",
    "        \n",
    "print(dff.columns.difference(form_cols))\n",
    "d_n = dff[dff.columns.difference(form_cols)]\n",
    "d_n.loc[:, \"redcap_event_name\"] = \"forms_arm_1\"\n",
    "d_n.to_csv(f\"data_new_other.csv\", na_rep=\"\", index_label=dff.index.names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv(\"data_new.csv\", index_label=\"record_id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
